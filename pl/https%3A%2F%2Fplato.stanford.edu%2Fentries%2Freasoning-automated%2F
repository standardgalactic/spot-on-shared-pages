<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html lang="en"> <!-- <![endif]-->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Automated Reasoning (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Automated Reasoning" />
<meta property="citation_author" content="Portoraro, Frederic" />
<meta property="citation_publication_date" content="2001/07/18" />
<meta name="DC.title" content="Automated Reasoning" />
<meta name="DC.creator" content="Portoraro, Frederic" />
<meta name="DCTERMS.issued" content="2001-07-18" />
<meta name="DCTERMS.modified" content="2024-02-10" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
                    <li role="menuitem"><a href="../../new.html">What's New</a></li>
                    <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li role="menuitem"><a href="../../published.html">Chronological</a></li>
                    <li role="menuitem"><a href="../../archives/">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
                    <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
                    <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
                    <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
                    <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
                    <li role="menuitem"><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
                    <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
                    <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit" aria-label="search"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/reasoning-automated/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=reasoning-automated">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Automated Reasoning</h1><div id="pubinfo"><em>First published Wed Jul 18, 2001; substantive revision Sat Feb 10, 2024</em></div>

<div id="preamble">

<p>
Reasoning is the ability to make inferences, and automated reasoning
is concerned with the building of computing systems that automate this
process. Although the overall goal is to mechanize different forms of
reasoning, the term has largely been identified with valid deductive
reasoning as practiced in mathematics and formal logic. In this
respect, automated reasoning is akin to mechanical theorem proving.
Building an automated reasoning program means providing an algorithmic
description to a formal calculus so that it can be implemented on a
computer to prove theorems of the calculus in an efficient manner.
Important aspects of this exercise involve defining the class of
problems the program will be required to solve, deciding what language
will be used by the program to represent the information given to it
as well as new information inferred by the program, specifying the
mechanism that the program will use to conduct deductive inferences,
and figuring out how to perform all these computations efficiently.
While basic research work continues in order to provide the necessary
theoretical framework, the field has reached a point where automated
reasoning programs are being used by researchers to attack open
questions in mathematics and logic, provide important applications in
computing science, solve problems in engineering, and find novel
approaches to questions in exact philosophy. </p>
</div>

<div id="toc">
<!--Entry Contents-->

<ul>

 <li><a href="#Int">1. Introduction</a>
 
<ul>

 <li><a href="#ProDom">1.1 Problem Domain</a></li>
 
 <li><a href="#LanRep">1.2 Language Representation</a></li>
 </ul></li>

 <li><a href="#DedCal">2. Deduction Calculi</a>
 
<ul>

 <li><a href="#Res">2.1 Resolution</a></li>
 
 <li><a href="#SeqDed">2.2 Sequent Deduction</a></li>
 
 <li><a href="#NatDed">2.3 Natural Deduction</a></li>
 
 <li><a href="#MatConMet">2.4 The Matrix Connection Method</a></li>
 
 <li><a href="#TerRew">2.5 Term Rewriting</a></li>
 
 <li><a href="#MatInd">2.6 Mathematical Induction</a></li>
 </ul></li>

 <li><a href="#OthLog">3. Other Logics</a>
 
<ul>

 <li><a href="#HigOrdLog">3.1 Higher-Order Logic</a></li>
 
 <li><a href="#NonClaLog">3.2 Non-classical Logics</a></li>
 </ul></li>

 <li><a href="#App">4. Applications</a>
 
<ul>

 <li><a href="#LogPro">4.1 Logic Programming</a></li>
 
 <li><a href="#SATSol">4.2 SAT Solvers</a></li>
 
 <li><a href="#DedComAlg">4.3 Deductive Computer Algebra</a></li>
 
 <li><a href="#ForVerHar">4.4 Formal Verification of Hardware</a></li>
 
 <li><a href="#ForVerSof">4.5 Formal Verification of Software</a></li>
 
 <li><a href="#LogicAndPhil">4.6 Logic and Philosophy</a></li>
 
 <li><a href="#Mathematics">4.7 Mathematics</a></li>
 
 <li><a href="#AI">4.8 Artificial Intelligence</a></li>
 </ul></li>

 <li><a href="#Con">5. Conclusion</a></li>
 
 <li><a href="#Bib">Bibliography</a></li>
 
 <li><a href="#Aca">Academic Tools</a></li>
 
 <li><a href="#Oth">Other Internet Resources</a></li>
 
 <li><a href="#Rel">Related Entries</a></li>
 </ul>
<!--Entry Contents-->

<hr />
</div>

<div id="main-text">

<h2><a name="Int">1. Introduction</a></h2>

<p>
A problem being presented to an automated reasoning program consists
of two main items, namely a statement expressing the particular
question being asked called the <strong>problem&rsquo;s conclusion</strong>,
and a collection of statements expressing all the relevant information
available to the program&mdash;the <strong>problem&rsquo;s
assumptions</strong>. Solving a problem means proving the conclusion
from the given assumptions by the systematic application of rules of
deduction embedded within the reasoning program. The problem solving
process ends when one such proof is found, when the program is able to
detect the non-existence of a proof, or when it simply runs out of
resources.</p>

<h3><a name="ProDom">1.1 Problem Domain</a></h3>

<p>
A first important consideration in the design of an automated
reasoning program is to delineate the class of problems that the
program will be required to solve&mdash;the <strong>problem
domain</strong>. The domain can be very large, as would be the case
for a general-purpose theorem prover for first-order logic, or be more
restricted in scope as in a special-purpose theorem prover for
Tarski&rsquo;s geometry, or the modal logic K. A typical approach in the
design of an automated reasoning program is to provide it first with
sufficient logical power (e.g., first-order logic) and then further
demarcate its scope to the particular domain of interest defined by a
set of <strong>domain axioms</strong>. To illustrate, EQP, a
theorem-proving program for equational logic, was used to solve an
open question in Robbins algebra (McCune 1997): <em>Are all Robbins
algebras Boolean?</em> For this, the program was provided with the
axioms defining a Robbins algebra:</p>

\[\begin{align}
\tag{A1} &amp;x+y=y+x &amp; \text{(commutativity)}\\
\tag{A2} (&amp;x+y)+z = x+ (y+z) &amp; \text{(associativity)}\\
\tag{A3} -(-(&amp;x+y)+ -(x+-y))=x &amp; \text{(Robbins equation)}
\end{align}\]

<p>
The program was then used to show that a characterization of Boolean
algebra that uses Huntington&rsquo;s equation,

\[-(-x + y) + -(-x + -y) = x,\]


follows from the axioms. We should remark that this problem is
non-trivial since deciding whether a finite set of equations provides
a basis for Boolean algebra is undecidable, that is, it does not
permit an algorithmic representation; also, the problem was attacked
by Robbins, Huntington, Tarski and many of his students with no
success. The key step was to establish that all Robbins algebras
satisfy


\[\exists x\exists y(x + y = x),\]



since it was known that this formula is a sufficient condition for a
Robbins algebra to be Boolean. When EQP was supplied with this piece
of information, the program provided invaluable assistance by
completing the proof automatically. </p>

<p>
A special-purpose theorem prover does not draw its main benefit by
restricting its attention to the domain axioms but from the fact that
the domain may enjoy particular theorem-proving techniques which can
be hardwired&mdash;coded&mdash;within the reasoning program itself and
which may result in a more efficient logic implementation. Much of
EQP&rsquo;s success at settling the Robbins question can be attributed to
its built-in associative-commutative inference mechanisms.</p>

<h3><a name="LanRep">1.2 Language Representation</a></h3>

<p>
A second important consideration in the building of an automated
reasoning program is to decide (1) how problems in its domain will be
presented to the reasoning program; (2) how they will actually be
represented internally within the program; and, (3) how the solutions
found&mdash;completed proofs&mdash;will be displayed back to the user.
There are several formalisms available for this, and the choice is
dependent on the problem domain and the underlying deduction calculus
used by the reasoning program. The most commonly used formalisms
include standard first-order logic, typed \(\lambda\)-calculus, and
clausal logic. We take up clausal logic here and assume that the
reader is familiar with the rudiments of first-order logic; for the
typed \(\lambda\)-calculus the reader may want to check Church 1940.
Clausal logic is a quantifier-free variation of first-order logic and
has been the most widely used notation within the automated reasoning
community. Some definitions are in order: A <strong>term</strong> is a
constant, a variable, or a function whose arguments are themselves
terms. For example, \(a, x, f(x)\),
and \(h(c,f(z),y)\) are all
terms. A <strong>literal</strong> is either an atomic formula, e.g.
\(F(x)\), or the negation of an atomic formula, e.g.
\({\sim}R(x,f(a))\). Two literals are
<strong>complementary</strong> if one is the negation of the other. A
<strong>clause</strong> is a (possibly empty) finite disjunction of
literals \(l_1\vee \ldots \vee l_n\) where no literal appears more than once in the
clause (that is, clauses can be alternatively treated as sets of
literals). <strong>Ground</strong> terms, ground literals, and ground
clauses have no variables. The <strong>empty clause</strong>,
[&nbsp;], is the clause having no literals and, hence, is
unsatisfiable&mdash;false under any interpretation. Some examples:
\({\sim}R(a,b)\), and \(F(a) \vee{\sim}R(f(x),b) \vee F(z)\) are both examples of clauses but only the
former is ground. The general idea is to be able to express a
problem&rsquo;s formulation as a set of clauses or, equivalently, as a
formula in <strong>conjunctive normal form (CNF)</strong>, that is, as
a conjunction of clauses.</p>

<p>
For formulas already expressed in standard logic notation, there is a
systematic two-step procedure for transforming them into conjunctive
normal form. The first step consists in re-expressing a formula into a
semantically equivalent formula in <strong>prenex normal
form</strong>,
\((\Theta x_1)\ldots(\Theta x_n)\alpha(x_1 ,\ldots ,x_n)\), consisting of a
string of quantifiers
\((\Theta x_1)\ldots(\Theta x_n)\)
followed by a quantifier-free expression
\(\alpha(x_1 ,\ldots ,x_n)\) called
the <strong>matrix</strong>. The second step in the transformation
first converts the matrix into conjunctive normal form by using
well-known logical equivalences such as DeMorgan&rsquo;s laws, distribution,
double-negation, and others; then, the quantifiers in front of the
matrix, which is now in conjunctive normal form, are dropped according
to certain rules. In the presence of existential quantifiers, this
latter step does not always preserve equivalence and requires the
introduction of <strong>Skolem functions</strong> whose role is to
&ldquo;simulate&rdquo; the behaviour of existentially quantified
variables. For example, applying the skolemizing process to the
formula


\[\forall x\exists y\forall z\exists u\forall v[R(x,y,v)
\vee{\sim}K(x,z,u,v)]\]



requires the introduction of a one-place and two-place Skolem
functions, \(f\) and \(g\) respectively, resulting in the
formula


\[\forall x\forall z\forall v[R(x,f(x),v)
\vee{\sim}K(x,z,g(x,z),v)]\]



The universal quantifiers can then be removed to obtain the final
clause, \(R(x,f(x),v) \vee{\sim}K(x,z,g(x,z),v)\)
in our example. The Skolemizing process may not preserve equivalence
but maintains satisfiability, which is enough for clause-based
automated reasoning.</p>

<p>
Although clausal form provides a more uniform and economical
notation&mdash;there are no quantifiers and all formulas are
disjunctions&mdash;it has certain disadvantages. One drawback is the
increase in the size of the resulting formula when transformed from
standard logic notation into clausal form. The increase in size is
accompanied by an increase in cognitive complexity that makes it
harder for humans to read proofs written with clauses. Another
disadvantage is that the syntactic structure of a formula in standard
logic notation can be used to guide the construction of a proof but
this information is completely lost in the transformation into clausal
form.</p>

<h2><a name="DedCal">2. Deduction Calculi</a></h2>

<p>
A third important consideration in the building of an automated
reasoning program is the selection of the actual deduction calculus
that will be used by the program to perform its inferences. As
indicated before, the choice is highly dependent on the nature of the
problem domain and there is a fair range of options available:
General-purpose theorem proving and problem solving (first-order
logic, simple type theory), program verification (first-order logic),
distributed and concurrent systems (modal and temporal logics),
program specification (intuitionistic logic), hardware verification
(higher-order logic), logic programming (Horn logic), constraint
satisfaction (propositional clausal logic), mathematics (higher-order logic), computational metaphysics (higher-order modal logic), and others.</p>

<p>
A deduction calculus consists of a set of logical axioms and a
collection of deduction rules for deriving new formulas from
previously derived formulas. Solving a problem in the program&rsquo;s
problem domain then really means establishing a particular formula
\(\alpha\)&mdash;the problem&rsquo;s conclusion&mdash;from the extended set
\(\Gamma\) consisting of the logical axioms, the domain axioms, and the
problem assumptions. That is, the program needs to determine if
\(\Gamma\) entails \(\alpha , \Gamma \vDash \alpha\). How the program
goes about establishing this semantic fact depends, of course, on the
calculus it implements. Some programs may take a very
<strong>direct</strong> route and attempt to establish that
\(\Gamma \vDash \alpha\) by actually constructing a
step-by-step proof of \(\alpha\) from \(\Gamma\). If successful, this shows
of course that \(\Gamma\) derives&mdash;proves&mdash;\(\alpha\), a fact we
denote by writing \(\Gamma \vdash \alpha\). Other reasoning
programs may instead opt for a more <strong>indirect</strong> approach
and try to establish that \(\Gamma \vDash \alpha\) by showing
that \(\Gamma \cup \{{\sim}\alpha \}\) is inconsistent which, in turn, is shown
by deriving a contradiction, \(\bot\), from the set \(\Gamma \cup \{{\sim}\alpha \}\). Automated systems that implement the former approach
include natural deduction systems; the latter approach is used by
systems based on resolution, sequent deduction, and matrix connection
methods.</p>

<p>
Soundness and completeness are two (metatheoretical) properties of a
calculus that are particularly important for automated deduction.
<strong>Soundness</strong> states that the rules of the calculus are
truth-preserving. For a direct calculus this means that if
\(\Gamma \vdash \alpha\) then
\(\Gamma \vDash \alpha\). For indirect calculi, soundness
means that if \(\Gamma \cup \{{\sim}\alpha \} \vdash \bot\) then
\(\Gamma \vDash \alpha\). <strong>Completeness</strong> in a
direct calculus states that if \(\Gamma \vDash \alpha\) then
\(\Gamma \vdash \alpha\). For indirect calculi, the
completeness property is expressed in terms of
<strong>refutations</strong> since one establishes that
\(\Gamma \vDash \alpha\) by showing the existence of a proof,
not of \(\alpha\) from \(\Gamma\), but of \(\bot\) from
\(\Gamma \cup \{{\sim}\alpha \}\). Thus, an indirect calculus is
<strong>refutation complete</strong> if \(\Gamma \vDash \alpha\)
implies \(\Gamma \cup \{{\sim}\alpha \} \vdash \bot\). Of the two
properties, soundness is the most desirable. An incomplete calculus
indicates that there are entailment relations that cannot be
established within the calculus. For an automated reasoning program
this means, informally, that there are true statements that the
program cannot prove. Incompleteness may be an unfortunate affair but
lack of soundness is a truly problematic situation since an unsound
reasoning program would be able to generate false conclusions from
perfectly true information.</p>

<p>
It is important to appreciate the difference between a logical
calculus and its corresponding implementation in a reasoning program.
The implementation of a calculus invariably involves making some
modifications to the calculus and this results, strictly speaking, in
a new calculus. The most important modification to the original
calculus is the &ldquo;mechanization&rdquo; of its deduction rules,
that is, the specification of the systematic way in which the rules
are to be applied. In the process of doing so, one must exercise care
to preserve the metatheoretical properties of the original
calculus.</p>

<p>
Two other metatheoretical properties of importance to automated
deduction are decidability and complexity. A calculus is
<strong>decidable</strong> if it admits an algorithmic representation,
that is, if there is an algorithm that, for any given \(\Gamma\) and
\(\alpha\), it can determine in a finite amount of time the answer,
&ldquo;Yes&rdquo; or &ldquo;No&rdquo;, to the question &ldquo;Does
\(\Gamma \vDash \alpha\)?&rdquo; A calculus may be
undecidable in which case one needs to determine which decidable
fragment to implement. The time-space <strong>complexity</strong> of a
calculus specifies how efficient its algorithmic representation is.
Automated reasoning is made the more challenging because many calculi
of interest are not decidable and have poor complexity measures
forcing researchers to seek tradeoffs between deductive power versus
algorithmic efficiency.</p>

<h3><a name="Res">2.1 Resolution</a></h3>

<p>
Of the many calculi used in the implementation of reasoning programs,
the ones based on the <strong>resolution</strong> principle have been
the most popular. Resolution is modeled after the chain rule (of which
Modus Ponens is a special case) and essentially states that from
\(p \vee q\) and \({\sim}q \vee r\) one can
infer \(p \vee r\). More formally, let \(C - l\) denote the clause \(C\) with the literal
\(l\) removed. Assume that \(C_1\) and
\(C_2\) are ground clauses containing, respectively, a
positive literal \(l_1\) and a negative literal
\({\sim}l_2\) such that \(l_1\) and
\({\sim}l_2\) are complementary. Then, the rule of
<strong>ground resolution</strong> states that, as a result of
<strong>resolving</strong> \(C_1\) and
\(C_2\), one can infer \((C_1 - l_1) \vee(C_2 - {\sim}l_2)\):</p>

\[\tag{ground resolution}\frac{C_1 C_2}{(C_1 - l_1)\vee (C_2 - \sim l_2)}\]

<p>
<strong>Herbrand&rsquo;s theorem</strong> (Herbrand 1930) assures us that
the non-satisfiability of <em>any</em> set of clauses, ground or not,
can be established by using ground resolution. This is a very
significant result for automated deduction since it tells us that if a
set \(\Gamma\) is not satisfied by any of the infinitely many
interpretations, this fact can be determined in <em>finitely</em> many
steps. Unfortunately, a direct implementation of ground resolution
using Herbrand&rsquo;s theorem requires the generation of a vast number of
ground terms making this approach hopelessly inefficient. This issue
was effectively addressed by generalizing the ground resolution rule
to <strong>binary resolution</strong> and by introducing the notion of
unification (Robinson 1965a). Unification allows resolution proofs to
be &ldquo;lifted&rdquo; and be conducted at a more general level;
clauses only need to be instantiated at the moment where they are to
be resolved. Moreover, the clauses resulting from the instantiation
process do not have to be ground instances and may still contain
variables. The introduction of binary resolution and unification is
considered one of the most important developments in the field of
automated reasoning.</p>

<h4>Unification</h4>

<p>
A <strong>unifier</strong> of two expressions&mdash;terms or
clauses&mdash;is a substitution that when applied to the expressions
makes them equal. For example, the substitution \(\sigma\) given by</p>

\[\sigma := \{x \leftarrow b, y \leftarrow b, z \leftarrow f(a,b)\}\]

<p>is a unifier for </p>

\[R(x,f(a,y))\]

<p>and</p>

\[R(b,z)\]

<p>since when applied to both expressions it makes them equal:</p>

\[\begin{aligned}
R(x, f(a, y))\sigma &amp; =  R(b, f(a, b))\\
&amp; =  R(b, z)\sigma
\end{aligned}\]

<p>
A <strong>most general unifier</strong> (mgu) produces the most
general instance shared by two unifiable expressions. In the previous
example, the substitution \(\{x \leftarrow b, y \leftarrow b, z \leftarrow f(a,b)\}\) is a unifier but not an mgu;
however, \(\{x \leftarrow b, z \leftarrow f(a,y)\}\) is an mgu. Note that unification
attempts to &ldquo;match&rdquo; two expressions and this fundamental
process has become a central component of most automated deduction
programs, resolution-based and otherwise.
<strong>Theory-unification</strong> is an extension of the unification
mechanism that includes built-in inference capabilities. For example,
the clauses \(R(g(a,b),x)\)
and \(R(g(b,a),d)\) do not
unify but they AC-unify, where AC-unification is unification with
built-in associative and commutative rules such as
\(g(a,b) = g(b,a)\).
Shifting inference capabilities into the unification mechanism adds
power but at a price: The existence of an mgu for two unifiable
expressions may not be unique (there could actually be infinitely
many), and the unification process becomes undecidable in general.
</p>

<h4>Binary resolution</h4>

<p>
Let \(C_1\) and \(C_2\) be two clauses
containing, respectively, a positive literal \(l_1\)
and a negative literal \({\sim}l_2\) such that
\(l_1\) and \(l_2\) unify with mgu
\(\theta\). Then, </p>

\[\tag{binary resolution}\frac{C_1 C_2}{(C_1 \theta - l_1 \theta)\vee (C_2 \theta - \sim l_2 \theta)}\]


<p>
by binary resolution; the clause \((C_1\theta - l_1\theta) \vee 
(C_2\theta - {\sim}l_2\theta)\)
is called a <strong>binary resolvent</strong> of
\(C_1\) and \(C_2\). </p>

<h4>Factoring</h4>

<p>
If two or more literals occurring in a clause \(C\) share an mgu
\(\theta\) then \(C\theta\) is a <strong>factor</strong> of
\(C\). For example, in \(R(x,a) \vee{\sim}K(f(x),b) \vee R(c,y)\) the literals
\(R(x,a)\) and
\(R(c,y)\) unify with mgu \(\{x \leftarrow c, y \leftarrow a\}\) and, hence,
\(R(c,a) \vee{\sim}K(f(c),b)\) is a factor of the
original clause. </p>

<h4>The Resolution Principle</h4>

<p>
Let \(C_1\)and \(C_2\) be two clauses.
Then, a <strong>resolvent</strong> obtained by
<strong>resolution</strong> from \(C_1\) and
\(C_2\) is defined as: (a) a binary resolvent of
\(C_1\) and \(C_2\); (b) a binary
resolvent of \(C_1\) and a factor of
\(C_2\); (c) a binary resolvent of a factor of
\(C_1\) and \(C_2\); or, (d) a binary
resolvent of a factor of \(C_1\) and a factor of
\(C_2\). </p>

<p>
Resolution proofs, more precisely refutations, are constructed by
deriving the empty clause [&nbsp;] from \(\Gamma \cup \{{\sim}\alpha \}\) using
resolution; this will always be possible if \(\Gamma \cup \{{\sim}\alpha \}\)
is unsatisfiable since resolution is refutation complete (Robinson
1965a). As an example of a resolution proof, we show that the set
\(\{\forall x(P(x) \vee Q(x)), \forall x(P(x)
\supset R(x)),\forall x(Q(x)
\supset R(x))\}\), denoted by \(\Gamma\), entails the
formula \(\exists xR(x)\). The first step is to
find the clausal form of \(\Gamma \cup \{{\sim}\exists xR(x)\}\); the resulting clause set,
denoted by \(S_0\), is shown in steps 1 to 4 in the
refutation below. The refutation is constructed by using a
level-saturation method: Compute all the resolvents of the initial
set, \(S_0\), add them to the set and repeat the
process until the empty clause is derived. (This produces the sequence
of increasingly larger sets: \(S_0,
S_1, S_2,\ldots)\) The only
constraint that we impose is that we do not resolve the same two
clauses more than once.</p>

<blockquote>

<table class="cellpad-med-dense centered">
<tr>
 <td>\(S_0\)</td>
 <td>1</td>
 <td>\(P(x) \vee Q(x)\)</td>
 <td>Assumption</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>2</td>
 <td><em>\({\sim}\)P</em>\((x) \vee R(x)\)</td>
 <td>Assumption</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>3</td>
 <td><em>\({\sim}\)Q</em>\((x) \vee R(x)\)</td>
 <td>Assumption</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>4</td>
 <td>\({\sim}R(a)\)</td>
 <td>Negate conclusion</td> </tr>
<tr>
 <td>\(S_1\)</td>
 <td>5</td>
 <td>\(Q(x) \vee R(x)\)</td>
 <td>Res 1 2</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>6</td>
 <td>\(P(x) \vee R(x)\)</td>
 <td>Res 1 3</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>7</td>
 <td>\({\sim}P(a)\)</td>
 <td>Res 2 4</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>8</td>
 <td>\({\sim}Q(a)\)</td>
 <td>Res 3 4</td> </tr>
<tr>
 <td>\(S_2\)</td>
 <td>9</td>
 <td>\(Q(a)\)</td>
 <td>Res 1 7</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>10</td>
 <td>\(P(a)\)</td>
 <td>Res 1 8</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>11</td>
 <td>\(R(x)\)</td>
 <td>Res 2 6</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>12</td>
 <td>\(R(x)\)</td>
 <td>Res 3 5</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>13</td>
 <td>\(Q(a)\)</td>
 <td>Res 4 5</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>14</td>
 <td>\(P(a)\)</td>
 <td>Res 4 6</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>15</td>
 <td>\(R(a)\)</td>
 <td>Res 5 8</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>16</td>
 <td>\(R(a)\)</td>
 <td>Res 6 7</td> </tr>
<tr>
 <td>\(S_3\)</td>
 <td>17</td>
 <td>\(R(a)\)</td>
 <td>Res 2 10</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>18</td>
 <td>\(R(a)\)</td>
 <td>Res 2 14</td> </tr>
<!--pdf include <tr> <td colspan="4">&nbsp;</td> </tr> pdf include-->
<tr>
 <td>&nbsp;</td>
 <td>19</td>
 <td>\(R(a)\)</td>
 <td>Res 3 9</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>20</td>
 <td>\(R(a)\)</td>
 <td>Res 3 13</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>21&nbsp;</td>
 <td>[&nbsp;]</td>
 <td>Res 4 11</td> </tr>
</table>
</blockquote>

<p>
Although the resolution proof is successful in deriving [&nbsp;], it
has some significant drawbacks. To start with, the refutation is too
long as it takes 21 steps to reach the contradiction, [&nbsp;]. This
is due to the na&iuml;ve brute-force nature of the implementation. The
approach not only generates too many formulas but some are clearly
redundant. Note how \(R(a)\) is derived six times; also,
\(R(x)\) has more &ldquo;information content&rdquo; than
\(R(a)\) and one should keep the former and disregard
the latter. Resolution, like all other automated deduction methods,
must be supplemented by strategies aimed at improving the efficiency
of the deduction process. The above sample derivation has 21 steps but
research-type problems command derivations with thousands or hundreds
of thousands of steps.</p>

<h4>Resolution Strategies</h4>

<p>
The successful implementation of a deduction calculus in an automated
reasoning program requires the integration of search strategies that
reduce the search space by pruning unnecessary deduction paths. Some
strategies remove redundant clauses or tautologies as soon as they
appear in a derivation. Another strategy is to remove more specific
clauses in the presence of more general ones by a process known as
<strong>subsumption</strong> (Robinson 1965a). Unrestricted
subsumption, however, does not preserve the refutation completeness of
resolution and, hence, there is a need to restrict its applicability
(Loveland 1978). <strong>Model elimination</strong> (Loveland 1969)
can discard a sentence by showing that it is false in some model of
the axioms. The subject of model generation has received much
attention as a complementary process to theorem proving. The method
has been used successfully by automated reasoning programs to show the
independence of axioms sets and to determine the existence of discrete
mathematical structures meeting some given criteria. </p>

<p>
Instead of removing redundant clauses, some strategies prevent the
generation of useless clauses in the first place. The
<strong>set-of-support strategy</strong> (Wos, Carson &amp; Robinson
1965) is one of the most powerful strategies of this kind. A subset
\(T\) of the set \(S\), where \(S\) is initially
\(\Gamma \cup \{{\sim}\alpha \}\), is called a <strong>set of support</strong>
of \(S\) iff \(S - T\) is satisfiable.
Set-of-support resolution dictates that the resolved clauses are not
both from \(S - T\). The motivation behind
set-of-support is that since the set \(\Gamma\) is usually satisfiable it
might be wise not to resolve two clauses from \(\Gamma\) against each
other. <strong>Hyperresolution</strong> (Robinson 1965b) reduces the
number of intermediate resolvents by combining several resolution
steps into a single inference step.</p>

<p>
Independently co-discovered, <strong>linear resolution</strong>
(Loveland 1970, Luckham 1970) always resolves a clause against the
most recently derived resolvent. This gives the deduction a simple
&ldquo;linear&rdquo; structure affording a straightforward
implementation; yet, linear resolution preserves refutation
completeness. Using linear resolution we can derive the empty clause
in the above example in only eight steps:</p>

<blockquote>

<table class="cellpad-med-dense centered">
<tr>
 <td>1&nbsp;</td>
 <td>\(P(x) \vee Q(x)\)</td>
 <td>Assumption</td> </tr>
<tr>
 <td>2</td>
 <td><em>\({\sim}\)P</em>\((x) \vee R(x)\)</td>
 <td>Assumption</td> </tr>
<tr>
 <td>3</td>
 <td><em>\({\sim}\)Q</em>\((x) \vee R(x)\)</td>
 <td>Assumption</td> </tr>
<tr>
 <td>4</td>
 <td>\({\sim}R(a)\)</td>
 <td>Negated conclusion</td> </tr>
<tr>
 <td>5</td>
 <td>\({\sim}P(a)\)</td>
 <td>Res 2 4</td> </tr>
<tr>
 <td>6</td>
 <td>\(Q(a)\)</td>
 <td>Res 1 5</td> </tr>
<tr>
 <td>7</td>
 <td>\(R(a)\)</td>
 <td>Res 3 6</td> </tr>
<tr>
 <td>8</td>
 <td>[&nbsp;]</td>
 <td>Res 4 7</td> </tr>
</table>
</blockquote>

<p>
With the exception of unrestricted subsumption, all the strategies
mentioned so far preserve refutation completeness. Efficiency is an
important consideration in automated reasoning and one may sometimes
be willing to trade completeness for speed. <strong>Unit
resolution</strong> and <strong>input resolution</strong> are two such
refinements of linear resolution. In the former, one of the resolved
clauses is always a literal; in the latter, one of the resolved
clauses is always selected from the original set to be refuted. Albeit
efficient, neither strategy is complete. Ordering strategies impose
some form of partial ordering on the predicate symbols, terms,
literals, or clauses occurring in the deduction. <strong>Ordered
resolution</strong> treats clauses not as sets of literals but as
sequences&mdash;linear orders&mdash;of literals. Ordered resolution is
extremely efficient but, like unit and input resolution, is not
refutation complete. To end, it must be noted that some strategies
improve certain aspects of the deduction process at the expense of
others. For instance, a strategy may reduce the size of the proof
search space at the expense of increasing, say, the length of the
shortest refutations. A taxonomy and detailed presentation of theorem-proving strategies can be found in Bonacina 1999; for a discussion of the relative complexity (i.e. efficiency measures) of resolution see Buresh-Oppenheim &amp; Pitassi 2003, and Urquhart 1987.</p>

<p>
There are several automated reasoning programs that are based on
resolution, or refinements of resolution. Otter (succeeded by Prover4)
was a driving force in the development of automated reasoning (Wos,
Overbeek, Lusk &amp; Boyle 1984) but it has been superseded by more
capable programs like Vampire (Voronkov 1995, Kov&aacute;cs &amp;
Voronkov 2013). Resolution also provides the underlying
logico-computational mechanism for the popular logic programming
language Prolog (Clocksin &amp; Mellish 1981).</p>

<h3><a name="SeqDed">2.2 Sequent Deduction</a></h3>

<p>
Hilbert-style calculi (Hilbert and Ackermann 1928) have been
traditionally used to characterize logic systems. These calculi
usually consist of a few axiom schemata and a small number of rules
that typically include modus ponens and the rule of substitution.
Although they meet the required theoretical requisites (soundness,
completeness, etc.) the approach at proof construction in these
calculi is difficult and does not reflect standard practice. It was
Gentzen&rsquo;s goal &ldquo;to set up a formalism that reflects as
accurately as possible the actual logical reasoning involved in
mathematical proofs&rdquo; (Gentzen 1935). To carry out this task,
Gentzen analyzed the proof-construction process and then devised two
deduction calculi for classical logic: the natural deduction calculus,
\(\mathbf{NK}\), and the sequent calculus, \(\mathbf{LK}\).
(Gentzen actually designed NK first and then introduced LK to pursue
metatheoretical investigations). The calculi met his goal to a large
extent while at the same time managing to secure soundness and
completeness. Both calculi are characterized by a relatively larger
number of deduction rules and a simple axiom schema. Of the two
calculi, LK is the one that has been most widely used in
implementations of automated reasoning programs, and it is the one
that we will discuss first; NK will be discussed in the next
section.</p>

<p>
Although the application of the LK rules affect logic formulas, the
rules are seen as manipulating not logic formulas themselves but
sequents. <strong>Sequents</strong> are expressions of the form
\(\Gamma \rightarrow \Delta\), where both \(\Gamma\) and \(\Delta\) are (possibly
empty) sets of formulas. \(\Gamma\) is the sequent&rsquo;s
<strong>antecedent</strong> and \(\Delta\) its
<strong>succedent</strong>. Sequents can be interpreted thus: Let
\(\mathcal{I}\) be an interpretation. Then,</p>

<blockquote>
\(\mathcal{I}\) satisfies the sequent \(\Gamma \rightarrow \Delta\) (written as: \(\mathcal{I} \vDash \Gamma \rightarrow \Delta)\) iff
<br />
either \(\mathcal{I} \not\vDash \alpha\) (for some
\(\alpha \in \Gamma)\) or \(\mathcal{I} \vDash \beta\) (for some \(\beta \in \Delta)\).
</blockquote>

<p>
In other words, </p>

<blockquote>
\(\mathcal{I} \vDash \Gamma \rightarrow \Delta\) iff
\(\mathcal{I} \vDash(\alpha_1~
\amp \ldots \amp ~\alpha_n) \supset 
(\beta_1 \vee \ldots \vee \beta_n)\),
where \(\alpha_1~ \amp \ldots \amp
~\alpha_n\) is the iterated conjunction of the
formulas in \(\Gamma\) and \(\beta_1 \vee \ldots \vee \beta_n\) is the iterated disjunction of those in
\(\Delta\).
</blockquote>

<p>
If \(\Gamma\) or \(\Delta\) are empty then they are respectively valid or
unsatisfiable. An <strong>axiom of LK</strong> is a sequent \(\Gamma \rightarrow \Delta\) where \(\Gamma \cap \Delta \ne \varnothing\). Thus, the
requirement that the same formula occurs at each side of the \(\rightarrow\)
sign means that the axioms of LK are valid, for no interpretation can
then make all the formulas in \(\Gamma\) true and, simultaneously, make
all those in \(\Delta\) false. LK has two rules per logical connective,
plus one extra rule: the cut rule. </p>

<table class="all-rules cellpad-small cell-center avoid-break centered smaller">
<tr>
<th colspan="2"> Axioms </th>
<th colspan="2"> Cut Rule </th> </tr>
<tr>
 <td colspan="2">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> &nbsp;&nbsp; </td> </tr>
<tr>
 <td style="padding:0px;"> \(\Gamma , \alpha \rightarrow \Delta , \alpha\)
</td> </tr>
</table> </td>
 <td colspan="2">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma \rightarrow \Delta ,
\alpha\) </td>
 <td style="border-bottom:1px solid black;"> \(\alpha , \lambda \rightarrow \Sigma\) </td> </tr>
<tr>
 <td colspan="2" style="padding:0px;"> \(\Gamma , \lambda \rightarrow \Delta , \Sigma\) </td> </tr>
</table> </td> </tr>
<tr>
<th colspan="2"> Antecedent Rules \((\Theta \rightarrow)\) </th>
<th colspan="2"> Succedent Rules \((\rightarrow \Theta)\) </th> </tr>
<tr>
 <td class="wid05">\(\amp\rightarrow\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma , \alpha , \beta \rightarrow \Delta\) </td> </tr>
<tr>
 <td style="padding:0px;"> \(\Gamma , \alpha \amp \beta \rightarrow \Delta\) </td> </tr>
</table> </td>
 <td class="wid05">\(\rightarrow\amp\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma \rightarrow \Delta ,
\alpha\) </td>
 <td style="border-bottom:1px solid black;"> \(\Gamma \rightarrow \Delta ,
\beta\) </td> </tr>
<tr>
 <td colspan="2" style="padding:0px;"> \(\Gamma \rightarrow \Delta ,
\alpha \amp \beta\) </td> </tr>
</table> </td> </tr>
<tr>
 <td class="wid05">\(\vee \rightarrow\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma , \alpha \rightarrow \Delta\) </td>
 <td style="border-bottom:1px solid black;"> \(\Gamma , \beta \rightarrow \Delta\) </td> </tr>
<tr>
 <td colspan="2" style="padding:0px;"> \(\Gamma , \alpha \vee \beta \rightarrow \Delta\) </td> </tr>
</table> </td>
 <td class="wid05">\(\rightarrow \vee\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma \rightarrow \Delta ,
\alpha , \beta\) </td> </tr>
<tr>
 <td style="padding:0px;"> \(\Gamma \rightarrow \Delta , \alpha \vee \beta\) </td> </tr>
</table> </td> </tr>
<tr>
 <td class="wid05">\(\supset \rightarrow\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma \rightarrow \Delta ,
\alpha\) </td>
 <td style="border-bottom:1px solid black;"> \(\Gamma , \beta \rightarrow \Delta\) </td> </tr>
<tr>
 <td colspan="2" style="padding:0px;"> \(\Gamma , \alpha \supset \beta \rightarrow \Delta\) </td> </tr>
</table> </td>
 <td class="wid05">\(\rightarrow \supset\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma , \alpha \rightarrow \Delta , \beta\) </td> </tr>
<tr>
 <td style="padding:0px;"> \(\Gamma \rightarrow \Delta , \alpha \supset \beta\) </td> </tr>
</table> </td> </tr>
<tr>
 <td class="wid05">\(\supset \equiv\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma , \alpha , \beta \rightarrow \Delta\) </td>
 <td style="border-bottom:1px solid black;"> \(\Gamma \rightarrow \Delta ,
\alpha , \beta\) </td> </tr>
<tr>
 <td colspan="2" style="padding:0px;"> \(\Gamma , \alpha \equiv \beta \rightarrow \Delta\) </td> </tr>
</table> </td>
 <td class="wid05">\(\equiv \supset\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma , \alpha \rightarrow \Delta , \beta\) </td>
 <td style="border-bottom:1px solid black;"> \(\Gamma , \beta , \rightarrow \Delta , \alpha\) </td> </tr>
<tr>
 <td colspan="2" style="padding:0px;"> \(\Gamma \rightarrow \Delta ,
\alpha \equiv \beta\) </td> </tr>
</table> </td> </tr>
<tr>
 <td class="wid05">\({\sim}\rightarrow\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma \rightarrow \Delta ,
\alpha\) </td> </tr>
<tr>
 <td style="padding:0px;"> \(\Gamma , {\sim}\alpha \rightarrow \Delta\) </td>
</tr>
</table> </td>
 <td class="wid05">\(\rightarrow{\sim}\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma , \alpha \rightarrow \Delta\) </td> </tr>
<tr>
 <td style="padding:0px;"> \(\Gamma \rightarrow \Delta , {\sim}\alpha\) </td>
</tr>
</table> </td> </tr>
<tr>
 <td class="wid05">\(\exists \rightarrow\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma ,
\alpha(a/x) \rightarrow \Delta\) </td> </tr>
<tr>
 <td style="padding:0px;"> \(\Gamma ,
\exists x\alpha(x) \rightarrow \Delta\) </td> </tr>
</table> </td>
 <td class="wid05">\(\rightarrow \exists\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma \rightarrow \Delta ,
\alpha(t/x), \exists x\alpha(x)\)
</td> </tr>
<tr>
 <td style="padding:0px;"> \(\Gamma \rightarrow \Delta ,
\exists x\alpha(x)\) </td> </tr>
</table> </td> </tr>
<tr>
 <td class="wid05">\(\forall \rightarrow\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma ,
\alpha(t/x), \forall x\alpha(x)
\rightarrow \Delta\) </td> </tr>
<tr>
 <td style="padding:0px;"> \(\Gamma ,
\forall x\alpha(x) \rightarrow \Delta\) </td> </tr>
</table> </td>
 <td class="wid05">\(\rightarrow \forall\)</td>
 <td class="wid40">

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma \rightarrow \Delta ,
\alpha(a/x)\) </td> </tr>
<tr>
 <td style="padding:0px;"> \(\Gamma \rightarrow \Delta ,
\forall x\alpha(x)\) </td> </tr>
</table> </td> </tr>
</table>

<p>
The sequents above a rule&rsquo;s line are called the <strong>rule&rsquo;s
premises</strong> and the sequent below the line is the <strong>rule&rsquo;s
conclusion</strong>. The quantification rules \(\exists \rightarrow\) and
\(\rightarrow \forall\) have an eigenvariable condition that restricts their
applicability, namely that \(a\) must not occur in \(\Gamma ,
\Delta\) or in the quantified sentence. The purpose of this restriction
is to ensure that the choice of parameter, \(a\), used in the
substitution process is completely &ldquo;arbitrary&rdquo;.</p>

<p>
Proofs in LK are represented as trees where each node in the tree is
labeled with a sequent, and where the original sequent sits at the
root of the tree. The children of a node are the premises of the rule
being applied at that node. The leaves of the tree are labeled with
axioms. Here is the LK-proof of
\(\exists xR(x)\) from the set
\(\{\forall x(P(x) \vee Q(x)), \forall x(P(x)
\supset R(x)),\forall x(Q(x)
\supset R(x))\}\). In the tree below, \(\Gamma\) stands for
this set:</p>

<!--pdf include <small> pdf include-->

<table class="centered cellpad-med-dense centercell smaller">
<tr>
 <td style="border-bottom:1px solid black;">

<table class="cellpad-med-dense" style="margin-bottom:0px;">
<tr>
 <td style="border-bottom:1px solid black;">
\(\Gamma ,P(a) \rightarrow\)

<!--pdf include <br/>
pdf include-->
\(P(a),R(a),\exists xR(x)\)
</td>
 <td style="border-bottom:1px solid black;">
\(\Gamma ,P(a),R(a) \rightarrow\)

<!--pdf include <br/>
pdf include-->
\(R(a),\exists xR(x)\) </td>
</tr>
<tr>
 <td colspan="2" style="border-bottom:1px solid black;">
\(\Gamma ,P(a),P(a) \supset R(a) \rightarrow R(a),\exists xR(x)\) </td>
</tr>
<tr>
 <td colspan="2"> \(\Gamma ,P(a) \rightarrow R(a),\exists xR(x)\) </td>
</tr>
</table> </td>
 <td style="border-bottom:1px solid black;">

<table class="cellpad-med-dense" style="border-spacing:0px; margin-bottom:0px;">
<tr>
 <td style="border-bottom:1px solid black;">
\(\Gamma ,Q(a) \rightarrow\)

<!--pdf include <br/>
pdf include-->
\(Q(a),R(a),\exists xR(x)\)
</td>
 <td style="border-bottom:1px solid black;">
\(\Gamma ,Q(a),R(a) \rightarrow\)

<!--pdf include <br/>
pdf include-->
\(R(a),\exists xR(x)\) </td>
</tr>
<tr>
 <td colspan="2" style="border-bottom:1px solid black;">
\(\Gamma ,Q(a),Q(a) \supset R(a) \rightarrow R(a),\exists xR(x)\) </td>
</tr>
<tr>
 <td colspan="2"> \(\Gamma ,Q(a) \rightarrow R(a),\exists xR(x)\) </td>
</tr>
</table> </td> </tr>
<tr>
 <td colspan="2">

<table class="centered cellpad-med-dense centercell">
<tr>
 <td style="border-bottom:1px solid black;">
\(\Gamma ,P(a) \vee Q(a) \rightarrow R(a),\exists xR(x)\) </td>
</tr>
<tr>
 <td style="border-bottom:1px solid black;"> \(\Gamma \rightarrow R(a),\exists xR(x)\) </td>
</tr>
<tr>
 <td> \(\Gamma \rightarrow \exists xR(x)\) </td>
</tr>
</table> </td> </tr>
</table>

<!--pdf include </small> pdf include-->

<p>
In our example, all the leaves in the proof tree are labeled with
axioms. This establishes the validity of \(\Gamma \rightarrow \exists xR(x)\) and, hence, the fact that
\(\Gamma \vDash \exists xR(x)\). LK
takes an indirect approach at proving the conclusion and this is an
important difference between LK and NK. While NK constructs an actual
proof (of the conclusion from the given assumptions), LK instead
constructs a proof that proves the existence of a proof (of the
conclusion from the assumptions). For instance, to prove that \(\alpha\)
is entailed by \(\Gamma\), NK constructs a step-by-step proof of \(\alpha\)
from \(\Gamma\) (assuming that one exists); in contrast, LK first
constructs the sequent \(\Gamma \rightarrow \alpha\) which then attempts to
prove valid by showing that it cannot be made false. This is done by
searching for a counterexample that makes (all the sentences in)
\(\Gamma\) true and makes \(\alpha\) false: If the search fails then a
counterexample does not exist and the sequent is therefore valid. In
this respect, proof trees in LK are actually refutation proofs. Like
resolution, LK is refutation complete: If
\(\Gamma \vDash \alpha\) then the sequent \(\Gamma \rightarrow \alpha\) has a proof tree.</p>

<p>
As it stands, LK is unsuitable for automated deduction and there are
some obstacles that must be overcome before it can be efficiently
implemented. The reason is, of course, that the statement of the
completeness of LK only has to assert, for each entailment relation,
the existence of a proof tree but a reasoning program has the more
difficult task of actually having to construct one. Some of the main
obstacles: First, LK does not specify the order in which the rules
must be applied in the construction of a proof tree. Second, and as a
particular case of the first problem, the premises in the rules
\(\forall \rightarrow\) and \(\rightarrow \exists\) rules inherit the quantificational
formula to which the rule is applied, meaning that the rules can be
applied repeatedly to the same formula sending the proof search into
an endless loop. Third, LK does not indicate which formula must be
selected next in the application of a rule. Fourth, the quantifier
rules provide no indication as to what terms or free variables must be
used in their deployment. Fifth, and as a particular case of the
previous problem, the application of a quantifier rule can lead into
an infinitely long tree branch because the proper term to be used in
the instantiation never gets chosen. Fortunately, as we will hint at
below each of these problems can be successfully addressed.</p>

<p>
Axiom sequents in LK are valid, and the conclusion of a rule is valid
iff its premises are. This fact allows us to apply the LK rules in
either direction, forwards from axioms to conclusion, or backwards
from conclusion to axioms. Also, with the exception of the cut rule,
all the rules&rsquo; premises are subformulas of their respective
conclusions. For the purposes of automated deduction this is a
significant fact and we would want to dispense with the cut rule;
fortunately, the cut-free version of LK preserves its refutation
completeness (Gentzen 1935). These results provide a strong case for
constructing proof trees in a backwards fashion; indeed, by working
this way a refutation in cut-free LK gets increasingly simpler as it
progresses since subformulas are simpler than their parent formulas.
Moreover, and as far as propositional rules go, the new subformulas
entered into the tree are completely dictated by the cut-free LK
rules. Furthermore, and assuming the proof tree can be brought to
completion, branches eventually end up with atoms and the presence of
axioms can be quickly determined. Another reason for working backwards
is that the truth-functional fragment of cut-free LK is
<strong>confluent</strong> in the sense that the order in which the
non-quantifier rules are applied is irrelevant: If there is a proof,
regardless of what you do, you will run into it! To bring the
quantifier rules into the picture, things can be arranged so that all
rules have a fair chance of being deployed: Apply, as far as possible,
all the non-quantifier rules before applying any of the quantifier
rules. This takes care of the first and second obstacles, and it is no
too difficult to see how the third one would now be handled. The
fourth and fifth obstacles can be addressed by requiring that the
terms to be used in the substitutions be suitably selected from the
Herbrand universe (Herbrand 1930).</p>

<p>
The use of sequent-type calculi in automated theorem proving was
initiated by efforts to mechanize mathematics (Wang 1960). At the
time, resolution captured most of the attention of the automated
reasoning community but during the 1970s some researchers started to
further investigate non-resolution methods (Bledsoe 1977), prompting a
frutiful and sustained effort to develop more human-oriented theorem
proving systems (Bledsoe 1975, Nevins 1974). Eventually, sequent-type
deduction gained momentum again, particularly in its re-incarnation as
<strong>analytic tableaux</strong> (Fitting 1990). The method of
deduction used in tableaux is essentially cut-free LK&rsquo;s with sets used
in lieu of sequents.</p>

<h3><a name="NatDed">2.3 Natural Deduction</a></h3>

<p>
Although LK and NK are both commonly labeled as &ldquo;natural
deduction&rdquo; systems, it is the latter which better deserves the
title due to its more natural, human-like, approach to proof
construction. The rules of NK are typically presented as acting on
standard logic formulas in an implicitly understood context, but they
are also commonly given in the literature as acting more explicitly on
&ldquo;judgements&rdquo;, that is, expressions of the form
\(\Gamma \vdash \alpha\) where \(\Gamma\) is a set of formulas
and \(\alpha\) is a formula. This form is typically understood as making
the metastatement that there is a proof of \(\alpha\) from \(\Gamma\)
(Kleene 1962). Following Gentzen 1935 and Prawitz 1965 here we take
the former approach. The system NK has no logical axioms and provides
two introduction-elimination rules for each logical connective:</p>

<table class="all-rules cellpad-small cell-center avoid-break centered">
<tr>
<th colspan="2"> Introduction Rules \((\Theta \mathbf{I})\)</th>
<th colspan="2"> Elimination Rules \((\Theta \mathbf{E})\)</th>
</tr>
<tr>
 <td>\(\amp\)I</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="padding:0px;border-bottom:1px solid black; text-align:center;">
\(\alpha\) </td>
 <td style="padding:0px;border-bottom:1px solid black; text-align:center;">
\(\beta\) </td> </tr>
<tr>
 <td style="padding:0px; text-align:center;" colspan="2"> \(\alpha \amp \beta\) </td> </tr>
</table> </td>
 <td>\(\amp\)E</td>
 <td>

<table class="no-rules centered" style="border-spacing:0px;">
<tr>
 <td style="padding:0px;border-bottom:1px solid black; text-align:center;">
\(\alpha_1 \amp \alpha_2\)
</td> </tr>
<tr>
 <td style="padding:0px; text-align:center;">
\(\alpha_i\) (for \(i = 1,2)\) </td> </tr>
</table> </td> </tr>
<tr>
 <td>\(\vee\)I</td>
 <td>

<table class="no-rules centered" style="border-spacing:0px;">
<tr>
 <td style="padding:0px;border-bottom:1px solid black; text-align:center;">
\(\alpha_i\) (for \(i =
1,2)\) </td> </tr>
<tr>
 <td> \(\alpha_1 \vee \alpha_2\) </td> </tr>
</table> </td>
 <td>\(\vee\)E</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black; text-align:center;">
\(\alpha \vee \beta\) </td>
 <td style="border-bottom:1px solid black; text-align:center;">
[\(\alpha\) &mdash; \(\gamma\)] </td>
 <td style="border-bottom:1px solid black; text-align:center;">
[\(\beta\) &mdash; \(\gamma\)] </td> </tr>
<tr>
 <td style="padding:0px; text-align:center;" colspan="3"> \(\gamma\)
</td> </tr>
</table> </td> </tr>
<tr>
 <td>\(\supset\)I</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="padding:0px;border-bottom:1px solid black; text-align:center;">
[\(\alpha\) &mdash; \(\beta\)] </td> </tr>
<tr>
 <td style="padding:0px; text-align:center;"> \(\alpha \supset \beta\)
</td> </tr>
</table> </td>
 <td>\(\supset\)E</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black; text-align:center;">
\(\alpha\) </td>
 <td style="border-bottom:1px solid black; text-align:center;">
\(\alpha \supset \beta\) </td> </tr>
<tr>
 <td colspan="2"> \(\beta\) </td> </tr>
</table> </td> </tr>
<tr>
 <td>\(\equiv\)I</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black; text-align:center;">
[\(\alpha\) &mdash; \(\beta\)] </td>
 <td style="border-bottom:1px solid black; text-align:center;">
[\(\beta\) &mdash; \(\alpha\)] </td> </tr>
<tr>
 <td colspan="2"> \(\alpha \equiv \beta\) </td> </tr>
</table> </td>
 <td>\(\equiv\)E</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black; text-align:center;">
\(\alpha_i (i = 0,1)\) </td>
 <td style="border-bottom:1px solid black; text-align:center;">
\(\alpha_0 \equiv \alpha_1\) </td> </tr>
<tr>
 <td colspan="2"> \(\alpha_{1-i}\) </td> </tr>
</table> </td> </tr>
<tr>
 <td>\({\sim}\)I</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="padding:0px;border-bottom:1px solid black; text-align:center;">
[\(\alpha\) &mdash; \(\bot\)] </td> </tr>
<tr>
 <td style="padding:0px; text-align:center;"> \({\sim}\alpha\) </td> </tr>
</table> </td>
 <td>\({\sim}\)E</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="padding:0px;border-bottom:1px solid black; text-align:center;">
[\({\sim}\alpha\) &mdash; \(\bot\)] </td> </tr>
<tr>
 <td style="padding:0px; text-align:center;"> \(\alpha\) </td> </tr>
</table> </td> </tr>
<tr>
 <td>\(\exists\)I</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="padding:0px;border-bottom:1px solid black; text-align:center;">
\(\alpha(t/x)\) </td> </tr>
<tr>
 <td style="padding:0px; text-align:center;">
\(\exists x\alpha(x)\) </td> </tr>
</table> </td>
 <td>\(\exists\)E</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="border-bottom:1px solid black; text-align:center;">
\(\exists x\alpha(x)\) </td>
 <td style="border-bottom:1px solid black; text-align:center;">
[\(\alpha(a/x)\) &mdash; \(\beta\)] </td> </tr>
<tr>
 <td colspan="2"> \(\beta\) </td> </tr>
</table> </td> </tr>
<tr>
 <td>\(\forall\)I</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="padding:0px;border-bottom:1px solid black; text-align:center;">
\(\alpha(a/x)\) </td> </tr>
<tr>
 <td style="padding:0px; text-align:center;">
\(\forall x\alpha(x)\) </td> </tr>
</table> </td>
 <td>\(\forall\)E</td>
 <td>

<table class="no-rules cellpad-med-dense centered">
<tr>
 <td style="padding:0px;border-bottom:1px solid black; text-align:center;">
\(\forall x\alpha(x)\) </td> </tr>
<tr>
 <td style="padding:0px; text-align:center;">
\(\alpha(t/x)\) </td> </tr>
</table> </td> </tr>
</table>

<p>
A few remarks: First, the expression
[\(\alpha\)&mdash;\( \gamma\)] represents the fact that \(\alpha\)
is an auxiliary assumption in the proof of \(\gamma\) that eventually
gets discharged, i.e. discarded. For example, \(\exists\)E tells us that
if in the process of constructing a proof one has already derived
\(\exists x\alpha(x)\) and also \(\beta\) with
\(\alpha(a/x)\) as an auxiliary assumption then the
inference to \(\beta\) is allowed. Second, the eigenparameter,
\(a\), in \(\exists\)E and \(\forall\)I must be foreign to the premises,
undischarged&mdash;&ldquo;active&rdquo;&mdash;assumptions, to the
rule&rsquo;s conclusion and, in the case of \(\exists\)E, to
\(\exists x\alpha(x)\). Third, \(\bot\) is shorthand for
two contradictory formulas, \(\beta\) and \({\sim}\beta\). Finally, NK is
complete: If \(\Gamma \vDash \alpha\) then there is a
proof of \(\alpha\) from \(\Gamma\) using the rules of NK.</p>

<p>
As in LK, proofs constructed in NK are represented as trees with the
proof&rsquo;s conclusion sitting at the root of the tree, and the problem&rsquo;s
assumptions sitting at the leaves. (Proofs are also typically given as
sequences of judgements, \(\Gamma \vdash \alpha\), running
from the top to the bottom of the printed page.) Here is a natural
deduction proof tree of \(\exists xR(x)\) from
\(\forall x(P(x) \vee Q(x)), \forall x(P(x)
\supset R(x))\) and
\(\forall x(Q(x) \supset R(x))\):</p>

<!--pdf include <small> pdf include-->

<table class="centered cellpad-med-dense centercell smaller">
<tr>
 <td style="border-bottom:1px solid black; vertical-align:bottom;">

<table class="cellpad-med-dense" style="margin-bottom:0px;">
<tr>
 <td style="border-bottom:1px solid black;">
\(\forall x(P(x)\vee Q(x))\)
</td> </tr>
<tr>
 <td> \(P(a)\vee Q(a)\) </td> </tr>
</table> </td>
 <td style="border-bottom:1px solid black; vertical-align:bottom;">

<table class="cellpad-med-dense" style="margin-bottom:0px;">
<tr style="vertical-align:bottom;">
 <td style="border-bottom:1px solid black;">

<table class="cellpad-med-dense" style="margin-bottom:0px;">
<tr>
 <td style="border-bottom:1px solid black;">
\(\forall x(P(x)\supset R(x))\)
</td> </tr>
<tr>
 <td> \(P(a)\supset R(a)\) </td> </tr>
</table> </td>
 <td style="border-bottom:1px solid black;">
[\(P(a)\)&mdash;\(R(a)\)] </td> </tr>
<tr>
 <td colspan="2"> \(R(a)\) </td> </tr>
</table> </td>
 <td style="border-bottom:1px solid black;vertical-align:bottom;">

<table class="cellpad-med-dense" style="margin-bottom:0px;">
<tr style="vertical-align:bottom;">
 <td style="border-bottom:1px solid black;">

<table class="cellpad-med-dense" style="margin-bottom:0px;">
<tr>
 <td style="border-bottom:1px solid black;">
\(\forall x(Q(x)\supset R(x))\)
</td> </tr>
<tr>
 <td> \(Q(a)\supset R(a)\) </td> </tr>
</table> </td>
 <td style="border-bottom:1px solid black;">
[\(Q(a)\)&mdash;\(R(a)\)]</td> </tr>
<tr>
 <td colspan="2"> \(R(a)\) </td> </tr>
</table> </td> </tr>
<tr>
 <td colspan="3">
  <table class="centered cell-center" style="margin-bottom:0px">
    <tr><td style="border-bottom:1px solid black;">\(R(a)\)</td></tr>
    <tr><td>\(\exists xR(x)\) </td></tr>
  </table>
</td></tr>
</table>

<!--pdf include </small> pdf include-->

<p>
As in LK, a forward-chaining strategy for proof construction is not
well focused. So, although proofs are <em>read</em> forwards, that is,
from leaves to root or, logically speaking, from assumptions to
conclusion, that is not the way in which they are typically
<em>constructed</em>. A backward-chaining strategy implemented by
applying the rules in reverse order is more effective. Many of the
obstacles that were discussed above in the implementation of sequent
deduction are applicable to natural deduction as well. These issues
can be handled in a similar way, but natural deduction introduces some
issues of its own. For example, as suggested by the \(\supset\)-Introduction
rule, to prove a goal of the form \(\alpha \supset \beta\) one could
attempt to prove \(\beta\) on the assumption that \(\alpha\). But note that
although the goal \(\alpha \supset \beta\) does not match the conclusion
of any other introduction rule, it matches the conclusion of all
<em>elimination</em> rules and the reasoning program would need to
consider those routes too. Similarly to forward-chaining, here there
is the risk of setting goals that are irrelevant to the proof and that
could lead the program astray. To wit: What prevents a program from
entering the never-ending process of building, say, larger and larger
conjunctions? Or, what is there to prevent an uncontrolled chain of
backward applications of, say, \(\supset\)-Elimination? Fortunately, NK
enjoys the <strong>subformula property</strong> in the sense that each
formula entering into a natural deduction proof can be restricted to
being a subformula of \(\Gamma \cup \Delta \cup \{\alpha \}\), where
\(\Delta\) is the set of auxiliary assumptions made by the \({\sim}\)-Elimination
rule. By exploiting the subformula property a natural deduction
automated theorem prover can drastically reduce its search space and
bring the backward application of the elimination rules under control
(Portoraro 1998, Sieg &amp; Byrnes 1996). Further gains can be realized
if one is willing to restrict the scope of NK&rsquo;s logic to its
intuitionistic fragment where every proof has a normal form in the
sense that no formula is obtained by an introduction rule and then is
eliminated by an elimination rule (Prawitz 1965).</p>

<p>
Implementations of automated theorem proving systems using NK
deduction have been motivated by the desire to have the program reason
with precisely the same proof format and methods employed by the human
user. This has been particularly true in the area of education where
the student is engaged in the interactive construction of formal
proofs in an NK-like calculus working under the guidance of a theorem
prover ready to provide assistance when needed (Portoraro 1994, Suppes
1981). Other, research-oriented, theorem provers true to the spirit of
NK exist (Pelletier 1998) but are rare.</p>

<h3><a name="MatConMet">2.4 The Matrix Connection Method</a></h3>

<p>
The name of the matrix connection method (Bibel 1981) is indicative of
the way it operates. The term &ldquo;matrix&rdquo; refers to the form
in which the set of logic formulas expressing the problem is
represented; the term &ldquo;connection&rdquo; refers to the way the
method operates on these formulas. To illustrate the method at work,
we will use an example from propositional logic and show that
\(R\) is entailed by \(P \vee Q, P \supset R\) and \(Q \supset R\). This is done by
establishing that the formula</p>

\[(P \vee Q) \amp(P \supset R) \amp(Q \supset R) \amp{\sim}R\]


<p>
is unsatisfiable. To do this, we begin by transforming it into
conjunctive normal form: </p>


\[(P \vee Q) \amp({\sim}P \vee R) \amp({\sim}Q \vee R) \amp{\sim}R\]


<p>
This formula is then represented as a matrix, one conjunct per row
and, within a row, one disjunct per column:</p>

<table class="all-rules cellpad-small indent centercell centered">
<tr>
 <td>\(P\)</td>
 <td>\( Q\)</td> </tr>
<tr>
 <td>\({\sim}P\)</td>
 <td>\(R\)</td> </tr>
<tr>
 <td>\({\sim}Q\)</td>
 <td>\(R\)</td> </tr>
<tr>
 <td>\({\sim}R\)</td>
 <td>&nbsp;</td> </tr>
</table>

<p>
The idea now is to explore all the possible vertical paths running
through this matrix. A <strong>vertical path</strong> is a set of
literals selected from each row in the matrix such that each literal
comes from a different row. The vertical paths:</p>

<table class="all-rules cellpad-small indent avoid-break centered">
<tr>
 <td><em>Path 1</em></td>
 <td>\(P, {\sim}P, {\sim}Q\) and \({\sim}R\)</td> </tr>
<tr>
 <td><em>Path 2</em></td>
 <td>\(P, {\sim}P, R\) and \({\sim}R\)</td> </tr>
<tr>
 <td><em>Path 3</em></td>
 <td>\(P, R, {\sim}Q\) and \({\sim}R\)</td> </tr>
<tr>
 <td><em>Path 4</em></td>
 <td>\(P, R, R\) and \({\sim}R\)</td> </tr>
<tr>
 <td><em>Path 5</em></td>
 <td>\(Q, {\sim}P, {\sim}Q\) and \({\sim}R\)</td> </tr>
<tr>
 <td><em>Path 6</em></td>
 <td>\(Q, {\sim}P, R\) and \({\sim}R\)</td> </tr>
<tr>
 <td><em>Path 7</em></td>
 <td>\(Q, R, {\sim}Q\) and \({\sim}R\)</td> </tr>
<tr>
 <td><em>Path 8</em></td>
 <td>\(Q, R, R\) and \({\sim}R\)</td> </tr>
</table>

<p>
A path is <strong>complementary</strong> if it contains two literals
which are complementary. For example, Path 2 is complementary since it
has both \(P\) and \({\sim}P\) but so is Path 6 since it contains
both \(R\) and \({\sim}R\). Note that as soon as a path includes
two complementary literals there is no point in pursuing the path
since it has itself become complementary. This typically allows for a
large reduction in the number of paths to be inspected. In any event,
all the paths in the above matrix are complementary and this fact
establishes the unsatisfiability of the original formula. This is the
essence of the matrix connection method. The method can be extended to
predicate logic but this demands additional logical apparatus:
Skolemnization, variable renaming, quantifier duplication,
complementarity of paths via unification, and simultaneous
substitution across all matrix paths (Bibel 1981, Andrews 1981).
Variations of the method have been implemented in reasoning programs
in higher-order logic (Andrews 1981) and non-classical logics (Wallen
1990).</p>

<h3><a name="TerRew">2.5 Term Rewriting</a></h3>

<p>
Equality is an important logical relation whose behavior within
automated deduction deserves its own separate treatment.
<strong>Equational logic</strong> and, more generally, <strong>term
rewriting</strong> treat equality-like equations as <strong>rewrite
rules</strong>, also known as <strong>reduction</strong> or
<strong>demodulation rules</strong>. An equality statement like
\(f(a)= a\) allows the simplification of a term
like \(g(c,f(a))\) to
\(g(c,a)\). However, the same equation also has
the potential to generate an unboundedly large term:
\(g(c,f(a)),
g(c,f(f(a))),
g(c,f(f(f(a)))),\ldots\) . What distinguishes term rewriting from equational logic is
that in term rewriting equations are used as unidirectional reduction
rules as opposed to equality which works in both directions. Rewrite
rules have the form \(t_1 \Rightarrow t_2\) and the basic idea is to look for terms
\(t\) occurring in expressions \(e\) such that \(t\)
unifies with \(t_1\) with unifier \(\theta\) so that the
occurrence \(t_1\theta\) in \(e\theta\) can be
replaced by \(t_2\theta\). For example, the rewrite
rule \(x + 0 \Rightarrow x\) allows the rewriting of
<em>succ</em>(<em>succ</em>(0) \(+ 0)\) as
<em>succ</em>(<em>succ</em>(0)).</p>

<p>
To illustrate the main ideas in term rewriting, let us explore an
example involving symbolic differentiation (the example and ensuing
discussion are adapted from Chapter 1 of Baader &amp; Nipkow 1998). Let
<em>der</em> denote the derivative respect to \(x\), let
\(y\) be a variable different from \(x\), and let \(u\)
and \(v\) be variables ranging over expressions. We define the
rewrite system:</p>

\[\begin{align}
\tag{R1} \der(x) &amp; \Rightarrow 1\\
\tag{R2} \der(y) &amp; \Rightarrow 0\\
\tag{R3} \der(u+v) &amp; \Rightarrow \der(u) + \der(v)\\
\tag{R4} \der( u \times v) &amp; \Rightarrow (u \times \der(v)) + (\der(u) \times v)
\end{align}\]

<p>
Again, the symbol \(\Rightarrow\) indicates that a term matching the left-hand
side of a rewrite rule should be replaced by the rule&rsquo;s right-hand
side. To see the differentiation system at work, let us compute the
derivative of \(x \times x\) respect to \(x\),
\(\der(x \times x)\):</p>

<table class="indent centered">
<tr>
 <td>\(\der(x \times x)\)</td>
 <td>\(\Rightarrow\)</td>
 <td>\((x \times \der(x)) +
(\der(x) \times x)\)</td>
 <td>&nbsp;</td>
 <td>by R4</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>\(\Rightarrow\)</td>
 <td>\((x \times 1) + (\der(x) \times x)\)</td>
 <td>&nbsp;</td>
 <td>by R1</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>\(\Rightarrow\)</td>
 <td>\((x \times 1) + (1 \times x)\)</td>
 <td>&nbsp;</td>
 <td>by R1</td> </tr>
</table>

<p>
At this point, since none of the rules (R1)&ndash;(R4) applies, no
further reduction is possible and the rewriting process ends. The
final expression obtained is called a <strong>normal form</strong>,
and its existence motivates the following question: Is there an
expression whose reduction process will never terminate when applying
the rules (R1)&ndash;(R4)? Or, more generally: Under what conditions a
set of rewrite rules will always stop, for any given expression, at a
normal form after finitely many applications of the rules? This
fundamental question is called the <strong>termination</strong>
problem of a rewrite system, and we state without proof that the
system (R1)&ndash;(R4) meets the termination condition.</p>

<p>
There is the possibility that when reducing an expression, the set of
rules of a rewrite system could be applied in more than one way. This
is actually the case in the system (R1)&ndash;(R4) where in the
reduction of \(\der(x \times x)\) we could have
applied R1 first to the second sub-expression in \((x \times\)
\(\der(x)) + \der(x) \times x)\), as shown below:</p>

<table class="indent centered">
<tr>
 <td>\(\der(x \times x)\)</td>
 <td>\(\Rightarrow\)</td>
 <td>\((x \times \der(x)) +
(\der(x) \times x)\)</td>
 <td>&nbsp;</td>
 <td>by R4</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>\(\Rightarrow\)</td>
 <td>\((x \times \der(x)) + (1 \times x)\)</td>
 <td>&nbsp;</td>
 <td>by R1</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>\(\Rightarrow\)</td>
 <td>\((x \times 1) + (1 \times x)\)</td>
 <td>&nbsp;</td>
 <td>by R1</td> </tr>
</table>

<p>
Following this alternative course of action, the reduction terminates
with the same normal form as in the previous case. This fact, however,
should not be taken for granted: A rewriting system is said to be
<strong>(globally) confluent</strong> if and only if independently of
the order in which its rules are applied every expression always ends
up being reduced to its one and only normal form. It can be shown that
(R1)&ndash;(R4) is confluent and, hence, we are entitled to say:
&ldquo;Compute <em>the</em> derivative of an expression&rdquo; (as
opposed to simply &ldquo;\(a\)&rdquo; derivative). Adding more
rules to a system in an effort to make it more practical can have
undesired consequences. For example, if we add the rule</p>


\[\tag{R5} u+0\Rightarrow u\]

<p>
to (R1)&ndash;(R4) then we will be able to further reduce certain
expressions but at the price of losing confluency. The following
reductions show that \(\der(x + 0)\) now has two normal
forms: the computation</p>

<table class="indent centered">
<tr>
 <td>\(\der(x + 0)\)</td>
 <td>\(\Rightarrow\)</td>
 <td>\(\der(x) + \der(0)\)</td>
 <td>&nbsp;</td>
 <td>by R3</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>\(\Rightarrow\)</td>
 <td>\(1 + \der(0)\)</td>
 <td>&nbsp;</td>
 <td>by R1</td> </tr>
</table>

<p>
gives one normal form, and</p>

<table class="indent centered">
<tr>
 <td>\(\der(x + 0)\)</td>
 <td>\(\Rightarrow\)</td>
 <td>\(\der(x)\)</td>
 <td>&nbsp;</td>
 <td>by R5</td> </tr>
<tr>
 <td>&nbsp;</td>
 <td>\(\Rightarrow\)</td>
 <td>1</td>
 <td>&nbsp;</td>
 <td>by R1</td> </tr>
</table>

<p>
gives another. Adding the rule</p>

\[\tag{R6} \der(0) \Rightarrow 0\]

<p>
would allow the further reduction of \(1 + \der(0)\) to \(1 + 0\) and
then, by R5, to 1. Although the presence of this new rule actually
increases the number of alternative
paths&mdash;\(\der(x + 0)\) can now be reduced in four
possible ways&mdash;they all end up with the same normal form, namely
1. This is no coincidence as it can be shown that (R6) actually
restores confluency. This motivates another fundamental question:
Under what conditions can a non-confluent system be made into an
equivalent confluent one? The Knuth-Bendix <strong>completion</strong>
algorithm (Knuth &amp; Bendix 1970) gives a partial answer to this
question.</p>

<p>
Term rewriting, like any other automated deduction method, needs
strategies to direct its application. Rippling (Bundy, Stevens &amp;
Harmelen 1993, Basin &amp; Walsh 1996) is a heuristic that has its
origins in inductive theorem-proving that uses annotations to
selectively restrict the rewriting process. The <strong>superposition calculus</strong>
is a calculus of equational first-order logic that combines notions
from first-order resolution and Knuth-Bendix ordering equality.
Superposition is refutation complete (Bachmair &amp; Ganzinger 1994) and
is at the heart of a number of theorem provers, most notably the E
equational theorem prover (Schulz 2004) and Vampire (Voronkov
1995). Superposition has been extended to higher-order logic (Bentkamp <em>et al</em>. 2021).</p>

<h3><a name="MatInd">2.6 Mathematical Induction</a></h3>

<p>
Mathematical induction is a very important technique of theorem
proving in mathematics and computer science. Problems stated in terms
of objects or structures that involve recursive definitions or some
form of repetition invariably require mathematical induction for their
solving. In particular, reasoning about the correctness of computer
systems requires induction and an automated reasoning program that
effectively implements induction will have important applications.</p>

<p>
To illustrate the need for mathematical induction, assume that a
property \(\phi\) is true of the number zero and also that if true of a
number then is true of its successor. Then, with our deductive
systems, we can deduce that for any given number \(n, \phi\) is
true of it, \(\phi(n)\). But we cannot deduce that \(\phi\) is true
of all numbers, \(\forall x\phi(x)\); this inference
step requires the rule of mathematical induction:</p>

\[\tag{mathematical induction}\frac{\alpha(0)\quad \quad [\alpha(n)-\alpha(\textit{succ}(n))]}{\forall x \alpha(x)}\]

<p>
In other words, to prove that \(\forall x\alpha(x)\)
one proves that \(\alpha(0)\) is the case, and that
\(\alpha(succ(n))\) follows from the assumption that
\(\alpha(n)\). The implementation of induction in a reasoning
system presents very challenging search control problems. The most
important of these is the ability to determine the particular way in
which induction will be applied during the proof, that is, finding the
appropriate induction schema. Related issues include selecting the
proper variable of induction, and recognizing all the possible cases
for the base and the inductive steps.</p>

<p>
Nqthm (Boyer &amp; Moore 1979) has been one of the most successful
implementations of automated inductive theorem proving. In the spirit
of Gentzen, Boyer and Moore were interested in how people prove
theorems by induction. Their theorem prover is written in the
functional programming language Lisp which is also the language in
which theorems are represented. For instance, to express the
commutativity of addition the user would enter the Lisp expression
<span class="fw">(EQUAL (PLUS X Y) (PLUS Y X))</span>. Everything
defined in the system is a functional term, including its basic
&ldquo;predicates&rdquo;: <span class="fw">T</span>, <span class="fw">F</span>,
<span class="fw">EQUAL X Y</span>, <span class="fw">IF
X Y Z</span>, <span class="fw">AND</span>, <span class="fw">NOT</span>,
etc. The program operates largely as a black
box, that is, the inner working details are hidden from the user;
proofs are conducted by rewriting terms that posses recursive
definitions, ultimately reducing the conclusion&rsquo;s statement to the
<span class="fw">T</span> predicate. The Boyer-Moore theorem prover
has been used to check the proofs of some quite deep theorems (Boyer,
Kaufmann &amp; Moore 1995). Lemma caching, problem statement
generalization, and proof planning are techniques particularly useful
in inductive theorem proving (Bundy, Harmelen &amp; Hesketh 1991).</p>

<h2><a name="OthLog">3. Other Logics</a></h2>

<h3><a name="HigOrdLog">3.1 Higher-Order Logic</a></h3>

<p>
Higher-order logic differs from first-order logic in that
quantification over functions and predicates is allowed. The statement
&ldquo;<em>Any two people are related to each other in one way or
another</em>&rdquo; can be legally expressed in higher-order logic as
\(\forall x\forall y\exists RR(x,y)\)
but not in first-order logic. Higher-order logic is inherently more
expressive than first-order logic and is closer in spirit to actual
mathematical reasoning. For example, the notion of set finiteness
cannot be expressed as a first-order concept. Due to its richer
expressiveness, it should not come as a surprise that implementing an
automated theorem prover for higher-order logic is more challenging
than for first-order logic. This is largely due to the fact that
unification in higher-order logic is more complex than in the
first-order case: unifiable terms do not always possess a most general
unifier, and higher-order unification is itself undecidable. Finally,
given that higher-order logic is incomplete, there are always proofs
that will be entirely out of reach for any automated reasoning
program.</p>

<p>
Methods used to automate first-order deduction can be adapted to
higher-order logic. TPS (Andrews <em>et al</em>. 1996, Andrews <em>et
al</em>. 2006) is a theorem proving system for higher-order logic that
uses Church&rsquo;s typed \(\lambda\)-calculus as its logical representation
language and is based on a connection-type deduction mechanism that
incorporates Huet&rsquo;s unification algorithm (Huet 1975). As a sample of
the capabilities of TPS, the program has proved automatically that a
subset of a finite set is finite, the equivalence among several
formulations of the Axiom of Choice, and Cantor&rsquo;s Theorem that a set
has more subsets than members. The latter was proved by the program by
asserting that there is no onto function from individuals to sets of
individuals, with the proof proceeding by a diagonal argument. HOL
(Gordon &amp; Melham 1993) is another higher-order proof development
system primarily used as an aid in the development of hardware and
software safety-critical systems. HOL is based on the LCF approach to
interactive theorem proving (Gordon, Milner &amp; Wadsworth 1979), and
it is built on the strongly typed functional programming language ML.
HOL, like TPS, can operate in automatic and interactive mode.
Availability of the latter mode is welcomed since the most useful
automated reasoning systems may well be those which place an emphasis
on interactive theorem proving (Farmer, Guttman &amp; Thayer 1993) and
can be used as assistants operating under human guidance. (Harrison
2000) discusses the verification of floating-point algorithms and the
non-trivial mathematical properties that are proved by HOL Light under
the guidance of the user. Isabelle (Paulson 1994) is a generic,
higher-order, framework for rapid prototyping of deductive systems.
Object logics can be formulated within Isabelle&rsquo;s metalogic by using
its many syntactic and deductive tools. Isabelle also provides some
ready-made theorem proving environments, including Isabelle/HOL,
Isabelle/ZF and Isabelle/FOL, which can be used as starting points for
applications and further development by the user (Paulson 1990, Nipkow
&amp; Paulson 2002). Isabelle/ZF has been used to prove equivalent
formulations of the Axiom of Choice, formulations of the Well-Ordering
Principle, as well as the key result about cardinal arithmetic that,
for any infinite cardinal \(\kappa , \kappa \cdot \kappa = \kappa\)
(Paulson &amp; Grabczewski 1996).</p>

<p>
To help prove higher-order theorems and discharge goals arising in
interactive proofs, the user can ask Isabelle/HOL to invoke external
first-order provers through Sledgehammer (Paulson 2010), a subsystem
aimed at combining the complementary capabilities of automated
reasoning systems of different types, including SMT solvers (see
<a href="#SATSol">the section on SAT Solvers</a>; Blanchette <em>et al</em>. 2013).
LEO-II (Benzm&uuml;ller <em>et al</em>. 2015) is also a resolution-based
automated theorem prover for higher-order logic that has been applied
in a wide array of problems, most notably in the automation of
G&ouml;del&rsquo;s ontological proof of God&rsquo;s existence (see <a href="#LogicAndPhil">  Section 4.6 Logic and Philosophy</a>). Leo-II has been superseded by Leo-III which implements a higher-order ordered paramodulation calculus that operates within a multi-agent blackboard architecture for parallel proof search; the architecture allows to independently run agents using Leo-III&rsquo;s native proof calculus as well as, in a cooperative fashion, agents for external, specialized, first- and higher-order theorem provers and model finders (Benzm&uuml;ller, Steen &amp; Wisniewski 2017, Steen and Benzm&uuml;ller 2021).</p>

<h3><a name="NonClaLog">3.2 Non-classical Logics</a></h3>

<p>
Non-classical logics (Haack 1978) such as modal logics, intuitionsitic
logic, multi-valued logics, autoepistemic logics, non-monotonic
reasoning, commonsense and default reasoning, relevance logic,
paraconsistent logic, and so on, have been increasingly gaining the
attention of the automated reasoning community. One of the reasons has
been the natural desire to extend automated deduction techniques to
new domains of logic. Another reason has been the need to mechanize
non-classical logics as an attempt to provide a suitable foundation
for artificial intelligence. A third reason has been the desire to
attack some problems that are combinatorially too large to be handled
by paper and pencil. Indeed, some of the work in automated
non-classical logic provides a prime example of automated reasoning
programs at work. To illustrate, the Ackerman Constant Problem asks
for the number of non-equivalent formulas in the relevance logic R.
There are actually 3,088 such formulas (Slaney 1984) and the number
was found by &ldquo;sandwiching&rdquo; it between a lower and an upper
limit, a task that involved constraining a vast universe of
\(20^{400} 20\)-element models in search of those models that
rejected non-theorems in R. It is safe to say that this result would
have been impossible to obtain without the assistance of an automated
reasoning program.</p>

<p>
There have been three basic approaches to automate the solving of
problems in non-classical logic (McRobie 1991). One approach has been,
of course, to try to mechanize the non-classical deductive calculi.
Another has been to simply provide an equivalent formulation of the
problem in first-order logic and let a classical theorem prover handle
it. A third approach has been to formulate the semantics of the
non-classical logic in a first-order framework where resolution or
connection-matrix methods would apply. (Pelletier <em>et al</em>.
2017) describes an automated reasoning system for a paraconsistent
logic that takes both &ldquo;indirect&rdquo; approaches, the
translational and the truth-value approach, to prove its theorems.</p>

<h4>Modal logic</h4>

<p>
Modal logics find extensive use in computing science as logics of
knowledge and belief, logics of programs, and in the specification of
distributed and concurrent systems. Thus, a program that automates
reasoning in a modal logic such as K, K4, T, S4, or S5 would have
important applications. With the exception of S5, these logics share
some of the important metatheoretical results of classical logic, such
as cut-elimination, and hence cut-free (modal) sequent calculi can be
provided for them, along with techniques for their automation.
Connection methods (Andrews 1981, Bibel 1981) have played an important
role in helping to understand the source of redundancies in the search
space induced by these modal sequent calculi and have provided a
unifying framework not only for modal logics but also for
intuitionistic and classical logic as well (Wallen 1990). Current
efforts to automate modal logic reasoning revolve around the
translational approach mentioned above, namely to embed modal logic
into classical logic and then use an existing automated reasoning
system for the latter to prove theorems of the former.
(Benzm&uuml;ller &amp; Paulson 2013) shows how to embed quantified modal
logic into simple type theory, proves the soundness and completeness
of the embedding, and demonstrates with simple experiments how
existing higher-order theorem provers can be used to automate proofs
in modal logic. The approach can be extended to higher-order modal
logic as well (Benzm&uuml;ller &amp; Paleo 2015). As a matter of fact, embeddings in classical higher-order logic can be used as a means for universal reasoning (Benzm&uuml;ller 2019); that is, the embedding provides a universal logical reasoning framework that uses classical higher-order logic as a metalogic in which various other classical and non-classical logics can be represented. Further evidence to the claim of universality is provided by the semantical embedding approach to free logic and category theory (Benzm&uuml;ller &amp; Scott 2020). Embedding yields a number of practical benefits to automated deduction: universality, uniformity, expressiveness of notation and reasoning, and ready availability of existing powerful automated theorem-proving tools that are known to be sound.</p>

<h4>Intuitionistic logic</h4>

<p>
There are different ways in which intuitionsitic logic can be
automated. One is to directly implement the intuitionistic versions of
Gentzen&rsquo;s sequent and natural deduction calculi, LJ and NJ
respectively. This approach inherits the stronger normalization
results enjoyed by these calculi allowing for a more compact
mechanization than their classical counterparts. Another approach at
mechanizing intuitionistic logic is to exploit its semantic
similarities with the modal logic S4 and piggy back on an automated
implementation of S4. Automating intuitionistic logic has applications
in software development since writing a program that meets a
specification corresponds to the problem of proving the specification
within an intuitionistic logic (Martin-L&ouml;f 1982). A system that
automated the proof construction process would have important
applications in algorithm design but also in constructive mathematics.
Nuprl (Constable <em>et al</em>. 1986) is a computer system supporting
a particular mathematical theory, namely constructive type theory, and
whose aim is to provide assistance in the proof development process.
The focus is on logic-based tools to support programming and on
implementing formal computational mathematics. Over the years the
scope of the Nuprl project has expanded from
&ldquo;proofs-as-programs&rdquo; to &ldquo;systems-as-theories&rdquo;.
Similar in spirit and based on the Curry-Howard isomorphism, the Coq
system formalizes its proofs in the Calculus of Inductive
Constructions, a \(\lambda\)-calculus with a rich system of types
including dependent types (Coquand &amp; Huet 1988, Coquand &amp;
Paulin-Mohring 1988). Like Nuprl, Coq is designed to assist in the
development of mathematical proofs as well as computer programs from
their formal specifications.</p>

<h2><a name="App">4. Applications</a></h2>

<h3><a name="LogPro">4.1 Logic Programming</a></h3>

<p>
Logic programming, particularly represented by the language
<strong>Prolog</strong> (Colmerauer <em>et al</em>. 1973), is probably
the most important and widespread application of automated theorem
proving. During the early 1970s, it was discovered that logic could be
used as a programming language (Kowalski 1974). What distinguishes
logic programming from other traditional forms of programming is that
logic programs, in order to solve a problem, do not explicitly state
<em>how</em> a specific computation is to be performed; instead, a
logic program states <em>what</em> the problem is and then delegates
the task of actually solving it to an underlying theorem prover. In
Prolog, the theorem prover is based on a refinement of resolution
known as SLD-resolution. <strong>SLD-resolution</strong> is a
variation of linear input resolution that incorporates a special rule
for selecting the next literal to be resolved upon; SLD-resolution
also takes into consideration the fact that, in the computer&rsquo;s memory,
the literals in a clause are actually ordered, that is, they form a
sequence as opposed to a set. A Prolog <strong>program</strong>
consists of clauses stating known facts and rules. For example, the
following clauses make some assertions about flight connections:</p>

<blockquote>
flight(toronto, london).
<br />
flight(london, rome).
<br />
flight(chicago, london).
<br />
flight\((X, Y)\) :&ndash; flight\((X, Z)\) ,
flight\((Z, Y)\).
</blockquote>

<p>
The clause flight(toronto, london) is a fact while
flight\((X, Y)\) :&ndash; <span style="white-space:nowrap;">flight\((X, Z)\)
,</span>
flight\((Z,Y)\) is a rule, written by convention as a
reversed conditional (the symbol &ldquo;:&ndash;&rdquo; means
&ldquo;if&rdquo;; the comma means &ldquo;and&rdquo;; terms starting in
uppercase are variables). The former states that there is flight
connection between Toronto and London; the latter states that there is
a flight between cities \(X\) and \(Y\) if, for some city
\(Z\), there is a flight between \(X\) and \(Z\) and
one between \(Z\) and \(Y\). Clauses in Prolog programs are
a special type of Horn clauses having precisely one positive literal:
<strong>Facts</strong> are program clauses with no negative literals
while <strong>rules</strong> have at least one negative literal. (Note
that in standard clause notation the program rule in the previous
example would be written as flight\((X,Y) \vee{\sim}\)flight\((X,Z) \vee{\sim}\)flight\((Z,Y)\).)
The specific form of the program rules is to effectively express
statements of the form: &ldquo;<em>If these conditions over here are
jointly met then this other fact will follow</em>&rdquo;. Finally, a
<strong>goal</strong> is a Horn clause with no positive literals. The
idea is that, once a Prolog program \(\Pi\) has been written, we can then
try to determine if a new clause \(\gamma\), the goal, is entailed by
\(\Pi , \Pi \vDash \gamma\); the Prolog prover does this by attempting
to derive a contradiction from \(\Pi \cup \{{\sim}\gamma \}\). We should remark
that program facts and rules alone cannot produce a contradiction; a
goal must enter into the process. Like input resolution,
SLD-resolution is not refutation complete for first-order logic but it
is complete for the Horn logic of Prolog programs. The fundamental
theorem: If \(\Pi\) is a Prolog program and \(\gamma\) is the goal clause
then \(\Pi \vDash \gamma\) iff \(\Pi \cup \{{\sim}\gamma \} \vdash
[\,]\) by SLD-resolution (Lloyd 1984).</p>

<p>
For instance, to find out if there is a flight from Toronto to Rome
one asks the Prolog prover to see if the clause flight(toronto, rome)
follows from the given program. To do this, the prover adds
\({\sim}\)flight(toronto,rome) to the program clauses and attempts to derive
the empty clause, \([\,]\), by SLD-resolution:</p>

<table class="cellpad-med-dense vert-top centered">
<tr>
 <td>1</td>
 <td>flight(toronto, london)</td>
 <td>Program clause</td> </tr>
<tr>
 <td>2</td>
 <td>flight(london, rome)</td>
 <td>Program clause</td> </tr>
<tr>
 <td>3</td>
 <td>flight(chicago, london)</td>
 <td>Program clause</td> </tr>
<tr>
 <td>4</td>
 <td>flight\((X,Y) \vee{\sim}\)flight\((X,Z) \vee{\sim}\)flight\((Z,Y)\)</td>
 <td>Program clause</td> </tr>
<!--pdf include <tr> <td colspan="3">&nbsp;</td> </tr> pdf include-->
<tr>
 <td>5</td>
 <td>\({\sim}\)flight(toronto, rome)</td>
 <td>Negated conclusion</td> </tr>
<tr>
 <td>6</td>
 <td>\({\sim}\)flight(toronto,\(Z) \vee{\sim}\)flight\((Z\), rome)</td>
 <td>Res 5 4</td> </tr>
<tr>
 <td>7</td>
 <td>\({\sim}\)flight(london, rome)</td>
 <td>Res 6 1</td> </tr>
<tr>
 <td>8</td>
 <td>\([ \,]\)</td>
 <td>Res 7 2</td> </tr>
</table>

<p>
The conditional form of rules in Prolog programs adds to their
readability and also allows reasoning about the underlying refutations
in a more friendly way: To prove that there is a flight between
Toronto and Rome, flight(toronto,rome), unify this clause with the
consequent flight\((X,Y)\) of the fourth clause in the
program which itself becomes provable if both
flight(toronto,\(Z)\) and flight\((Z\),rome) can be proved.
This can be seen to be the case under the substitution \(\{Z \leftarrow\) london\(\}\) since both flight(toronto,london) and
flight(london,rome) are themselves provable. Note that the theorem
prover not only establishes that there is a flight between Toronto and
Rome but it can also come up with an actual itinerary,
Toronto-London-Rome, by extracting it from the unifications used in
the proof.</p>

<p>
There are at least two broad problems that Prolog must address in
order to achieve the ideal of a logic programming language. Logic
programs consist of facts and rules describing what is true; anything
that is not provable from a program is deemed to be false. In regards
to our previous example, <em>flight</em>(<em>toronto</em>,
<em>boston</em>) is not true since this literal cannot be deduced from
the program. The identification of falsity with non-provability is
further exploited in most Prolog implementations by incorporating an
operator, <strong>not</strong>, that allows programmers to explicitly
express the negation of literals (or even subclauses) within a
program. By definition, not \(l\) succeeds if the literal
\(l\) itself fails to be deduced. This mechanism, known as
<strong>negation-by-failure</strong>, has been the target of
criticism. Negation-by-failure does not fully capture the standard
notion of negation and there are significant logical differences
between the two. Standard logic, including Horn logic, is monotonic
which means that enlarging an axiom set by adding new axioms simply
enlarges the set of theorems derivable from it; negation-by-failure,
however, is <strong>non-monotonic</strong> and the addition of new
program clauses to an existing Prolog program may cause some goals to
cease from being theorems. A second issue is the <strong>control
problem</strong>. Currently, programmers need to provide a fair amount
of control information if a program is to achieve acceptable levels of
efficiency. For example, a programmer must be careful with the order
in which the clauses are listed within a program, or how the literals
are ordered within a clause. Failure to do a proper job can result in
an inefficient or, worse, non-terminating program. Programmers must
also embed hints within the program clauses to prevent the prover from
revisiting certain paths in the search space (by using the
<strong>cut</strong> operator) or to prune them altogether (by using
<strong>fail</strong>. Last but not least, in order to improve their
efficiency, many implementations of Prolog do not implement
unification fully and bypass a time-consuming yet critical
test&mdash;the so-called
<strong>occurs-check</strong>&mdash;responsible for checking the
suitability of the unifiers being computed. This results in an unsound
calculus and may cause a goal to be entailed by a Prolog program (from
a computational point of view) when in fact it should not (from a
logical point of view).</p>

<p>
There are variations of Prolog intended to extend its scope. By
implementing a model elimination procedure, the Prolog Technology
Theorem Prover (PTTP) (Stickel 1992) extends Prolog into full
first-order logic. The implementation achieves both soundness and
completeness. Moving beyond first-order logic, \(\lambda\)Prolog (Miller
&amp; Nadathur 1988) bases the language on higher-order constructive
logic.</p>

<h3><a name="SATSol">4.2 SAT Solvers</a></h3>

<p>
The problem of determining the satisfiability of logic formulas has
received much attention by the automated reasoning community due to
its important applicability in industry. A propositional formula is
<strong>satisfiable</strong> if there is an assignment of truth-values
to its variables that makes the formula true. For example, the
assignment \((P \leftarrow\) true, \(Q \leftarrow\) true, \(R \leftarrow\) false) does not make \((P \vee R) \amp{\sim}Q\) true but \((P \leftarrow\) true, \(Q \leftarrow\) false,
\(R \leftarrow\) false) does and, hence, the formula is satisfiable.
Determining whether a formula is satisfiable or not is called the
Boolean Satisfiability Problem&mdash;\(\mathbf{SAT}\) for
short&mdash;and for a formula with \(n\) variables SAT can be
settled thus: Inspect each of the \(2^n\) possible
assignments to see if there is at least one assignment that satisfies
the formula, i.e. makes it true. This method is clearly complete: If
the original formula is satisfiable then we will eventually find one
such satisfying assignment; but if the formula is contradictory (i.e.
non-satisfiable), we will be able to determine this too. Just as
clearly, and particularly in this latter case, this search takes an
exponential amount of time, and the desire to conceive more efficient
algorithms is well justified particularly because many computing
problems of great practical importance such as graph-theoretic
problems, network design, storage and retrieval, scheduling, program
optimization, and many others (Garey &amp; Johnson 1979) can be
expressed as SAT instances, i.e. as the SAT question of some
propositional formula representing the problem. Given that SAT is
NP-complete (Cook 1971) it is very unlikely that a polynomial
algorithm exists for it; however, this does not preclude the existence
of sufficiently efficient algorithms for particular cases of SAT
problems.</p>

<p>
The Davis-Putnam-Logemann-Loveland \((\mathbf{DPLL})\) algorithm
was one of the first SAT search algorithms (Davis &amp; Putnam 1960;
Davis, Logemman &amp; Loveland 1962) and is still considered one of the
best complete SAT solvers; many of the complete SAT procedures in
existence today can be considered optimizations and generalizations of
DPLL. In essence, DPLL search procedures proceed by considering ways
in which assignments can be chosen to make the original formula true.
For example, consider the formula in CNF

\[P \amp{\sim}Q \amp({\sim}P \vee Q \vee R) \amp(P \vee{\sim}S)\]


Since \(P\) is a conjunct, but also a unit clause, \(P\)
must be true if the entire formula is to be true. Moreover, the value
of \({\sim}P\) does not contribute to the truth of \({\sim}P \vee Q \vee R\) and \(P \vee{\sim}S\) is true
regardless of \(S\). Thus, the whole formula reduces to


\[{\sim}Q \amp(Q \vee R)\]



Similarly, \({\sim}Q\) must be true and the formula further reduces
to


\[R\]



which forces \(R\) to be true. From this process we can recover
the assignment \((P \leftarrow\) true, \(Q \leftarrow\) false,
\(R \leftarrow\) true, \(S \leftarrow\) false) proving that the
original formula is satisfiable. A formula may cause the algorithm to
branch; the search through a branch reaches a dead end the moment a
clause is deemed false&mdash;a <strong>conflicting
clause</strong>&mdash;and all variations of the assignment that has
been partially constructed up to this point can be discarded. To
illustrate:</p>

<table class="cellpad-med-dense vert-top centered">
<tbody>
<tr>
 <td>1</td>
 <td class="nw">\(R \amp(P \vee Q) \amp({\sim}P \vee Q) \amp({\sim}P \vee{\sim}Q)\)</td>
 <td>Given</td> </tr>
<tr>
 <td>2</td>
 <td>\((P \vee Q) \amp({\sim}P \vee Q) \amp({\sim}P \vee{\sim}Q)\)</td>
 <td>By letting \(R \leftarrow\) true</td> </tr>
<tr>
 <td>3</td>
 <td>\(Q \amp{\sim}Q\)</td>
 <td>By letting \(P \leftarrow\) true</td> </tr>
<tr>
 <td>4</td>
 <td>?</td>
 <td>Conflict: \(Q\) and \({\sim}Q\) cannot both be true</td>
</tr>
<tr>
 <td>5</td>
 <td>\((P \vee Q) \amp({\sim}P \vee Q) \amp({\sim}P \vee{\sim}Q)\)</td>
 <td>Backtrack to (2): \(R \leftarrow\) true still holds</td> </tr>
<tr>
 <td>6</td>
 <td>\({\sim}P\)</td>
 <td>By letting \(Q \leftarrow\) true</td> </tr>
<tr>
 <td>7</td>
 <td>true</td>
 <td>By letting \({\sim}P\) be true, i.e., <span class="nw">\(P \leftarrow\) false</span></td> </tr> </tbody>
</table>

<p>
Hence, the formula is satisfiable by the existence of \((P \leftarrow\) false, \(Q \leftarrow\) true, \(R \leftarrow\) true). DPLL
algorithms are made more efficient by strategies such as <strong>term
indexing</strong> (ordering of the formula variables in an
advantageous way), <strong>chronological backtracking</strong>
(undoing work to a previous branching point if the process leads to a
conflicting clause), and <strong>conflict-driven learning</strong>
(determining the information to keep and where to backtrack). The
combination of these strategies results in a large prune of the search
space; for a more extensive discussion the interested reader is
directed to Zhang &amp; Malik 2002.</p>

<p>
A quick back-envelope calculation reveals the staggering computing
times of (algorithms for) SAT-type problems represented by formulas
with as little as, say, 60 variables. To wit: A problem represented as
a Boolean formula with 10 variables that affords a linear solution
taking one hundredth of a second to complete would take just four
hundredths and six hundredths of a second to complete if the formula
had instead 40 and 60 variables respectively. In dramatic contrast, if
the solution to the problem were exponential (say
\(2^n)\) then the times to complete the job for 10, 40
and 60 variables would be respectively one thousandth of a second, 13
days, and 365 centuries. It is a true testament to the ingenuity of
the automated reasoning community and the power of current SAT-based
search algorithms that real-world problems with thousands of variables
can be handled with reasonable efficency. K&uuml;chlin &amp; Sinz 2000
discuss a SAT application in the realm of industrial automotive
product data management where 18,000 (elementary) Boolean formulas and
17,000 variables are used to express constraints on orders placed by
customers. As another example, Massacci &amp; Marraro 2000 discuss
an application in logical cryptanalysis, that is, the verification of
properties of cryptographic algorithms expressed as SAT problems. They
demonstrate how finding a key with a cryptographic attack is analogous
to finding a model&mdash;assignment&mdash;for a Boolean formula; the
formula in their application encodes the commercial version of the U.S
Data Encryption Standard (DES) with the encoding requiring 60,000
clauses and 10,000 variables.</p>

<p>
Although SAT is conceptually very simple, its inner nature is not well
understood&mdash;there are no criteria that can be generally applied
to answer as to why one SAT problem is harder than another. It should
then come as no surprise that algorithms that tend to do well on some
SAT instances do not perform so well on others, and efforts are being
spent in designing hybrid algorithmic solutions that combine the
strength of complementary approaches&mdash;see Prasad, Biere &amp;
Gupta 2005 for an application of this hybrid approach in the
verification of hardware design.</p>

<p>
Recent advances in SAT hybrid strategies coupled with supercomputing
power has allowed a team of three computing scientists to solve the
Boolean Pythagorean Triples Problem, a long-standing open question in
Ramsey Theory: Can the set \(\{1, 2,...\}\) of natural numbers be divided
into two parts with no part containing a triple
\((a, b, c)\) such that \(a^2 + b^2 = c^2\)? Heule, Kullmann
&amp; Marek 2016 proved that this cannot be done by showing that the
set \(\{1, 2, \ldots ,n\}\) can be so partitioned for \(n = 7824\) but that this is impossible for \(n \ge 
7825\). Expressing this deceptively simple question as a SAT problem
required close to 38,000 clauses and 13,000 variables with about half
of these going to represent that the problem is satisfiable when n \(=
7824\) and the other half to represent that it is not when n \(= 7825\); of
the two, proving the latter was far more challenging since it demanded
a proof of unsatisfiability, i.e. that no such partition exists. A
na&iuml;ve brute-force approach considering all \(2^{7825}\)
possible two-part partitions was clearly out of the question and the
problem was attacked by using &ldquo;clever&rdquo; algorithms within a
multi-stage SAT-based framework for solving hard problems in
combinatorics, consisting of five phases: <em>Encode</em> (encoding
the problem as SAT formulas), <em>Transform</em> (optimizing the
encoding using clause elimination and symmetry breaking
techniques), <em>Split</em> (dividing the problem effectively into
subproblems using splitting heuristics), <em>Solve</em> (searching for
satisfying assignments or their lack thereof using fast processing),
and <em>Validate</em> (validating the results of the earlier
phases). Of special importance was the application
of <strong>cube-and-conquer</strong>, a hybrid SAT strategy
particularly effective for hard combinatorial problems. The strategy
combines <strong>look-ahead</strong> with <strong>conflict-driven
clause-learning</strong> \((\mathbf{CDCL})\), with the former
aiming to construct small binary search trees using global heuristics
and the latter aiming to find short refutations using local
heuristics.</p>

<p>
After splitting the problem into \(10^6\) hard subproblems
(known as &ldquo;cubes&rdquo;), these were handed down to 800 cores
working in parallel on a <em>Stampede</em> supercomputer which, after
2 days of further splitting and CDCL clause-crunching, settled the
question and delivered a 200-terabyte proof validating the work. After
deservedly celebrating this significant accomplishment of automated
reasoning, and after entertaining all the new applications that the
enhanced SAT method would afford (particularly in the areas of
hardware and software verification), we should then ask some questions
that are of especial importance to mathematicians: Is there a more
insightful way to establish this result that would involve more
traditional and intellectually satisfying mathematical proof methods?
Or, as far as increasing our understanding of a given field
(combinatorics in this case), what is the value of settling a question
when no human can inspect the proof and hence get no insight from it?
Even the team responsible for the result admits that &ldquo;the proofs
of unsatisfiability coming from SAT solvers are, from a human point of
view, a giant heap of random information (no direct understanding is
involved)&rdquo;. The conjecture has been settled but we basically
have no underlying idea what makes 7825 so special. Perhaps the real
value to be drawn from these considerations is that they lead us to
think about the deeper question: What is it about the structure of a
specific problem that makes it amenable to standard mathematical
treatment as opposed to requiring a mindless brute-force approach?
While this question is being contemplated, SAT may provide the best line of attack on certain mathematical problems.</p>

<p>
The DPLL search procedure has been extended to quantified logic. MACE
is a popular program based on the DPLL algorithm that searches for
finite models of first-order formulas with equality. As an example
(McCune 2001), to show that not all groups are commutative one can
direct MACE to look for a model of the group axioms that also
falsifies the commutation law or, equivalently, to look for a model
of:</p>

\[\begin{align}
\tag{G1} &amp;e\cdot x = x &amp;\text{(left identity)} \\
\tag{G2} &amp; i(x)\cdot x = e &amp;\text{(left inverse)} \\
\tag{G3} &amp; x(\cdot y)\cdot z = x \cdot(y \cdot z) &amp;\text{(associativity)}\\
\tag{DC} &amp; a\cdot b \neq b\cdot a &amp; \text{(denial of commutativity)}
\end{align}\]

<p>
MACE finds a six-element model of these axioms, where \(\cdot\) is
defined as:</p>

<table class="all-rules cellpad-small indent avoid-break centered">
<tr>
 <td>\(\cdot\)</td>
 <td>0</td>
 <td>1</td>
 <td>2</td>
 <td>3</td>
 <td>4</td>
 <td>5</td> </tr>
<tr>
 <td>0</td>
 <td>0</td>
 <td>1</td>
 <td>2</td>
 <td>3</td>
 <td>4</td>
 <td>5</td> </tr>
<tr>
 <td>1</td>
 <td>1</td>
 <td>0</td>
 <td>4</td>
 <td>5</td>
 <td>2</td>
 <td>3</td> </tr>
<tr>
 <td>2</td>
 <td>2</td>
 <td>3</td>
 <td>0</td>
 <td>1</td>
 <td>5</td>
 <td>4</td> </tr>
<tr>
 <td>3</td>
 <td>3</td>
 <td>2</td>
 <td>5</td>
 <td>4</td>
 <td>0</td>
 <td>1</td> </tr>
<tr>
 <td>4</td>
 <td>4</td>
 <td>5</td>
 <td>1</td>
 <td>0</td>
 <td>3</td>
 <td>2</td> </tr>
<tr>
 <td>5</td>
 <td>5</td>
 <td>4</td>
 <td>3</td>
 <td>2</td>
 <td>1</td>
 <td>0</td> </tr>
</table>

<p>
and where \(i\) are defined as:</p>

<table class="all-rules cellpad-small-dense indent centered">
<tr>
 <td>\(x\)</td>
 <td>0</td>
 <td>1</td>
 <td>2</td>
 <td>3</td>
 <td>4</td>
 <td>5</td> </tr>
<tr>
 <td>\(i(x)\)</td>
 <td>0</td>
 <td>1</td>
 <td>2</td>
 <td>3</td>
 <td>4</td>
 <td>5</td> </tr>
</table>

<p>
This example also illustrates, once again, the benefits of using an automated
deduction system: How long would have taken the human researcher to
come up with the above or a similar model? For more challenging
problems, the program is being used as a practical complement to the
resolution-based theorem prover Prover9 (formerly Otter), with Prover9
searching for proofs and MACE jointly looking for (counter) models. To
find such models, MACE converts the first-order problem into a set of
"flattened" clauses which, for increasing model sizes, are
instantiated into propositional clauses and solved as a SAT problem.
The method has been implemented in other automated reasoning systems
as well, most notably in the Paradox model finder where the MACE-style
approach has been enhanced by four additional techniques resulting in
some significant efficiency improvements (Claessen &amp; S&ouml;rensson
2003): term definitions (to reduce the number of variables in
flattened clauses), static symmetric reduction (to reduce the number
of isomorphic models), sort inference (to apply symmetric reduction at
a finer level) and incremental SAT (to reuse search information
between consecutive model sizes). The strategy of pairing the
complementary capabilities of separate automated reasoning systems has
been applied to higher-order logic too as exemplified by Nitpick, a
counterexample generator for Isabelle/HOL (Blanchette &amp; Nipkow
2010). Brown 2013 describes a theorem proving procedure for
higher-order logic that uses SAT-solving to do most of the work; the
procedure is a complete, cut-free, ground refutation calculus that
incorporates restrictions on instantiations and has been implemented
in the Satallax theorem prover (Brown 2012).</p>

<p>
An approach of great interest at solving SAT problems in first-order
logic is <strong>Satisfiability Modulo Theory</strong>
\((\mathbf{SMT})\) where the interpretation of symbols in the
problem&rsquo;s formulation is constrained by a <strong>background
theory</strong>. For example, in linear arithmetic the function
symbols are restricted to + and \(-\). As another example, in the
extensional theory of arrays (McCarthy 1962) the array function
<em>read</em>\((a, i)\) returns the value of the array
\(a\) at index \(i\), and <em>write</em>\((a,
i, x)\) returns the array identical to \(a\) but
where the value of \(a\) at \(i\) is \(x\). More
formally,</p>

<dl class="partag indent">
<dt>(read-write axiom 1)</dt>
<dd>\(\forall a : \textit{Array} .
\forall i,j : \textit{Index} . \forall x :
\textit{Value} . i = j\ \rightarrow \)
\(\textit{read}(write(a, i, x), j) = x\)</dd>

<dt>(read-write axiom 2)</dt>
<dd>\(\forall a : \textit{Array} .
\forall i,j : \textit{Index} . \forall x :
Value . i \ne j\ \rightarrow\)
\(\textit{read}(\textit{write}(a, i, x), j) = \textit{read}(a, j)\)</dd>

<dt>(extensionality)</dt>
<dd>\(\forall a,b : \textit{Array} . \forall i : \textit{Index} . a = b\ \rightarrow\)
\(\textit{read}(a, i) = \textit{read}(b, i)\)</dd>
</dl>

<p>
In the context of these axioms, an SMT solver would attempt to
establish the satisfiability (or, dually, the validity) of a given
first-order formula, or thousands of formulas for that matter, such
as</p>

\[i - j = 1 \amp f(\textit{read}(\textit{write}(a, i, 2),
j + 1) = \textit{read}(\textit{write}(a, i,
f(i - j + 1)), i)\]


<p>
(Ganzinger <em>et al</em>. 2004) discusses an approach to SMT called
\(\mathbf{DPLL}(\mathbf{T})\) consisting of a general
DPLL(X) engine that works in conjunction with a solver
<em>Solver\(_T\)</em> for background theory \(T\). Bofill
<em>et al</em>. (2008) present the approach in the setting of the theory of
arrays, where the DPLL engine is responsible for enumerating
propositional models for the given formula whereas
<em>Solver\(_T\)</em> checks whether these models are consistent
with the theory of arrays. Their approach is sound and complete, and
can be smoothly extended to multidimensional arrays.</p>

<p>
SMT is particularly successful in verification applications, most
notably software verification. Having improved the efficiency of SAT
solvers with SMT, the effort is now on designing more efficient SMT
solvers (de Moura 2007). There is also the need to conduct a comprehensive comparison and potential consolidation of the techniques offered by the different SMT-based verification approaches, including bounded model checking, k-induction, predicate abstraction, and lazy abstraction with interpolants (Beyer, Dangl &amp; Wendler 2018 and 2021).</p>

<h3><a name="DedComAlg">4.3 Deductive Computer Algebra</a></h3>

<p>
To prove automatically even the simplest mathematical facts requires a
significant amount of domain knowledge. As a rule, automated theorem
provers lack such rich knowledge and attempt to construct proofs from
first principles by the application of elementary deduction rules.
This approach results in very lengthy proofs (assuming a proof is
found) with each step being justified at a most basic logical level.
Larger inference steps and a significant improvement in mathematical
reasoning capability can be obtained, however, by having a theorem
prover interact with a computer algebra system, also known as a
symbolic computation system. A <strong>computer algebra
system</strong> is a computer program that assists the user with the
symbolic manipulation and numeric evaluation of mathematical
expressions. For example, when asked to compute the improper
integral</p>

\[\int_0^\infty e^{-a^2 t^2}\cos(2bt)\,dt\]


<p>
a competent computer algebra system would quickly reply with the
answer</p>

\[\frac{\sqrt{\pi}}{2a}{e^{-b^2/a^2}}\]

<p>
Essentially, the computer algebra system operates by taking the input
expression entered by the user and successively applies to it a series
of transformation rules until the result no longer changes (see <a href="#TerRew">the
section on Term Rewriting</a> for more details).
These transformation rules encode a significant amount of domain
(mathematical) knowledge making symbolic systems powerful tools in the
hands of applied mathematicians, scientists, and engineers trying to
attack problems in a wide variety of fields ranging from calculus and
the solving of equations to combinatorics and number theory.</p>

<p>
Problem solving in mathematics involves the interplay of deduction and
calculation, with decision procedures being a reminder of the fuzzy
division between the two; hence, the integration of deductive and
symbolic systems, which we coin here as <strong>Deductive Computer
Algebra (DCA)</strong>, is bound to be a fruitful combination.
Analytica (Bauer, Clarke &amp; Zhao 1998) is a theorem prover built on
top of Mathematica, a powerful and popular computer algebra system.
Besides supplying the deductive engine, Analytica also extends
Mathematica&rsquo;s capabilities by defining a number of rewrite
rules&mdash;more precisely, identities about summations and
inequalities&mdash;that are missing in the system, as well as
providing an implementation of Gosper&rsquo;s algorithm for finding closed
forms of indefinite hypergeometric summations. Equipped with this
extended knowledge, Analytica can prove semi-automatically some
nontrivial theorems from real analysis, including a series of lemmas
directly leading to a proof of the Bernstein Approximation Theorem.
Here is the statement of the theorem simply to give the reader a sense
of the level of the mathematical richness we are dealing with:</p>

<blockquote>
<strong>Bernstein Approximation Theorem</strong>.
<br />
Let \(\text{I} = [0, 1]\) be the closed unit interval, \(f\) a real
continuous function on I, and
\(B_n (x,f)\) the
<em>nth</em> Bernstein polynomial for \(f\) defined as
\[B_n(x, f)= \sum_{k=0}^n \binom{n}{k} f(k/n)x^k(1-x)^{n-k}\]

 Then, on the interval I, the sequence of Bernstein
polynomials for \(f\) converges uniformly to \(f\).
</blockquote>

<p>
To be frank, the program is supplied with key information to establish
the lemmas that lead to this theorem but the amount and type of
deductive work done by the program is certainly nontrivial. (Clarke
&amp; Zhao 1994) provides examples of fully automated proofs using
problems in Chapter 2 of <em>Ramanujan&rsquo;s Notebooks</em> (Berndt 1985)
including the following example that the reader is invited to try.
Show that:</p>

\[\sum_{k=n+1}^{A_r}\frac{1}{k}=r+2\left(\sum_{k=1}^r (r-k)(\sum_{j=A_{k-1}+1}^{a_k} \frac{1}{(3j)^3 -3j})\right) + 2r\phi(3, A_0)\]

<p>
where \(A_0 =1\),
\(A_{n+1}=3A_n +1\) and
\(\phi(x,n)\) is Ramanujan&rsquo;s abbreviation for</p>

\[ \phi(x, n)=_{df} \sum_{K_1}^n \frac{1}{-(kx)+ k^3x^3}\]

<p>
Analytica&rsquo;s proof of this identity proceeds by simplifying both the
left- and right-hand sides of the equality and showing that both sides
reduce to the same expression, \(-H_n +\)
\(H_{A_r}\). The simplification uses the added summation
identities mentioned before as well as some elementary properties of
the harmonic numbers,</p>


\[ H_n=\sum_{k=1}^n\frac{1}{k} \]

<p>
The resulting proof has 28 steps (some of which are nontrivial) taking
about 2 minutes to find.</p>

<p>
Kerber, Kohlhase &amp; Sorge 1998 use the \(\Omega\)mega planning
system as the overall way to integrate theorem proving and symbolic
computation. In Harrison &amp; Th&eacute;ry 1998, we find an example
of the integration of a higher-order logic theorem proving system
(HOL) with a computer algebra system (Maple).</p>

<p>
Their great power notwithstanding, symbolic algebra systems do not
enforce the same level of rigor and formality that is the essence of
automated deduction systems. In fact, the mathematical semantics of
some of the knowledge rules in most algebra systems is not entirely
clear and are, in cases, logically unsound (Harrison &amp; Th&eacute;ry
1998). The main reason for this is an over-aggressiveness to provide
the user with an answer in a timely fashion at whatever cost,
bypassing the checking of required assumptions even if it means
sacrificing the soundness of the calculation. (This is strongly
reminiscent of most Prolog implementations that bypass the so-called
&ldquo;occurs-check&rdquo; also abandoning logical soundness in the
name of efficiency.) This serious problem opens the opportunity for a
deduction system to provide a service to the computer algebra system:
Use its deductive capabilities to verify that the computer algebra&rsquo;s
computational steps meet the required assumptions. There is a catch in
this, however: For sufficiently large calculation steps, verifying is
tantamount to proving and, to check these steps, the deduction system
may well need the assistance of the very same system that is in need
of verification! The solution to the soundness problem may then well
require an extensive modification of the chosen symbolic algebra
system to make it sound; an alternative approach is to develop a new
system, entirely from scratch, in conjunction with the development of
the automated theorem prover. In either case, the resulting combined
deductive computer algebra system should display a much improved
ability for automated mathematical reasoning.</p>

<h3><a name="ForVerHar">4.4 Formal Verification of Hardware</a></h3>

<p>
Automated reasoning has reached the level of maturity where theorem
proving systems and techniques are being used for industrial-strength
applications. One such application area is the formal verification of
hardware and software systems. The cost of defects in hardware can
easily run into the millions. In 1994, the Pentium processor was
shipped with a defect in its floating-point unit and the subsequent
offer by Intel to replace the flawed chip (which was taken up only by
a small fraction of all Pentium owners) cost the company close to $500
million. To guard against situations like this, the practice of
testing chip designs is now considered insufficient and more formal
methods of verification have not only gained large attention in the
microprocessor industry but have become a necessity. The idea behind
formal verification is to rigorously prove with mathematical certainty
that the system functions as specified. Common applications to
hardware design include formally establish that the system functions
correctly on all inputs, or that two different circuits are
functionally equivalent.</p>

<p>
Depending on the task at hand, one can draw from a number of automated
formal verification techniques, including SAT solvers in propositional
logic, symbolic simulation using binary decision diagrams (BDDs),
model checking in temporal logic, or conducting proofs in higher-order
logic. In the latter case, using an automated theorem prover like
HOL&mdash;see Section 3.1&mdash;has shown to be invaluable in practice.
Proof construction in a system like HOL proceeds semi-automatically
with the user providing a fair amount of guidance as to how the proof
should proceed: The user tries to find a proof while being assisted by
the theorem prover which, on request, can either automatically fill in
a proof segment or verify proof steps given to it. Although some of
the techniques mentioned above provide decision procedures which
higher-order logic lacks, higher-order logic has the advantage of
being very expressive. The tradeoff is justified since proving facts
about <strong>floating-point arithmetic</strong> requires the
formalization of a large body of real analysis, including many
elementary statements such as:</p>

<!--pdf include <small> pdf include-->

<table class="monospace smaller">
<tr>
  <td>|-</td>
  <td>(!x. a &lt;= x /\ x &lt;= b ==&gt; (f diffl (f' x)) x) /\</td>
</tr>
<tr>
  <td></td>
  <td>f(a) &lt;= K /\</td> </tr>
<tr>
  <td></td>
  <td>f(b) &lt;= K /\</td> </tr>
<tr>
  <td></td>
  <td>(!x. a &lt;= x /\ x &lt;= b /\ (f'(x) = 0) ==&gt; f(x) &lt;= K)
==&gt; </td> </tr>
<tr>
  <td></td>
  <td>&nbsp;&nbsp;(!x. a &lt;= x /\ x &lt;= b ==&gt; f(x) &lt;=
K)</td> </tr>
</table>

<!--pdf include </small> pdf include-->

<p>
This statement from Harrison 2000 written in HOL says that if a
function \(f\) is differentiable with derivative
\(f'\) in an interval \([a, b]\) then a
sufficient condition for \(f(x) \le K\)
throughout the interval is that \(f(x) \le K\)
at the endpoints \(a, b\) and at all points of zero
derivative. The result is used to determine error bounds when
approximating transcendental functions by truncated power series.
Conducting proofs in such a &ldquo;painstakingly foundational
system&rdquo; (Harrison 2006) has some significant benefits. First,
one achieves a high degree of assurance that the proofs are valid
since (admitedly lengthy) they are composed of small error-free
deductive steps. Second, the formalization of these elementary
statements and intermediate results can be reused in other tasks or
projects. For example, a library of formal statements and proven
results in floating-point division can be reused when proving other
results of floating-point algorithms for square roots or
transcendental functions. To further illustrate, different versions of
the square root algorithm for the Intel Itanium share many
similarities and the proof of correctness for one version of the
algorithm can be carried over to another version after minor tweaking
of the proof. A third benefit of using a prover like HOL is, of
course, that such lengthy proofs are carried out mechanically and are
deductively certain; the likelihood of introducing a human error if
they were carried out manually would be just as certain.</p>

<h3><a name="ForVerSof">4.5 Formal Verification of Software</a></h3>

<p>
Society is becoming increasingly dependent on software systems for
critical services such as safety and security. Serious adverse effects
of malfunctioning software include loss of human life, threats to
security, unauthorized access to sensitive information, large
financial losses, denial of critical services, and risk to safety. One
way to increase the quality of critical software is to supplement
traditional methods of testing and validation with techniques of
formal verification. The basic approach to formal verification is to
generate a number of conditions that the software must meet and to
verify&mdash;establish&mdash;them by mathematical proof. As with
hardware, automated formal verification (simply formal verification,
hereafter) is concerned with discharging these proof obligations using
an automated theorem prover.</p>

<p>
The formal verification of <strong>security protocols</strong> is an
almost ideal application of automated theorem proving in industry.
Security protocols are small distributed programs aimed at ensuring
that transactions take place securely over public networks. The
specification of a security protocol is relatively small and well
defined but its verification is certainly non-trivial. We have already
mentioned in a previous section the use of SAT-based theorem provers
in the verification of the U.S Data Encryption Standard (DES). As
another example, the Mondex &ldquo;electronic purse&rdquo; is a smart
card electronic cash system that was originally developed by National
Westminster Bank and subsequently sold to MasterCard International.
Schmitt &amp; Tonin 2007 describe a Java Card implementation of the
Mondex protocol for which the security properties were reformulated in
the Java Modeling Language (JML) following closely the original Z
specification. Proof of correctness was conducted using the KeY tool
(Beckert, Hanle &amp; Schmitt 2007), an interactive theorem proving
environment for first-order dynamic logic that allows the user to
prove properties of imperative and object-oriented sequential
programs. This application of automated reasoning demonstrates, in the
words of the authors, that &ldquo;it is possible to bridge the gap
between specification and implementation ensuring a fully verified
result&rdquo;.</p>

<p>
Denney, Fischer &amp; Schumann 2004 describe a system to automate the
certification of safety properties of data-analysis <strong>aerospace
software</strong> at NASA. Using Hoare-style program verification
techniques, their system generates proof obligations that are then
handled by an automated theorem prover. The process is not fully
automated, however, since many of the obligations must be simplified
first in order to improve the ability of the theorem prover to solve
the proof tasks. For example, one such class of obligations makes a
statement about a matrix, \(r\), that needs to remain symmetric
after updates along its diagonal have been made, and has the form:</p>

<p class="indent">
<strong>Original form</strong>:
<br />
\(\textit{symm}(r) \rightarrow\textit{symm}(\textit{diag-updates}(r))\)</p>

<p class="indent">
<strong>Simplified form</strong> (when \(r\) is 2x2):</p>

<!--pdf include <small> pdf include-->

<table class="indent">
<tr>
 <td>\((\forall i)(\forall j)(0 \le i,
j \le 1 \rightarrow \textit{sel}(r, i,
j) = \textit{sel}(r, j, i))
\rightarrow\)</td> </tr>
<tr>
 <td>\((\forall k)(\forall l)(0 \le k,
l \le 1 \rightarrow\)</td> </tr>
<tr>
 <td> \(\textit{sel}(\textit{upd}(\textit{upd}(r,
1, 1,
r_{11}), 0, 0, r_{00}), k,
l) = \textit{sel}(\textit{upd}(\textit{upd}(r, 1, 1,
r_{11}), 0, 0, r_{00}), l,
k)))\)</td> </tr>
</table>

<!--pdf include </small> pdf include-->

<p>
Even after the simplification, current theorem provers find the proof
task challenging. The task becomes intractable for larger matrices and
number of updates (e.g. a \(6\times 6\) matrix with 36 updates) and
further preprocessing and simplification on the obligation is required
before the task eventually falls within the reach of state-of-art
theorem provers. But it is worth remarking that proofs are found
without using any specific features or configuration parameters of the
theorem provers which would improve their chances at completing the
proofs. This is important since the everyday application of theorem
provers in industry cannot presuppose such deep knowledge of the
prover from their users. The formal verification of software remains a
demanding task but it is difficult to see how the certification of
properties could happen without the assistance of automated deduction
when one faces the humanly impossible task of establishing thousands
of such obligations.</p>

<p>
In the field of <strong>nuclear engineering</strong>, techniques of
automated reasoning are deemed mature enough to assist in the formal
verification of the safety-critical software responsible for
controlling a nuclear power plant&rsquo;s reactor prevention systems (RPS).
The RPS component of the digital control system of the APR-1400
nuclear reactor is specified using NuSCR, a formal specification
language customized for nuclear applications (Yoo, Jee &amp; Cha 2009).
Model checking in computation tree logic is used to check the
specifications for completeness and consistency. After this, nuclear
engineers generate function block designs via a process of automatic
synthesis and formally verify the designs also using techniques of
model checking in linear temporal logic; the techniques are also used
to verify the equivalence of the multiple revisions and releases of
the design. These model-checking tools were implemented to make their
use as easy and intuitive as possible, in a way that did not require a
deep knowledge of the techniques, and used notations familiar to
nuclear engineers. The use of automated reasoning tools not only helps
the design engineers to establish the desired results but it also
raises the confidence of the government&rsquo;s regulatory personnel that
need to approve the RPS software before the reactor can be certified
for operation.</p>

<p>
<strong>Quantum computing</strong> is an emerging field at the intersection of physics and computer science. The field is expected to bring very significant practical applications and, given the nature of the quantum world, we can rest assured there will be no shortage of philosophical implications. These applications require a firm foundation, including the formalization and verification of quantum algorithms and results in quantum information theory. Aiming to this worthwhile objective, a number of results have already been formalized in Isabelle/HOL and added to its library so they can be made available for further work. After formalizing a number of concepts in quantum computing such as qubits, quantum states, quantum gates, entanglement, measurement, matrix representation of quantum circuits, and others, the work proceeds to the formalization of theorems and algorithms (Bordg, Lachnitt &amp; He 2021), including:</p>
<ul>
<li>
the no-clone theorem, which states that it is impossible to make an exact copy of an unknown quantum state (Wooters &amp; Zurek 1982, Dieks 1982);
</li>
<li>
the quantum teleportation protocol, whose formalization had been done previously in the Coq system (Boender, Kamm&uuml;ller &amp; Nagarajan 2015) but now it is part of Isabelle&rsquo;s library as well; the protocol allows the transmission of an unknown quantum state in the absence of a quantum channel using only an entangled pair and a classical channel;
</li>
<li>
the verification of Deutsch&rsquo;s algorithm and its generalized version, the Deutsch-Jozsa&rsquo;s algorithm (Deutsch 1985). Deutsch was the first to demonstrate that a quantum computer could perform a task faster than any von-Neumann&mdash;classical&mdash;computer; and,
</li>
<li>
a number of results in quantum game theory such as the quantum prisoner&rsquo;s dilemma, i.e. the quantum version of the classical dilemma, and the unfair quantum prisoner&rsquo;s dilemma, where one of the prisoners abides by the laws of classical physics while the other has the quantum advantage (Eisert, Wilkens &amp; Lewenstein 1999).
</li>
</ul>
<p>
Of notable mention is the fact that the formalization of the unfair quantum prisoner&rsquo;s dilemma into Isabelle/HOL uncovered a flaw in the original &ldquo;paper-and-pencil&rdquo; publication and which had gone undetected for many years. Under the more formal and strict framework that Isabelle/HOL demands, the so-called quantum &ldquo;miracle move&rdquo; (as defined in Eisert, Wilkens &amp; Lewenstein 1999) was found to be of no advantage over a classical strategy. This error has now been rectified (Eisert, Wilkens &amp; Lewenstein 2020) thus re-establishing the advantage of a quantum strategy . Further use of Isabelle/HOL in quantum computing includes the verification of quantum cryptographic protocols and the addition to Isabelle&rsquo;s library the formalization of the quantum Fourier transform which will pave the way for more advanced quantum algorithms.</p>

<h3><a name="LogicAndPhil">4.6 Logic and Philosophy</a></h3>

<p>
In the spirit of Wos, Overbeek, Lusk &amp; Boyle 1992, we pose the
question: What do the following statements about different systems of
formal logic and exact philosophy have in common?</p>

<ul>

<li>The implicational fragments of the modal logics S4 and S5 have
been studied extensively over the years. Posed as an open question, it
was eventually shown that there is a single axiom for implicational S4
as well as several new shortest axioms for implicational S5 (Ernst,
Fitelson, Harris &amp; Wos 2002).</li>

<li>The \(L\) combinator is defined as \((Lx)y = x(yy)\). Although it was known that the
\(L\)-based combinator \(E_{12} =
((L(LL))(L(LL)))((L(LL))(L(LL)))\)
satisfies \(E_{12}E_{12} = E_{12}\) the question remained whether a shorter
\(L\)-based combinator satisfying this property existed.
(Glickfeld &amp; Overbeek 1986) showed this to be the case with
\(E_8 =
((LL)(L(LL)))(L(LL))\).</li>

<li>Thirteen shortest single axioms of length eleven for classical
equivalence had been discovered, and \(XCB= e(x, e(e(e(x,
y), e(z, y)), z))\) was the
only remaining formula of that length whose status was
undetermined&mdash;was it an axiom? For a quarter of a century this
question remained open despite intense study by various researchers.
It was finally settled that \(XCB\) is indeed such a single
axiom, thus ending the search for shortest single axioms for the
equivalential calculus (Wos, Ulrich &amp; Fitelson 2002).</li>

<li>Saint Anselm of Canterbury offered in his <em>Proslogium</em> a
famous argument for the existence of God. But, quite recently, a
simpler proof has been discovered in the sense that it is shorter and
uses fewer assumptions (Oppenheimer &amp; Zalta 2011). In the same
tradition, G&ouml;del produced a proof of God&rsquo;s existence but
(Benzm&uuml;ller &amp; Paleo 2014) have recently proved the same result
using a weaker logic system while simultaneously addressing a major
criticism of G&ouml;del&rsquo;s proof.</li>

<li>In the axioms defining a Robbins algebra, the Huntington&rsquo;s
equation \(-(-(x + y) + -(x + -y)) = x\) can be replaced by a simpler one,
namely the Robbins equation \(-(-x + y) + -(-x + -y) = x\). This
conjecture went unproved for more than 50 years resisting the attacks
of many logicians including Tarski until it was eventually proved in
(McCune 1997).</li>
</ul>

<p>
We ask again, what do these results have in common? The answer is that
each has been proved with the help of an automated reasoning program.
Having disclosed the answer to this question prompts a new one: How
much longer would have taken to settle these open problems without the
application of such an automated reasoning tool? </p>

<h4>Modal logic</h4>

<p>
The strict implicational fragments of the logical systems S4 and S5 of
<strong>modal logic</strong> are known as C4 and C5, respectively, and
their Hilbert-style axiomatizations presuppose condensed detachment as
their sole rule of inference. With insight from Kripke&rsquo;s work,
Anderson &amp; Belnap (1962) published the first axiomatization of C4
using the following 3-axiom basis, where the Polish notation
&lsquo;<em>Cpq</em>&rsquo; stands for &lsquo;\(p \rightarrow q\)&rsquo;. </p>

<dl class="sentag indent">
<dt>(1)</dt>
<dd>\(Cpp \quad CCpqCrCpq \quad CCpCqrCCpqCpr\)</dd>
</dl>

<p>
A question was posed sometime after: Is there a shorter such
axiomatization for C4, using a 2-axiom basis or even a single axiom?
Using the automated reasoning program Otter, the authors Ernst,
Fitelson, Harris &amp; Wos (2001) settled both questions in the
affirmative. In fact, several 2-axiom bases were discovered of which
the following turned out to be shortest: </p>

<dl class="sentag indent">
<dt> (2) </dt>
<dd> \(CpCqq \quad CCPCqrCCpqCsCpr \)</dd>
</dl>


<p>
Further rounds of automated reasoning work were rewarded with the
discovery of a single axiom for C4; the axiom is 21 symbols long and
it was also proved that it is the shortest such axiom: </p>

<dl class="sentag indent">
<dt> (3) </dt>
<dd> \(CCpCCqCrrCpsCCstCuCpt\) </dd>
</dl>

<p>
To show that each of (2) and (3) is necessary and sufficient for (1),
a circle of proofs was produced using the automated reasoning tool:
(1) \(\Rightarrow\) (3) \(\Rightarrow\) (2) \(\Rightarrow\) (1). As for C5, its axiomatization
was originally published in a paper by Lemmon, A. Meredith, D. Meredith,
Prior &amp; Thomas (1957) giving several 4-, 3-, 2- and 1-axiom bases
for C5, including the following 3-axiom basis: </p>

<dl class="sentag indent">
<dt> (4) </dt>
<dd> \(CqCpp \quad CCpqCCqrCpr \quad CCCCpqrCpqCpq\)</dd>
</dl>

<p>
The publication also included the shortest known 2-axiom bases for C5
(actually two of them, containing 20 symbols each) but the shortest
single axiom for C5 was later discovered by (Meredith and Prior 1964)
and having 21 symbols: </p>

<dl class="sentag indent">
<dt> (5) </dt>
<dd>\(CCCCCppqrCstCCtqCsCsq\)</dd>
</dl>

<p>
Applying automated reasoning strategies again, Ernst, Fitelson,
Harris &amp; Wos 2001) discovered several new bases, including the
following 2-axiom basis of length 18 and six 1-axiom bases matching
Meredith&rsquo;s length of 21 (only one of these is given below): </p>

<dl class="sentag indent">
<dt> (6) </dt>
 <dd>\(Cpp \quad CCpqCCCCqrsrCpr\)</dd>
</dl>

<dl class="sentag indent">
<dt> (7) </dt>
 <dd>\(CCCCpqrCCuuqCCqtCsCpt\)</dd>
</dl>

<p>
To show that each of (6) and (7) is necessary and sufficient for (4),
a circle of proofs was also produced with the theorem prover: (6)
\(\Rightarrow\) (4) \(\Rightarrow\) (7) \(\Rightarrow\) (6). </p>

<h4>Combinatory logic</h4>

<p>
A charming foray into <strong>combinatory logic</strong> is presented
in Smullyan 1985 and Glickfeld &amp; Overbeek 1986, where we learn
about a certain enchanted forest inhabited by talking birds. Given any
birds \(A\) and \(B\), if the name of bird \(B\) is
spoken to bird \(A\) then \(A\) will respond with the name
of some bird in the forest, \(AB\), and this response to
\(B\) from \(A\) will always be the same. Here are some
definitions about enchanted birds: </p>


<dl class="sentag">
<dt>\(\mathbf{B1}\)</dt>
 <dd>A <em>mockingbird</em> \(M\) <em>mimics</em> any bird in
the sense that \(M\)&rsquo;s response to a bird \(x\) is the same
as \(x\)&rsquo;s response to itself, \(Mx = xx\).</dd>

<dt>\(\mathbf{B2}\)</dt>
 <dd>A bird \(C\) <em>composes</em> birds \(A\) and
\(B\) if \(A(Bx) = Cx\), for any bird
\(x\). In other words, \(C\)&rsquo;s response to \(x\) is the
same as \(A\)&rsquo;s response to \(B\)&rsquo;s response to
\(x\).</dd>

 <dt>\(\mathbf{B3}\)</dt>
 <dd>A bird \(A\) is fond of a bird \(B\) if \(A\)&rsquo;s
response to \(B\) is \(B\); that is, \(AB = B\).</dd> 
</dl>


<p>
And here are two facts about this enchanted forest: </p>


<dl class="sentag">
 <dt>\(\mathbf{F1}\)</dt>
 <dd>For any birds \(A\) and \(B\) in the forest there is a
bird \(C\) that composes them.</dd>
 <dt>\(\mathbf{F2}\)</dt>
 <dd>There is a mockingbird in the forest.</dd>
</dl>

<p>
There have been rumors that every bird in the forest is fond of at
least one bird, and also that there is at least one bird that is not
fond of any bird. The challenge to the reader now is, of course, to
settle these rumors using only F1 and F2, and the given definitions
(B1)&ndash;(B3). Glickfeld &amp; Overbeek 1986 do this in mere
seconds with an automated reasoning system using paramodulation,
demodulation and subsumption. For a more challenging problem, consider
the additional definitions: </p>

<dl class="sentag avoid-break">
 <dt>\(\mathbf{B4}\)</dt>
 <dd>A bird is egocentric if it is fond of itself: \(EE = E\).</dd>

 <dt>\(\mathbf{B5}\)</dt>
 <dd>A bird \(L\) is a lark if for any birds \(x\) and
\(y\) the following holds: \((Lx)y = x(yy)\).</dd>
</dl>


<p>
Smullyan challenges us to prove a most surprising thing about larks:
Suppose we are not given any other information except that the forest
contains a lark. Then, show that at least one bird in the forest must
be egocentric! Below we give the salient steps in the proof found by
the automated reasoning system, where &lsquo;\(S(x,
y)\)&rsquo; stands for &lsquo;\(xy\)&rsquo; and where
clauses (2) and (3) are, respectively, the definition of a lark and
the denial of the theorem; numbers on the right are applications of
paramodulation: </p>

<!--pdf include <small> pdf include-->

<blockquote>

<table class="vert-top monospace smaller">
<tr>
  <td>1</td>
  <td>(x1 = x1)</td>
  <td></td> </tr>
<tr>
  <td>2</td>
  <td>(S(S(L, x1), x2) = S(x1, S(x2, x2)))</td>
  <td></td> </tr>
<tr>
  <td>3</td>
  <td style="text-align:left;">-(S(x1, x1) = x1)</td>
  <td></td> </tr>
<tr>
  <td>6</td>
  <td style="text-align:left;">(S(x1, S(S(L, S(x2, x2)), x2)) = S(S(L,
x1), S(x2, x2)))</td>
  <td>2&nbsp;2</td> </tr>
<tr>
  <td>8</td>
  <td style="text-align:left;">(S(x1, S(S(x2, x2), S(x2, x2))) =
S(S(L, S(L, x1)), x2))</td>
  <td>2&nbsp;2</td> </tr>
<tr>
  <td>9</td>
  <td style="text-align:left;">(S(S(S(L, L), x1), x2) = S(S(x1, x1),
S(x2, x2)))</td>
  <td>2&nbsp;2</td> </tr>
<tr>
  <td>18</td>
  <td style="text-align:left;">-(S(S(L, S(S(L, S(L, L)), x1)), x1) =
S(S(L, S(x1,x1)), x1))</td>
  <td>6&nbsp;3&nbsp;6&nbsp;9&nbsp;8&nbsp;8</td> </tr>
<tr>
  <td>19</td>
  <td style="text-align:left;">[]</td>
  <td>18&nbsp;1</td> </tr>
</table>
</blockquote>

<!--pdf include </small> pdf include-->

<p>
Closer inspection of the left and right hand sides of (18) under the
application of unification revealed the discovery of a \(10-L\)
bird, i.e. a 10-symbol bird expressed solely in terms of larks, which
was a strong candidate for egocentricity. This discovery was exciting
because the shortest egocentric \(L\)-bird known to Smullyan was
of length 12. A subsequent run of the automated reasoning system
produced a proof of this fact as well as another new significant bird:
A possible egocentric \(8-L\) bird! A few more runs of the system
eventually produced a 22-line proof (with terms with as many as 50
symbols, excluding commas and parentheses) of the fact that
\(((LL)(L(LL)))(L(LL))\) is
indeed egocentric. The natural questions to ask next are, of course,
whether there are other \(8-L\) egocentric birds and whether
there are shorter ones. The reader may want to attempt this with paper
and pencil but, given that there are 429 such birds, it may be wiser
to try it instead (or in conjunction) with an automated reasoning
program; both approaches are explored in Glickfeld &amp; Overbeek
1986. For a more formal, but admittedly less colorful, introduction
to combinatory logic and lambda-conversion the reader is referred to
Hindley &amp; Seldin 1986. </p>

<h4>Equivalential calculus</h4>

<p>
Formulas in the classical <strong>equivalential calculus</strong> are
written using sentential variables and a two-place function symbol,
\(e\), for equivalence. The calculus has two rules of inference,
detachment (modus ponens) and substitution; the rules can be combined
into the single rule of condensed detachment: Obtain \(t\theta\)
from \(e(s,t)\) and \(r\) where
\(s\theta = r\theta\) with mgu \(\theta\). The calculus
can be axiomatized with the formulas: </p>

\[\begin{align}
\tag{E1}&amp; e(x, x) &amp;\text{(reflexivity)}\\
\tag{E2}&amp; e(e(x, y), e(y, x)) &amp; \text{(symmetry)}\\
\tag{E3}&amp; e(e(x, y), e(e(y, z), e(x, z))) &amp; \text{(transitivity)}
\end{align}\]

<p>
We can dispense with reflexivity since it is derivable from the other
two formulas. This brings the number of axioms down to two and a
natural question to ask is whether there is a single axiom for the
equivalential calculus. In 1933, &#321;ukasiewicz found three formulas
of length eleven that each could act as a single axiom for the
calculus&mdash;here&rsquo;s one of them:
\(e(e(x,y),e(e(z,y),e(x,z)))\)&mdash;and
he also showed that no shorter single axiom existed. Over time, other
single axioms also of length eleven were found and the list kept
growing with additions by Meredith, Kalman and Peterson to a total of
14 formulas of which 13 were known to be single axioms and one formula
with a yet undetermined status: the formula \(XCB= e(x, e(e(e(x,
y), e(z, y)), z))\).
(Actually, the list grew to 18 formulas but Wos, Winker, Veroff,
Smith &amp; Henschen 1983 reduced it to 14.) Resisting the intense
study of various researchers, it remained as an open question for many
years whether the 14th formula, \(XCB\), was a single axiom for
the equivalential calculus (Peterson 1977). One way to answer the
question in the affirmative would be to show that at least one of the
13 known single axioms is derivable from \(XCB\) alone; another
approach would be to derive from \(XCB\) the 3-axiom set
(E1)&ndash;(E3). While Wos, Ulrich &amp; Fitelson 2002 take shots at
the former, their line of attack concentrates on the latter with the
most challenging task being the proving of symmetry. Working with the
assistance of a powerful automated reasoning program, Otter, they
conducted a concerted, persistent and very aggressive assault on the
open question. (Their article sometimes reads like a military briefing
from the front lines!) For simpler problems, proofs can be found by
the reasoning program automatically; deeper and more challenging ones
like the one at hand require the guidance of the user. The relentless
application of the reasoning tool involved much guidance in the
setting of lemmas as targets and the deployment of an arsenal of
strategies, including the set of support, forward and backward
subsumption, lemma adjunction, formula complexity, hints strategy,
ratio strategy, term avoidance, level saturation, and others. After
much effort and CPU time, the open question finally succumbed to the
combined effort of man and machine and a 61-step proof of symmetry was
found, followed by one for transitivity after 10 more applications of
condensed detachment. Subsequent runs of the theorem prover using
demodulation blocking and the so-called cramming strategy delivered
shorter proofs. Here are the last lines of their 25-step proof which
in this case proves transitivity first followed by symmetry: </p>

<!--pdf include <small> pdf include-->

<table class="vert-top indent monospace smaller">
<tr>
 <td>123</td>
 <td>[hyper,51,106,122]</td>
 <td style="text-align:left;">P(e(e(e(e(x,y),e(z,y)),z),x)).</td>
</tr>
<tr>
 <td>124</td>
 <td>[hyper,51,53,123]</td>
 <td style="text-align:left;">P(e(e(e(e(e(e(e(x,y),e(z,y)),
<br />
z),x),u),e(v,u)),v)).</td> </tr>
<tr>
 <td>125</td>
 <td>[hyper,51,124,123]</td>
 <td style="text-align:left;">P(e(e(e(x,y),x),y)).</td> </tr>
<tr>
 <td>127</td>
 <td>[hyper,51,124,108]</td>
 <td style="text-align:left;">P(e(e(e(e(x,e(e(e(x,y),e(z,y))
<br />
,z)),e(e(e(e(e(u,v),e(w,v)),w),u),
<br />
v6)),v7),e(v6,v7))).</td> </tr>
<tr>
 <td>128</td>
 <td>[hyper,51,127,123]</td>
 <td style="text-align:left;">P(e(e(x,y),e(e(y,z),e(x,z)))).</td>
</tr>
<tr>
 <td>130</td>
 <td>[hyper,51,128,125]</td>
 <td style="text-align:left;">P(e(e(x,y),e(e(e(z,x),z),y))).</td>
</tr>
<tr>
 <td>131</td>
 <td>[hyper,51,128,130]</td>
 <td style="text-align:left;">P(e(e(e(e(e(x,y),x),z),u),
<br />
e(e(y,z),u))).</td> </tr>
<tr>
 <td>132</td>
 <td>[hyper,51,131,123]</td>
 <td style="text-align:left;">P(e(e(x,y),e(y,x))).</td> </tr>
</table>

<!--pdf include </small> pdf include-->

<p>
With an effective methodology and a strategy that included the
assistance of an automated reasoning program in a crucial way, the
search for shortest single axioms for the equivalent calculus came to
an end. </p>

<h4>Computational metaphysics</h4>

<p>
Fitelson &amp; Zalta 2007, Oppenheimer &amp; Zalta 2011, and Alama,
Oppenheimer, &amp; Zalta 2015 describe several applications of
automated reasoning in <strong>computational metaphysics</strong>. By
representing formal metaphysical claims as axioms and premises in an
automated reasoning environment using programs like Prover9, Mace4,
the E-prover system and Paradox, the logical status of metaphysical
arguments is investigated. After the suitable formalization of axioms
and premises, the model finder program Mace4 is used to help verify
their consistency. Then, using Prover9, proofs are automatically
generated for a number of theorems of the Theory of Plato&rsquo;s Forms,
twenty five fundamental theorems of the Theory of Possible Worlds, the
theorems described in Leibniz&rsquo;s unpublished paper of 1690 and in his
modal metaphysics, and a fully automated construction of Saint
Anselm&rsquo;s Ontological Argument. In the latter application, Saint Anselm
is understood in Oppenheimer &amp; Zalta 2011 as having found a way of
inferring God&rsquo;s existence from His mere being as opposed to inferring
God&rsquo;s actuality from His mere possibility. This allows for a
formalization that is free of modal operators, involving an underlying
logic of descriptions, three non-logical premises, and a definition of
God. Here are two key definitions in the formalization, as inputted
into Prover9, that helped express the concept of God: </p>

<!--pdf exclude begin-->

<blockquote>

<!--pdf exclude end-->

<table class="monospace smaller">
<tr>
  <td><small>Definition of none_greater:</small></td> </tr>
<tr>
  <td><small>all x (Object(x) -&gt; (Ex1(none_greater,x)
&lt;-&gt;</small></td> </tr>
<tr>
  <td><small>&nbsp;(Ex1(conceivable,x) &amp;</small></td> </tr>
<tr>
  <td><small>&nbsp;&nbsp;-(exists y (Object(y) &amp;
Ex2(greater_than,y,x) &amp;</small></td> </tr>
<tr>
  <td><small>&nbsp;&nbsp;&nbsp;Ex1(conceivable,y)))))).</small></td>
</tr>
<tr>
  <td>&nbsp;</td> </tr>
<tr>
  <td><small>Definition of God:</small></td> </tr>
<tr>
  <td><small>Is_the(g,none_greater).</small></td> </tr>
</table>

<!--pdf exclude begin-->
</blockquote>

<!--pdf exclude end-->

<p>
Part of the challenge when representing in Prover9 these and other
statements from axiomatic metaphysics was to circumvent some of the
prover&rsquo;s linguistic limitations. For example, Prover9 does not have
definite descriptions so statements of this kind as well as
second-order concepts had to be expressed in terms of Prover9&rsquo;s
existing first-order logic. But the return is worth the investment
since Prover9 not only delivered a proof
of <span class="fw">Ex1(e,g)</span>&mdash;there is one and only one
God&mdash;but does so with an added bonus. A close inspection of the
output provides yet another example of an automated theorem prover
"outreasoning" its users, revealing that some of the logical machinery
is actually redundant: The proof can be constructed only using two of
the logical theorems of the theory of descriptions (called "Theorem 2"
and "Theorem 3" in their article), one of the non-logical premises
(called "Premise 2"), and the definition of God. We cannot help but to
include here Prover9&rsquo;s shorter proof, written in the more elegant
notation of standard logic (from Oppenheimer &amp; Zalta 2011): </p>

<table class="cellpad-small-dense vert-top">
<tr>
 <td>1.</td>
 <td>\({\sim}E!\iota x\phi_1\)</td>
 <td>Assumption, for <em>Reductio</em></td> </tr>
<tr>
 <td>2.</td>
 <td>\(\exists y(Gy\iota x\phi_1 \amp Cy)\)</td>
 <td>from (1), by Premise 2 and MP</td> </tr>
<tr>
 <td>3.</td>
 <td>\(Gh\iota x\phi_1 \amp Ch\)</td>
 <td>from (2), by \(\exists\)E, &lsquo;\(h\)&rsquo; arbitrary</td>
</tr>
<tr>
 <td>4.</td>
 <td>\(Gh\iota x\phi_1\)</td>
 <td>from (3), by &amp;E</td> </tr>
<tr>
 <td>5.</td>
 <td>\(\exists y(y = \iota x\phi_1)\)</td>
 <td>from (4), by Theory of Descriptions, Theorem 3</td> </tr>
<tr>
 <td>6.</td>
 <td>\(C\iota x\phi_1 \amp{\sim}\exists y(Gy\iota x\phi_1 \amp Cy)\)</td>
 <td>from (5), by Theory of Descriptions, Theorem 2</td> </tr>
<tr>
 <td>7.</td>
 <td>\({\sim}\exists y(Gy\iota x\phi_1 \amp Cy)\)</td>
 <td>from (6), by &amp;E</td> </tr>
<tr>
 <td>8.</td>
 <td>\(E!\iota x\phi_1\)</td>
 <td>from (1), (2), (7), by <em>Reductio</em></td> </tr>
<tr>
 <td>9.</td>
 <td>\(E!g\)</td>
 <td>from (8), by the definition of &lsquo;\(g\)&rsquo;</td> </tr>
</table>

<p>
In the same tradition as St. Anselm&rsquo;s, G&ouml;del also provided an
ontological proof of God&rsquo;s existence (G&ouml;del 1970, Scott 1972). An
important difference between the two is G&ouml;del&rsquo;s use of modal
operators to represent metaphysical possibility and necessity and, of
course, his use of symbolic logic for added reasoning precision. In
his proof, G&ouml;del begins by framing the concept of &ldquo;positive
property&rdquo; using two axioms, and he introduces a definition
stating that &ldquo;A God-like being possesses all positive
properties&rdquo;. This is enough logical machinery to prove as a
theorem the possibility of God&rsquo;s existence,
\(\Diamond \exists xG(x)\); three more axioms and
two additional definitions allow G&ouml;del to further his proof to
establish not only that God exists,
\(\exists xG(x)\), but that this is so by
necessity, \(\Box \exists xG(x)\).
G&ouml;del&rsquo;s proof is in the formalism of higher-order modal logic
(HOML) using modal operators and quantification over properties.
G&ouml;del never published his proof but he shared it with Dana Scott
who produced the version presented below, which is taken from
(Benzm&uuml;ller &amp; Paleo 2014) along with its English annotation to
aid the reader with its intended interpretation: </p>

<dl class="partag indent">
<dt><strong>Axiom A1</strong></dt>
<dd>
\(\forall \varphi[P({\sim}\varphi) \equiv{\sim}P(\varphi)]\)
<br />
&nbsp;&nbsp;<em>Either a property or its negation is positive, but not
both</em>)</dd>

<dt><strong>Axiom A2</strong></dt>
<dd>\(\forall \varphi \forall \psi[(P(\varphi) \wedge \Box \forall x[\varphi(x) \rightarrow \psi(x)]) \supset P(\psi)]\)
<br />
&nbsp;&nbsp;<em>A property necessarily implied by a positive property
is positive</em></dd>

<dt><strong>Theorem T1 </strong></dt>
<dd>\(\forall \varphi[P(\varphi) \supset \Diamond \exists x \varphi(x)]\)
<br />
&nbsp;&nbsp;<em>Positive properties are possibly exemplified</em></dd>

<dt><strong> Definition D1</strong> </dt>
<dd> \(G(x) \equiv \forall \varphi[P(\varphi) \supset \varphi(x)]\)
<br /> 
&nbsp;&nbsp;<em>A God-like being possesses all positive
properties</em></dd>

<dt><strong> Axiom A3</strong> </dt>
<dd>
\(P(G)\)
<br />
&nbsp;&nbsp;<em>The property of being God-like is positive</em></dd>

<dt><strong>Corollary C</strong> </dt>
<dd>
\(\Diamond \exists xG(x)\)
<br />
&nbsp;&nbsp;<em>Possibly, God exists</em></dd>


<dt><strong> Axiom A4</strong> </dt>
<dd>
\(\forall \varphi[P(\varphi) \supset \Box P(\varphi)]\)
<br />
&nbsp;&nbsp;<em>Positive properties are necessarily positive</em></dd>


<dt> <strong>Definition D2</strong></dt>
<dd>
\(\varphi \ess x \equiv \varphi(x) \wedge \forall \psi(\psi(x) \supset \Box \forall y(\varphi(y) \supset \psi(y)))\)
<br />
&nbsp;&nbsp;<em>An essence of an individual is a property possessed by
it and
<br />
&nbsp;&nbsp;necessarily implying any of its properties</em></dd>


<dt><strong>Theorem T2</strong></dt>
<dd>
\(\forall x[G(x) \supset G \ess x]\)
<br />
&nbsp;&nbsp;<em>Being God-like is an essence of any God-like
being</em></dd>


<dt><strong> Definition D3</strong> </dt>
<dd>
\(NE(x) \equiv \forall \varphi [\varphi \ess x \supset \Box \exists y\varphi(y)]\)
<br />
&nbsp;&nbsp;<em>Necessary existence of an individual is the necessary
<br />
&nbsp;&nbsp; exemplification of all its essences</em></dd>

<dt><strong>Axiom A5</strong></dt>
<dd>
\(P(NE)\)
<br />
&nbsp;&nbsp;<em>Necessary existence is a positive property</em></dd>

<dt> <strong>Theorem T3</strong> </dt>
<dd>
\(\Box \exists xG(x)\)
<br />
&nbsp;&nbsp;<em>Necessarily, God exists</em></dd>
</dl>

<p>
The proof has recently been analysed to an unprecedented degree of
detail and precision by Benzm&uuml;ller &amp; Paleo 2014 with the help
of automated theorem provers. A major challenge faced by these authors
was the lack of a HOML-based theorem prover that could carry out the
work but this was circumvented by embedding the logic into the
classical higher-order logic (HOL) already offered by existing theorem
provers like LEO-II, Satallax and the countermodel finder Nitpick.
Details of the syntactic and semantic embedding are given in their
paper and it consists of encoding HOML formulas as HOL predicates via
mappings, expansions, and \(\beta \eta\)-conversions. The
mapping associates HOML types \(\alpha\), terms
\(s_{\alpha}\), and logical operators \(\theta\) with
corresponding HOL &ldquo;raised&rdquo; types
\(\lceil\alpha\rceil\), type-raised terms
\(\lceil s_{\alpha}\rceil\), and type-raised logical
operators \(\theta^{\bullet}\). If \(\mu\)
and \(\omicron\) are, respectively, the types of individuals and
Booleans then \(\lceil\mu\rceil = \mu\) and
\(\lceil\omicron\rceil = \sigma\)
where \(\sigma\) is shorthand
for \(\iota \rightarrow \omicron\)
with \(\iota\) as the type of possible worlds; as for function
types, \(\lceil\beta \rightarrow \gamma\rceil = \lceil\beta\rceil\rightarrow\lceil\gamma\rceil\). For
type-raised terms, \(\lceil s_\alpha \rceil\)
is defined inductively on the structure
of \(s_\alpha \) as the following example
illustrates:</p>

\[\begin{align}
\lceil \exists_{(\mu\rightarrow\omicron)\rightarrow\omicron}X_\mu. g_{\mu\rightarrow \omicron}X\rceil &amp; = \lceil \exists_{(\mu\rightarrow \omicron)\rightarrow \omicron}\rceil\lceil X_\mu . g_{\mu\rightarrow \omicron}X\rceil\\
&amp; = \lceil \exists_{(\mu\rightarrow\omicron)\rightarrow\omicron}\rceil\lceil X_\mu\rceil . \lceil g_{\mu\rightarrow \omicron}\rceil\lceil X\rceil\\
&amp; = \exists^{\bullet}_{\lceil (\mu\rightarrow\omicron)\rightarrow\omicron\rceil}X_{\lceil \mu \rceil} . g_{\lceil\mu\rightarrow\omicron\rceil}X\\
&amp; = \exists^{\bullet}_{(\mu\rightarrow \sigma)\rightarrow\sigma}X_\mu. g_{\mu\rightarrow \sigma} X
\end{align}\]


<p>
Type-raised logical connectives, \(\theta^{\bullet}\), are defined below where \(r\) is a new constant symbol in HOL associated with the accessibility relation of HOML:
</p>

\[\begin{align}
 \sim^{\bullet}_{\sigma\rightarrow\sigma} &amp; =\lambda s_\sigma \lambda w_\iota\sim(sw)\\
 \vee^{\bullet}_{\sigma\rightarrow\sigma\rightarrow\sigma} &amp; = \lambda s_\sigma \lambda t_\sigma \lambda w_\iota(sw\vee tv) \\
 \forall^{\bullet}_{(\alpha\rightarrow\sigma)\rightarrow\sigma} &amp; = \lambda s_{\alpha\rightarrow\sigma}\lambda w_\iota \forall x_\alpha sxw \\
 \Box^\bullet_{\sigma\rightarrow\sigma} &amp;  = \lambda s_\sigma \lambda w_\iota \forall u_\iota . \sim(r_{\iota\rightarrow\iota\rightarrow\omicron} wu)\vee su) 
\end{align}\]

<p>
The other connectives can be defined in the usual way. Validity is
expressed as a \(\lambda\)-term,
\(\lambda s_{\iota\rightarrow \omicron}\forall w_\iota sw\),
that when applied to a term \(s_{\sigma}\) we write as
\([s_{\sigma}]\). For example, under the embedding,
proving in HOML the possibility of God&rsquo;s existence,
\(\Diamond_{\omicron\rightarrow \omicron}\exists_{(\mu \rightarrow \omicron)\rightarrow \omicron} X_{\mu} . g_{\mu \rightarrow\omicron} X\),
is tantamount to proving its validity in HOL:
\([\Diamond^{\bullet}_{\sigma \rightarrow \sigma}\exists^{\bullet}_{(\mu \rightarrow \sigma)\rightarrow \sigma} X_{\mu} . g_{\mu \rightarrow \sigma} X]_{\mu \rightarrow\omicron }\).
To prove so, the type-raised HOL expression
\([\Diamond^{\bullet}\exists^{\bullet}X_{\mu} . g_{\mu \rightarrow\sigma } X]\)
is then encoded in the so-called THF0 syntax (Sutcliffe &amp;
Benzm&uuml;ller 2010) prior to being fed, along with the above set of
equality rules, to the provers that were used in completing the proof:
</p>

<table class="monospace smaller">
<tr>
 <td>thf(corC, conjecture,</td></tr>
<tr>
 <td> &nbsp;&nbsp; (v</td></tr>
<tr>
 <td> &nbsp;&nbsp; &nbsp;&nbsp; @(mdia</td></tr>
<tr>
 <td> &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; @(mexists_ind</td></tr>
<tr>
 <td> &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;&nbsp; @^[X: mu]
:</td></tr>
<tr>
 <td> &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;
&nbsp;&nbsp; (g @ X)))))).</td></tr>
</table>

<p>
The proof in Benzm&uuml;ller &amp; Paleo 2014 is presented here,
including the axioms and definitions as well as the derivation of its
four main results&mdash;T1, C, T2, T3&mdash;all written in the
type-decorated type-raised higher-order logic notation resulting from
the embedding. The proof steps are not fully expanded&mdash;note the
presence of type-raised connectives&mdash;and the inferential moves
are not broken down to lower levels of detail. Borrowing a phrase from
Bertrand Russell (Urquhart 1994), this was done to spare the reader of
the &ldquo;kind of nausea&rdquo; that the fully detailed automated
proof would cause: </p>

<table class="cellpad-small-dense vert-top">
<tr>
<td>A1</td>
<td>\([\forall^{\bullet}\varphi_{\mu\rightarrow \sigma} . p_{(\mu \rightarrow \sigma)\rightarrow\sigma} (\lambda X_{\mu} . {\sim}^{\bullet}\varphi\)X))\( \equiv^{\bullet} {\sim}^{\bullet}p\varphi]\)</td>
 <td>Axiom</td> 
</tr>

<tr>
<td>A2</td>
<td>\([\forall^{\bullet}\varphi_{\mu\rightarrow \sigma} .\forall^{\bullet}\psi_{\mu \rightarrow \sigma} . (p_{(\mu \rightarrow \sigma)\rightarrow\sigma} \varphi\ \wedge^{\bullet}\) 
\(\Box^{\bullet}\forall^{\bullet}X_{\mu}.(\varphi X \supset^{\bullet}\psi X)) \supset^{\bullet}\psi]\)</td>
 <td>Axiom</td> 
</tr>

<tr>
 <td>T1</td>
 <td>\([\forall^{\bullet}\varphi_{\mu\rightarrow \sigma} . p_{(\mu \rightarrow \sigma)\rightarrow\sigma} \varphi \supset^{\bullet} \Diamond^{\bullet}\exists^{\bullet}X_{\mu}.&nbsp;\varphi X]\)</td>
 <td>A1, A2 (in K)</td> 
</tr>

<tr>
 <td>D1</td>
<td>\(g_{\mu\rightarrow\sigma} =\lambda X_{\mu} .\forall^{\bullet}\varphi_{\mu\rightarrow\sigma }&nbsp;.&nbsp;p_{(\mu\rightarrow \sigma)\rightarrow\sigma} \varphi \supset^{\bullet}\varphi X\)</td>
 <td>Definition</td> 
</tr>

<tr>
 <td>A3</td>
<td>\([p_{(\mu\rightarrow \sigma)\rightarrow \sigma} g_{\mu \rightarrow\sigma}]\)</td>
 <td>Axiom</td> 
</tr>

<tr>
 <td>C</td>
<td>\([\Diamond^{\bullet}\exists^{\bullet}X_{\mu} . g_{\mu \rightarrow\sigma} X]\)</td>
 <td>T1, D1, A3 (in K)</td> 
</tr>

<tr>
 <td>A4</td>
<td>\([\forall^{\bullet}\varphi_{\mu\rightarrow \sigma} . p_{(\mu \rightarrow \sigma)\rightarrow\sigma} \varphi \supset^{\bullet} \Box^{\bullet}p\varphi]\)</td>
 <td>Axiom</td> 
</tr>

<tr>
 <td>D2</td>
<td>\(\ess_{(\mu\rightarrow \sigma)\rightarrow \mu \rightarrow \sigma} = \lambda \varphi_{\mu \rightarrow\sigma} . \lambda X_{\mu}.&nbsp;\varphi X\ \wedge\)
\(\forall^{\bullet}\psi_{\mu\rightarrow\sigma}.&nbsp;(\psi X \supset^{\bullet} \Box^{\bullet}\forall^{\bullet}Y_{\mu}.&nbsp;(\varphi Y \supset^{\bullet}\psi Y))\)</td>
 <td>Definition</td> 
</tr>

<tr>
<td>T2</td>
<td>\([\forall^{\bullet}X_{\mu} . g_{\mu \rightarrow\sigma} X \supset^{\bullet}\ess_{(\mu\rightarrow \sigma)\rightarrow \mu \rightarrow\sigma} gX]\)</td>
<td>A1, D1, A4, D2 (in K)</td> 
</tr>

<tr>
 <td>D3</td>
<td>\(\text{NE}_{\mu\rightarrow \sigma} = \lambda X_{\mu} .\forall^{\bullet}\varphi_{\mu \rightarrow\sigma}.&nbsp;(\ess&nbsp;\varphi X \supset^{\bullet} \Box^{\bullet}\exists^{\bullet}Y_{\mu}.&nbsp;\varphi Y)\)</td>
 <td>Definition</td> 
</tr>

<tr>
 <td>A5</td>
<td>\([p_{(\mu\rightarrow \sigma)\rightarrow\sigma}\text{NE}_{\mu\rightarrow\sigma}]\)</td>
 <td>Axiom</td> 
</tr>

<tr>
 <td>T3</td>
<td>\([\Box^{\bullet}\exists X_{\mu} . g_{\mu \rightarrow\sigma} X]\)</td>
 <td>D1, C, T2, D3, A5 (in KB)</td> 
</tr>

</table>

<p>
Besides helping in the completion of the proof, the automated theorem
provers were also very instrumental in the finding of some novel
results. First, G&ouml;del&rsquo;s set of original assumptions was shown to
be inconsistent by LEO-II by proving that self-difference becomes an
essential property of every entity; a re-formulation of the definition
of essence due to Dana Scott&mdash;this involved the addition of a
missing conjunct, \(\varphi X\), in the definition&mdash;was shown
by Nitpick to be consistent. Second, LEO-II and Satallax managed to
prove C, T1 and T2 using only the logic system K and, moreover,
Nitpick found a counter-model for T3 in K thus showing that more
logical power is required to complete the rest of the proof. Third,
using LEO-II and Satallax, it is shown that the logic system KB
(system K with the Brouwer axiom) is sufficient to establish the
necessity of God&rsquo;s existence,
\(\Box^{\bullet}\exists^{\bullet}X_{\mu} . g_{\mu \rightarrow\sigma} X\),
which is a double-win for automated reasoning: a gain in logical
economy, and the deeper philosophical result of having effectively
dismissed a major criticism against G&ouml;del&rsquo;s proof, namely his use
of the stronger logic system S5. Fourth, the authors also prove in KB
that:</p>

\[(\forall^{\bullet}\varphi_{\mu\rightarrow\sigma} .\forall^{\bullet}X_{\mu} . (g_{\mu \rightarrow \sigma} X \supset^{\bullet} ({\sim}^{\bullet}(p_{(\mu \rightarrow \sigma)\rightarrow\sigma} \varphi) \supset^{\bullet} {\sim}^{\bullet}(\varphi X)))\]


<p>
as well as:</p>


\[\forall^{\bullet}X_{\mu} .\forall^{\bullet}Y_{\mu} . (g_{\mu \rightarrow \sigma} X \supset^{\bullet} (g_{\mu \rightarrow\sigma} Y \supset^{\bullet} X =^{\bullet} Y)),\]
<p>
that is, that God is flawless and that monotheism holds, respectively.
At this point, it would be fair to say that any of these results would
be enough to vindicate the application of automated reasoning in exact
philosophy. Now, for the bad news followed by good news: Fifth, the
formula
\(s_{\sigma} \supset^{\bullet} \Box^{\bullet}s_{\sigma}\)
can also be formally derived which is unfortunate since it implies
that there are no contingent truths and that everything is determined,
i.e. there is no free will. However, the issue has been addressed by
follow-up work based on Fitting&rsquo;s and Anderson&rsquo;s variants of the
ontological argument (Fuenmayor &amp; Benzm&uuml;ller 2017, Fitting
2002, Anderson 1990). </p>

<p>
<strong>Abstract object theory</strong> (AOT) is a metaphysical theory of abstract objects (Zalta 1983). Abstract objects are the objects presupposed by scientific theories: numbers, natural laws, properties, states of affairs, possibilities, etc. AOT draws a fundamental distinction between ordinary objects defined as \(O!x =_{df} \Diamond E!x\) and abstract objects defined as \(A!x =_{df}\lnot\Diamond E!x\). AOT also provides two distinctive modes of predication: exemplification \((Fx\), more generally \(Fx_1 ...x_n)\) and encoding \((xF\), &lsquo;\(x\) encodes \(F\)&rsquo;, and more generally \(x_1 ...x_n F)\). AOT adds encoding to 2<sup>nd</sup>-order S5 quantified modal logic without identity, extended with definite descriptions \(\iota x \phi\), lambda expressions \(\lambda x_1 ...x_n \phi^*\) (where \(\phi^*\) means no encoding of subformulas), and a free logic for complex terms (Zalta 1983, Zalta 1988). The key axioms of AOT are comprehension for abstract objects, \[\exists x(A!x \amp \forall F(xF \equiv \phi))\] with no free \(x\)&rsquo;s in \(\phi\), and classical \(\lambda\)-conversion, \[[\lambda y_1 ...y_n \phi^*]x_1 ...x_n \equiv \phi^* (x_1 /y_1,..., x_n /y_n)\] with no descriptions in \(\phi^*\). These imply comprehension for relations, \[\exists F^n \Box \forall x_1 ...x_n (F^n x_1 ...x_n \equiv \phi^*)\] with no descriptions in \(\phi^*\). Other principles include \[\begin{align}
O!x &amp;\rightarrow \Box \lnot\exists FxF\\
 \Diamond xF &amp;\rightarrow \Box xF\\
 O!x \amp O!y &amp; \rightarrow(x = y \rightarrow \Box \forall F(Fx \equiv Fy))\\
 A!x \amp A!y &amp; \rightarrow(x = y \rightarrow \Box \forall F(xF \equiv yF))\end{align}\] and \(\iota x(A!x \amp \forall F(xF \equiv \phi))\) always being well-defined. To give a sense of the expressive power and application of AOT, here are some examples of AOT&rsquo;s ability to define metaphysical entities as abstract objects and derive interesting results (Zalta 2018):
</p>

<blockquote>

<p>
<strong>Plato&rsquo;s Forms (e.g. triangle)</strong>
<br/>
\(\Phi_T =_{df}\iota x(A!x \amp \forall F(xF \equiv \Box \forall x(Tx \rightarrow Fx)))\)
</p>

<p>
<strong>Leibniz&rsquo;s Concepts (e.g. Alexander)</strong>
<br/>
\(c_a =_{df}\iota x(A!x \amp \forall F(xF \equiv Fa))\)
</p>

<p>
<strong>Frege Numbers</strong>
<br/>
\(0 =_{df}\iota x(A!x \amp \forall F(xF \equiv\lnot\exists yFy))\)
<br/>
\(1 =_{df}\iota x(A!x \amp \forall F(xF \equiv \exists y(Fy \amp \forall z(Fz \rightarrow z = y))))\)
<br/>
etc.
</p>

<p>
<strong>Truth Values</strong>
<br/>
\(\top =_{df}\iota x(A!x \amp \forall F(xF \equiv \exists p(p \amp F = [\lambda y p])))\)
<br/>
\(\bot =_{df}\iota x(A!x \amp \forall F(xF \equiv \exists p(\lnot p \amp F = [\lambda y p])))\)
</p>

<p>
<strong>Situations and Possible Worlds</strong>
<br/>
\(\textit{Situation}(x) =_{df} \forall F(xF \rightarrow \exists p(F = [\lambda y p]))\)
<br/>
\(s \vDash p =_{df} s[\lambda y p]\)
<br/>
\(\textit{PossibleWorld}(x) =_{df} \Diamond \forall p((s \vDash p) \equiv p)\), from which one can derive Leibniz&rsquo;s Principle that \(p\) is necessary if true in all worlds, \(\vdash \Box p \equiv \forall w(w \vDash p)\), and also Lewis&rsquo; Principle that for every way the world might be, there is a world which is that way, \(\vdash \Diamond p \equiv \exists w(w \vDash p)\)
</p>

<p>
<strong>Theoretical Mathematical Objects (e.g. null set in ZF)</strong>
<br/>
\(\varnothing_{ZF} =_{df}\iota x(A!x \amp \forall F(xF \equiv ZF \vDash F\varnothing))\)
</p>

</blockquote>

<p>
AOT is under continuous development and for further details of the theory the reader is referred to one of its latest formulations (Zalta 2022). The computational analysis of AOT was pioneered by Fitelson and Zalta (Fitelson &amp; Zalta 2007) by using the first-order system Prover9. Conducting computational investigations of a higher-order theory like AOT using a first-order prover has inherent limitations and it would be preferable to work within the computational framework of a higher-order prover. AOT, however, is based on a logical foundation that is significantly different from classical higher-order logic and, ideally, one would want to work with a theorem prover for AOT itself. The downside to this is, of course, that one would need to build such a prover and this is no trivial task. But one can &ldquo;approximate&rdquo; such a system to a large extent by building instead a <strong>shallow semantic embedding</strong> (SSE) of AOT into an existing higher-order prover like e.g. Isabelle/HOL where the researcher can faithfully represent AOT&rsquo;s axioms and deductive system (Benzm&uuml;ller 2019, Kirchner 2021). In this setting, Isabelle/HOL acts as the metalogical framework for the SSE that provides the &ldquo;custom&rdquo; theorem prover for AOT. But there is always a trade-off, and building the embedding brings its own set of challenges. Key among these is that there are aspects of AOT which can be easily formulated in relational type theory but present a challenge when being re-formulated in the underlying functional type theory of Isabelle/HOL. For example, not every formula in AOT can be converted to a \(\lambda\)-term unless one is willing to face a contradiction! With some ingenuity, one can use Isabelle/HOL&rsquo;s functional calculus to define some complex types to help build an Aczel model of AOT, and then interpret those offending \(\lambda\)-expressions in terms of the complex types all in the context of a free logic. The bottom line: Every formula of AOT can then be expressed as a \(\lambda\)-term but not all these terms denote; hence, consistency is preserved.
</p>

<p>
Key aspects of the SSE of AOT in Isabelle/HOL include the model construction of the embedding using Aczel models, reproducing the syntax of AOT, extending Isabelle&rsquo;s &ldquo;outer&rdquo; syntax (to deal with certain challenges of reasoning in AOT), representing an abstract semantics of AOT, specifying the logic of the Hilbert \(\varepsilon\) operator, representing the logic of the actuality operator, representing hyperintensionality, deriving the axiom system and deductive system, and other considerations&mdash;see Kirchner 2021 for details. Salient among these is the use of <strong>abstraction layers</strong> (Kirchner 2017) which play an important role in determining the derivability of a statement from the deductive system of the target theory (AOT here). An abstraction layer is constructed by proving that the axioms and deduction rules of AOT are semantically valid in the SSE; after this, all subsequent reasoning (as conducted by e.g. sledgehammer, Isabelle/HOL&rsquo;s main tool for automated reasoning) is restricted to rely on the derived axioms and deduction rules themselves and may not refer to the underlying semantics. The work took about 25,000 lines of Isabelle/HOL: About 5,000 lines to build the required model structure and semantics as well as the syntax representation of AOT, and the remaining 20,000 for the logic reasoning in AOT. Under the embedding, computational explorations of AOT can be conducted in a more &ldquo;native&rdquo; fashion as illustrated below in the 9-line proof in Isabelle/HOL notation that no object is both ordinary and abstract (Kirchner 2021):
</p>

<table class="monospace smaller">
<tr><td>7571</td><td>&nbsp;&nbsp;<strong>AOT_theorem</strong> partition: &#10092; &#172;&exist;x (O!x &amp; A!x) &#10093;</td></tr>

<tr><td>7572</td><td>&nbsp;&nbsp;<strong>proof</strong>(rule "raa-cor:2")</td></tr>

<tr><td>7573</td><td>&nbsp;&nbsp;<strong>AOT_assume</strong> &#10092; &exist;x (O!x &amp; A!x) &#10093;</td></tr>

<tr><td>7574</td><td>&nbsp;&nbsp;then <strong>AOT_obtain</strong> a <strong>where</strong> &#10092; O!a &amp; A!a &#10093;</td></tr>

<tr><td>7575</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>using</strong> "&exist;E" [rotated] by blast</td></tr>

<tr><td>7576</td><td>&nbsp;&nbsp;<strong>AOT_thus</strong> &#10092; p &amp; &#172;p &#10093; for p</td></tr>

<tr><td>7577</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>by</strong> (metis "&amp;E"(1) "Conjunction Simplification"(2) "&equiv;E"(1)</td></tr>

<tr><td>7578</td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"modus-tollens:1" "oa-contingent:2" "raa-cor:3")</td></tr>

<tr><td>7579</td><td>&nbsp;&nbsp;<strong>qed</strong></td></tr>

</table>

<p>
An additional 1,000 lines of such computational derivations lead to the result that there are distinct abstract objects which cannot be distinguished by exemplification: \(\exists x\exists y(A!x \amp A!y \amp x \ne y \amp \forall F(Fx \equiv Fy))\). A few more derivations land a significant novel discovery which provides the analytical means to determine if a \(\lambda\)-expression denotes in AOT: \([\lambda x \phi]\downarrow \equiv \Box \forall x\forall y(\forall F(Fx \equiv Fy) \rightarrow(\phi \equiv \phi(y/x))\) with \(y\) not free in \(\phi\). And, as a corollary, \([\lambda x \phi]\downarrow \rightarrow \forall x\forall y(\forall F(Fx \equiv Fy) \rightarrow \Box(\phi \equiv \phi(y/x))\) with \(y\) not free in \(\phi\). The proof of the latter in the context of the SSE takes the 20 lines in Isabelle/HOL given below:
</p>

<table class="monospace smaller">

<tr><td>8761</td><td>&nbsp;&nbsp;<strong>AOT_theorem</strong> "kirchner-thm-cor:1":</td></tr>
<tr><td>8762</td><td>&nbsp;&nbsp;&nbsp;&nbsp;&#10092; [&lambda;x &phi;{x}]&darr; &rarr; &forall;x&forall;y(&forall;F([F]x &equiv; [F]y) &rarr; &#9633;(&phi;{x} &equiv; &phi;{y})) &#10093;</td></tr>
<tr><td>8763</td><td>&nbsp;&nbsp;<strong>proof</strong>(rule "&rarr;I"; rule GEN; rule GEN; rule "&rarr;I")</td></tr>
<tr><td>8764</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>fix</strong> x y</td></tr>
<tr><td>8765</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>AOT_assume</strong> &#10092; [&lambda;x &phi;{x}]&darr; &#10093;</td></tr>
<tr><td>8766</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>AOT_hence</strong> &#10092; &#9633;&forall;x&forall;y (&forall;F ([F]x &equiv; [F]y) &rarr; (&phi;{x} &equiv; &phi;{y})) &#10093;</td></tr>
<tr><td>8767</td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>by</strong> (rule "kirchner-thm:1"[THEN "&equiv;E"(1)])</td></tr>
<tr><td>8768</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>AOT_hence</strong> &#10092; &forall;x&#9633;&forall;y (&forall;F ([F]x &equiv; [F]y) &rarr; (&phi;{x} &equiv; &phi;{y})) &#10093;</td></tr>
<tr><td>8769</td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>using</strong> CBF[THEN "&rarr;E"] <strong>by</strong> blast</td></tr>
<tr><td>8770</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>AOT_hence</strong> &#10092; &#9633;&forall;y (&forall;F ([F]x &equiv; [F]y) &rarr; (&phi;{x} = &phi;{y})) &#10093;</td></tr>
<tr><td>8771</td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>using</strong> "&forall;E" <strong>by</strong> blast</td></tr>
<tr><td>8772</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>AOT_hence</strong> &#10092; &forall;y &#9633;(&forall;F ([F]x &equiv; [F]y) &rarr; (&phi;{x} &equiv; &phi;{y})) &#10093;</td></tr>
<tr><td>8773</td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>using</strong> CBF[THEN "&rarr;E"] <strong>by</strong> blast</td></tr>
<tr><td>8774</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>AOT_hence</strong> &#10092; &#7633;(&forall;F ([F]x &equiv; [F]y) &rarr; (&phi;{x} &equiv; &phi;{y})) &#10093;</td></tr>
<tr><td>8775</td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>using</strong> "&forall;E" <strong>by</strong> blast</td></tr>
<tr><td>8776</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>AOT_hence</strong> &#10092; &#9633;&forall;F([F]x &equiv; [F]y) &rarr; &#9633;(&phi;{x} &equiv; &phi;{y}) &#10093;</td></tr>
<tr><td>8777</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>&nbsp;&nbsp;using</strong> "qml:1"[axiom_inst] "vdash-properties:6" <strong>by</strong> blast</td></tr>
<tr><td>8778</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>moreover AOT_assume</strong> &#10092; &forall;F([F]x &equiv; [F]y) &#10093;</td></tr>
<tr><td>8779</td><td>&nbsp;&nbsp;&nbsp;&nbsp;<strong>ultimately AOT_show</strong> &#10092; &#9633;(&phi;{x} &equiv; &phi;{y}) &#10093; <strong>using</strong> "&rarr;E" "ind-nec" <strong>by</strong> blast</td></tr>
<tr><td>8780</td><td>&nbsp;&nbsp;<strong>qed</strong></td></tr>
</table>

<p>
After establishing further results about basic logical objects, restricted variables, the extended relation comprehension, and possible worlds, the computational exploration can then be redirected to Dedekind-Peano arithmetic where its postulates for natural numbers are formally derived in a system free of mathematical primitive notions and mathematical axioms&mdash;Frege&rsquo;s Theorem&mdash;and thereby supporting the claim that AOT can provide a philosophically grounded basis for objects of mathematics. The computational approach in Kirchner 2021 is guided by a proof outline that was previously given in Zalta 1999 but that now, being reconstructed in Isabelle/HOL, produces derivations of the postulates in full detail and formality.
</p>


<blockquote>
<p>
<em>Postulate 1</em>
<br/>
<span class="monospace">
<strong>AOT_theorem</strong> "0-n": &#10092; [&#8469;]0 &#10093;
</span>
</p>
<p>
<em>Postulate 2</em>
<br/>
<span class="monospace">
<strong>AOT_theorem</strong> "0-pred": &#10092; &#172;&exist;n [&#8473;]n 0 &#10093;
</span>
</p>
<p>
<em>Postulate 3</em>
<br/>
<span class="monospace">
<strong>AOT_theorem</strong> "no-same-succ": &#10092; &forall;n&forall;m&forall;k([&#8473;]nk &amp; [&#8473;]mk &rarr; n = m) &#10093;
</span>
</p>
<p>
<em>Postulate 4</em>
<br/>
<span class="monospace">
<strong>AOT_theorem</strong> "th-succ": &#10092; &forall;n&exist;!m [&#8473;]nm &#10093;
</span>
</p>
<p>
<em>Postulate 5</em>
<br/>
<span class="monospace">
<strong>AOT_theorem</strong> induction: &#10092; &forall;F([F]0 &amp; &forall;n&forall;m([&#8473;]nm &rarr; ([F]n &rarr; [F]m)) &rarr; &forall;n[F]n) &#10093;
</span>
</p>

</blockquote>

<p>
The computational explorations described above were done using the second-order fragment of AOT but the SSE could be extended to the full higher-order logic AOT (Kirchner 2021) where it could be applied to the analysis of theoretical mathematics. It is important to stress that embedding a target theory within the higher-order logic of an existing prover results in more than just a formalization of the theory: The SSE allows for the discovery of new results within the target theory, as exemplified above, as well as the study and further development of the target theory itself such as placing the theory on firmer foundations, e.g. avoiding known paradoxes (Zalta 2018, Kirchner 2021). The computational analysis of AOT described in here can also be construed as yet another test of the concept of embedding theories, simple and complex alike, within the framework of a higher-order prover. It illustrates the power and convenience of the approach, and researchers in automated reasoning may want to seriously consider using an SSE in their theorem-proving efforts (Benzm&uuml;ller 2019).
</p>

<p>
Leibniz&rsquo;s dream was to have a <em>charateristica universalis</em> and
<em>calculus ratiocinator</em> that would allow us to reason in
metaphysics and morals in much the same way as we do in geometry and
analysis; that is to say, to settle disputes between philosophers as
accountants do: &ldquo;To take pen in hand, sit down at the abacus
and, having called in a friend if they want, say to each other: Let us
calculate!&rdquo; From the above applications of automated reasoning,
one would agree with the researchers when they imply that these
results achieve, to some extent, Leibniz&rsquo;s goal of a computational
metaphysics (Fitelson &amp; Zalta 2007, Benzm&uuml;ller &amp; Paleo
2014).
</p>

<h4>Procedural epistemology</h4>

<p>
Work in computational metaphysics has implications in other areas in philosophy such as e.g. epistemology. An obvious example is our improved epistemological standing when errors in our reasoning are (computationally) detected and corrected. Also, proofs produced by automated reasoning systems can help us better understand complex arguments, and see more quickly the consequences of revising our theories by the introduction, or removal, or axioms&mdash;a sort of &ldquo;what-if analysis&rdquo;. To illustrate, in the desire to simplify the foundations of AOT, one can attempt the removal of constraints in the comprehension principle but it can be shown that this move leads to a paradox in a non-trivial way (Kirchner 2021). Finding alternative axiom sets for a given theory can help reduce the epistemological load needed to prove meta-theoretical results such as soundness. In brief, &ldquo;one of the great benefits of using computational techniques is that enables us to see exactly what the commitments of our theories are&rdquo; (Zalta 2018).
</p>

<p>
As a direct application in epistemology, a nonmonotonic theorem prover can provide the basis for a
&ldquo;computational laboratory&rdquo; in which to explore and
experiment with different models of artificial rationality; the
theorem prover can be used to equip an artificial rational agent with
an inference engine to reason and gain information about the world. In
such <strong>procedural epistemology</strong>, a rational agent is
defeasible (i.e. nonmonotonic) in the sense that new reasoning leads
to the acceptance of new beliefs but also to the retraction of
previously held beliefs in the presence of new information. At any
given point in time, the agent holds a set of justified beliefs but
this set is open to revision and is in a continuous set of flux as
further reasoning is conducted. This model better reflects our
accepted notion of rationality than a model in which all the beliefs
are warranted, i.e. beliefs that once are attained are never
retracted. Actually, a set of warranted beliefs can be seen as
justified beliefs &ldquo;in the limit&rdquo;, that is, as the ultimate
epistemic goal in the agent&rsquo;s search for true knowledge about its
world. (Pollock 1995) offers the following definition: </p>

<p>
A set is defeasible enumerable iff there is an effective computable
function \(f\) such that for each \(n,
f(n)\) is a recursive set and the following two
conditions hold </p>

<dl class="sentag indent">
 <dt>1.</dt>
 <dd>\((\forall x)(x \in A \rightarrow 
(\exists n)(\forall m \gt n) x \in f(m))\)</dd>

 <dt>2.</dt>
 <dd>\((\forall x)(x \not\in A \rightarrow 
(\exists n)(\forall m \gt n) x \not\in f(m))\)</dd> 
</dl>

<p>
To compare the concepts, if \(A\) is recursively enumerable then
there is a sequence of recursive sets \(A_i\) such that
each \(A_i\) is a subset of \(A\) with each
\(A_i\) growing monotonically, approaching \(A\)
in the limit. But if \(A\) is only defeasibly enumerable then the
\(A_i\)&rsquo;s still approach \(A\) in the limit but
may not be subsets of \(A\) and approach \(A\)
intermittently from above and below. The goal of the OSCAR Project
(Pollock 1989) is to construct a general theory of rationality and
implement it in an artificial computer-based rational agent. As such,
the system uses a defeasible automated reasoner that operates
according to the maxim that the set of warranted beliefs should be
defeasible enumerable. OSCAR has been in the making for some time and
the application of automated nonmonotonic reasoning has also been used
to extend its capabilities to reason defeasibly about perception and
time, causation, and decision-theoretic planning (Pollock 2006). </p>

<h3><a name="Mathematics">4.7 Mathematics</a></h3>

<p>
One of the main goals of automated reasoning has been the automation
of mathematics. An early attempt at this was Automath (de Bruijn 1968)
which was the first computer system used to check the correctness of
proofs and whole books of mathematics, including Landau&rsquo;s
<em>Grundlagen der Analysis</em> (van Benthem Jutting 1977). Automath
has been superseded by more modern and capable systems, most notably
Mizar. The Mizar system (Trybulec 1979, Muzalewski 1993) is based on
Tarski-Grothendieck set theory and, like Automath, consists of a
formal language which is used to write mathematical theorems and their
proofs. Once a proof is written in the language, it can be checked
automatically by Mizar for correctness. Mizar proofs are formal but
quite readable, can refer to definitions and previously proved
theorems and, once formally checked, can be added to the growing Mizar
Mathematical Library (MML) (Bancerek &amp; Rudnicki 2003, Bancerek
<em>et al</em>. 2018). As of June 2018, MML contained about 12,000
definitions and 59,000 theorems. The Mizar language is a subset of
standard English as used in mathematical texts and is highly
structured to ensure the production of rigorous and semantically
unambiguous texts. Here&rsquo;s a sample proof in Mizar of the existence of
a rational number <em>x\(^y\)</em> where \(x\) and
\(y\) are irrational: </p>

<table class="monospace smaller">
<tr>
  <td>theorem T2:</td></tr>
<tr>
  <td>&nbsp;&nbsp;ex x, y st x is irrational &amp; y is irrational
&amp; x.^.y is rational</td></tr>
<tr>
  <td>proof</td></tr>
<tr>
  <td>&nbsp;&nbsp;set w = &radic;2;</td></tr>
<tr>
  <td>&nbsp;&nbsp;H1: w is irrational by INT_2:44,T1;</td></tr>
<tr>
  <td>&nbsp;&nbsp;w&gt;0 by AXIOMS:22,SQUARE_1:84;</td></tr>
<tr>
  <td>&nbsp;&nbsp;then (w.^.w).^.w = w.^.(w&bull;w) by
POWER:38</td></tr>
<tr>
  <td>&nbsp;&nbsp;&nbsp;&nbsp;.= w.^.(w<sup>2</sup>) by
SQUARE_1:58</td></tr>
<tr>
  <td>&nbsp;&nbsp;&nbsp;&nbsp;.= w.^.2 by SQUARE_1:88</td></tr>
<tr>
  <td>&nbsp;&nbsp;&nbsp;&nbsp;.= w<sup>2</sup> by POWER:53</td></tr>
<tr>
  <td>&nbsp;&nbsp;&nbsp;&nbsp;.= 2 by SQUARE_1:88;</td></tr>
<tr>
  <td>&nbsp;&nbsp;then H2: (w.^.w).^.w is rational by
RAT_1:8;</td></tr>
<tr>
  <td>&nbsp;&nbsp;per cases;</td></tr>
<tr>
  <td>&nbsp;&nbsp;suppose H3: w.^.w is rational;</td></tr>
<tr>
  <td>&nbsp;&nbsp;&nbsp;&nbsp;take w, w;</td></tr>
<tr>
  <td>&nbsp;&nbsp;&nbsp;&nbsp;thus thesis by H1,H3;</td></tr>
<tr>
  <td>&nbsp;&nbsp;suppose H4: w.^.w is irrational;</td></tr>
<tr>
  <td>&nbsp;&nbsp;&nbsp;&nbsp;take w.^.w, w;</td></tr>
<tr>
  <td>&nbsp;&nbsp;&nbsp;&nbsp;thus thesis by H1,H2,H4;</td></tr>
<tr>
  <td>end;</td></tr>
</table>

<p>
Examples of proofs that have been checked by Mizar include the
Hahn-Banach theorem, the Brouwer fixed-point theorem, K&#337;nig&rsquo;s lemma,
the Jordan curve theorem, and G&ouml;del&rsquo;s completeness theorem.
Rudnicki (2004) discusses the challenges of formalizing Witt&rsquo;s proof
of the Wedderburn theorem: <em>Every finite division ring is commutative</em>.
The theorem was formulated easily using the existing formalizations
available in MML but the proof demanded further entries into the
library to formalize notions and facts from algebra, complex numbers,
integers, roots of unity, cyclotomic polynomials, and polynomials in
general. It took several months of effort to supply the missing
material to the MML library but, once in place, the proof was
formalized and checked correct in a matter of days. Clearly, a
repository of formalized mathematical facts and definitions is a
prerequisite for more advanced applications. The QED Manifesto (Boyer
<em>et al</em>. 1994, Wiedijk 2007) has such aim in mind and there is
much work to do: Mizar has the largest such repository but even after
30 years of work &ldquo;it is minuscule with respect to the body of
established mathematics&rdquo; (Rudnicki 2004). This last remark
should be construed as a call to increase the effort toward this
important aspect in the automation of mathematics. </p>

<p>
Mizar&rsquo;s goal is to assist the practitioner in the formalization of
proofs and to help check their correctness; other systems aim at
finding the proofs themselves. Geometry has been a target of early
automated proof-finding efforts. Chou (1987) proves over 500 geometry
theorems using the algebraic approach offered by Wu&rsquo;s method and the
Gr&ouml;bner basis method by representing hypotheses and conclusions
as polynomial equations. Quaife (1992) provides another early effort
to find proofs in first-order mathematics: over 400 theorems in
Neumann-Bernays-G&ouml;del set theory, over 1,000 theorems in
arithmetic, a number of theorems in Euclidian geometry, and
G&ouml;del&rsquo;s incompleteness theorems. The approach is best described
as semi-automatic or &ldquo;interactive&rdquo; with the user providing
a significant amount of input to guide the theorem-proving effort.
This is no surprise since, as one applies automated reasoning systems
into richer areas of mathematics, the systems take more on the role of
proof assistants than theorem provers. This is because in richer
mathematical domains the systems need to reason about theories and
higher-order objects which in general takes them deeper into the
undecidable. <strong>Interactive theorem proving</strong> is arguably
the &ldquo;killer&rdquo; application of automated reasoning in
mathematics and much effort is being expended in the building of
increasingly capable reasoning systems that can act as assistants to
professional mathematicians. The proof assistant Isabelle/HOL provides
the user with an environment in which to conduct proofs expressed in a
structured, yet human-readable, higher-order logic language and which
incorporates a number of facilities that increase the user&rsquo;s
productivity, automates proof-verification and proof-finding tasks,
and provides a modular way for the user to build and manage theory
hierarchies (Ballarin 2014). More recently, using both automated and interactive theorem proving techniques, Quafie&rsquo;s work in Tarskian geometry has been extended with the proving of additional theorems (some of which required Ph.D. level proofs), including four challenge problems left unsolved by Quaife, and the derivation of Hilbert&rsquo;s 1899 axioms for geometry from Tarski&rsquo;s axioms (Beeson and Wos 2017).
</p>

<p>
Different proof assistants offer different capabilities measured by
their power at automating reasoning tasks, supported logic, object
typing, size of mathematical library, and readability of input and
output. A &ldquo;canonical&rdquo; proof which is not too trivial but
not too complex either can be used as a baseline for system
comparison, as done in (Wiedijk 2006) where the authors of seventeen
reasoning systems are tasked with establishing the irrationality of
\(\sqrt{} 2\). The systems discussed are certainly more capable than this
and some have been used to assist in the formalization of far more
advanced proofs such as Erd&ouml;s-Selberg&rsquo;s proof of the Prime Number
Theorem (about 30,000 lines in Isabelle), the formalization of the
Four Color Theorem (60,000 lines in Coq), and the Jordan Curve Theorem
(75,000 lines in HOL Light). A milestone in interactive theorem
proving was reached in 2012 when, after six-years of effort and using
the Coq proof assistant, George Gonthier and his team completed the
formal verification of the 255-page proof of the Feit-Thompson
theorem, also known as the Odd Order Theorem, a major step in the
classification of finite simple groups. Other, more recent, successes include the resolution of Keller&rsquo;s conjecture (Brakensiek <em>et al.</em> 2022), the formalization of metric spaces (Maggesi 2018), and the formalization and classification of finite fields (Chan and Norrish 2019).</p>

<p>
The above notwithstanding, automated reasoning has had a small impact
on the practice of doing mathematics and there is a number of reasons
given for this. One reason is that automated theorem provers are not
sufficiently powerful to attempt the kind of problems mathematicians
typically deal with; that their current power is, at best, at the
level of first-year undergraduate mathematics and still far from
leading edge mathematical research. While it is true that current
systems cannot prove completely on their own problems at this level of
difficulty we should remember that the goal is to build reasoning
systems so that &ldquo;eventually machines are to be an aid to
mathematical research and not a substitute for it&rdquo; (Wang 1960).
With this in mind, and while the automated reasoning community
continues to try to meet the grand challenge of building increasingly
powerful theorem provers, mathematicians can draw now some of the
benefits offered by current systems, including assistance in
completing proof gaps or formalizing and checking the correctness of
proposed proofs. Indeed, the latter may be an application that could
help address some real issues currently being faced by the
mathematical community. Consider the announcement by Daniel Goldston
and Cem Yildrim of a proof of the Twin Prime Conjecture where,
although experts initially agreed that the proof was correct, an
insurmountable error was found shortly after. Or, think about the case
of Hales&rsquo; proof of the Kepler Conjecture which asserts that no packing
of congruent balls in Euclidean 3-space has density greater than the
face-centered cubic packing. Hales&rsquo; proof consists of about 300 pages
of text and a large number of computer calculations. After four years
of hard work, the 12-person panel assigned by <em>Annals of
Mathematics</em> to the task of verifying the proof still had genuine
doubts about its correctness. Thomas Hales, for one, took upon himself
to formalize his proof and have it checked by an automated proof
assistant with the aim of convincing others of its correctness (Hales
2005b, in Other Internet Resources). His task was admittedly heavy but
the outcome is potentially very significant to both the mathematical
and automated reasoning communities. All eyes were on Hales and his
formal proof as he announced the completion of the <em>Flyspeck</em>
project (Hales 2014, in Other Internet Resources; Hales 2015) having
constructed a formal proof of the conjecture using the Isabelle and
HOL Light automated proof assistants: &ldquo;In truth, my motivations
for the project are far more complex than a simple hope of removing
residual doubt from the minds of few referees. Indeed, I see formal
methods as fundamental to the long-term growth of mathematics.&rdquo;
(Hales 2006).</p>

<p>
Church 1936a, 1936b and Turing 1936 imply the existence of
theorems whose shortest proof is very large, and the proof of the Four
Color Theorem in (Appel &amp; Haken 1977), the Classification of Simple
Groups in (Gorenstein 1982), and the proof of the Kepler Conjecture in
(Hales 2005a) may well be just samples of what is yet to come. As
(Bundy 2011) puts it: &ldquo;As important theorems requiring larger
and larger proofs emerge, mathematics faces a dilemma: either these
theorems must be ignored or computers must be used to assist with
their proofs.&rdquo;</p>

<p>
The above remarks also counter another argument given for not using
automated theorem provers: Mathematicians enjoy proving theorems, so
why let machines take away the fun? The answer to this is, of course,
that mathematicians can have even more fun by letting the machine do
the more tedious and menial tasks: &ldquo;It is unworthy of excellent
men to lose hours like slaves in the labour of calculation which could
safely be relegated to anyone else if machines were used&rdquo; (G. W.
Leibniz, <em>New Essays Concerning Human Understanding</em>). If still
not convinced, just consider the sobering prospect of having to
manually check the 23,000 inequalities used in Hales&rsquo; proof!</p>

<p>
Another reason that is given for the weak acceptance of automated
reasoning by the mathematical community is that the programs are not
to be trusted since they may contain bugs&mdash;software
defects&mdash;and hence may produce erroneous results. Formally
verifying automated reasoning programs will help ameliorate this,
particularly in the case of proof checkers. Proving programs correct
is no easy task but the same is true about proving theorems in
advanced mathematics: Gonthier proved correct the programs used in the
formalization of his proof of the Four Color Theorem, but he spent far
more effort formalizing all the graph theory that was part of the
proof. So ironically enough, it turns out that at least in this case,
and surely there are others, &ldquo;it is actually easier to verify
the correctness of the program than to verify the correctness of the
pen-and-paper mathematics&rdquo; (Wiedijk 2006). For theorem provers
and model finders, a complementary strategy would be to verify the
programs&rsquo; results as opposed to the programs themselves. Paraphrasing
(Slaney 1994): It does not matter to the mathematician how many
defects a program may have as long as the proof (or model) it outputs
is correct. So, the onus is in the verification of results, whether
produced by machine or man, and checking them by independent parties
(where of course the effort may well use automated checkers) should
increase the confidence on the validity of the proofs. </p>

<p>
It is often argued that automated proofs are too long and detailed.
That a proof can be expressed in more elementary steps is in principle
very beneficial since this allows a mathematician to request a proof
assistant justify its steps in terms of simpler ones. But proof
assistants should also allow the opposite, namely to abstract detail
and present results and their justifications using the higher-level
concepts, language, and notation mathematicians are accustomed to.
Exploiting the hierarchical structure of proofs as done in (Denney
2006) is a step in this direction but more work along these lines is
needed. Having the proof assistant work at the desired level of
granularity provides more opportunity for insight during the proof
discovery process. This is an important consideration since
mathematicians are equally interested in gaining understanding from
their proofs as in establishing facts&mdash;more about this below. </p>

<p>
(Bundy 2011) alludes to a deadlock that is preventing the wider
adoption of theorem provers by the mathematical community: On the one
hand, the mathematicians need to use the proof assistants to build a
large formal library of mathematical results. But, on the other hand,
they do not want to use the provers since there is no such library of
previously proved results they can build upon. To break the impasse, a
number of applications are proposed of which assisting the
mathematician in the search of previously proved theorems is of
particular promise. Indeed, a thoughtful reuse of library results can lead to concise proofs of non-trivial mathematical problems as exemplified in the proving of some fundamental theorems of linear algebra (Aransay and Divans&oacute;n 2017) and probability theory (Avigad, H&ouml;lzl and Serafin 2017). During its history, mathematics has accumulated a
huge number of theorems and the number of mathematical results
continues to grow dramatically. In 2010, <em>Zentralblatt MATH</em>
covered about 120,000 new publications (Wegner 2011). Clearly, no
individual researcher can be acquainted with all this mathematical
knowledge and it will be increasingly difficult to cope with one&rsquo;s
ever-growing area of specialty unless assisted with automated
theorem-proving tools that can search in intelligent ways for
previously proved results of interest. An alternative approach to this
problem is for mathematicians to tap into each other&rsquo;s knowledge as
enabled in computational social systems like <em>polymath</em> and
<em>mathoverflow</em>. The integration of automated reasoning tools
into such social systems would increase the effectiveness of their
collective intelligence by supporting &ldquo;the combination of
precise formal deductions and the more informal loose interaction seen
in mathematical practice&rdquo; (Martin &amp; Pease 2013, in Other
Internet Resources). </p>

<p>
Due to real pressing needs from industry, some applications of
automated reasoning in pure and applied mathematics are more of
necessity than choice. After having worked on the formalization of
some elementary real analysis to verify hardware-based floating point
trigonometric functions, (Harrison 2006, Harrison 2000) mentions the
further need to formalize <em>more</em> pure mathematics&mdash;italics
are his&mdash;to extend his formalization to power series for
trigonometric functions and basic theorems about Diophantine
approximations. Harrison finds it surprising that &ldquo;such
extensive mathematical developments are used simply to verify that a
floating point tangent function satisfies a certain error bound&rdquo;
and, from this remark, one would expect there are other industrial
applications that will demand more extensive formalizations.</p>

<p>
Albeit not at the rate originally anticipated, automated reasoning is
finding applications in mathematics. Of these, formal verification of
proofs is of special significance since it not only provides a viable
mechanism to check proofs that humans alone could not but it also has,
as a side effect, the potential to redefine what it would take for a
proof to be accepted as such. As the use of automated reasoning
assistants becomes more widespread one can envision their use
following a certain methodical order: First, automated reasoning tools
are used for theory exploration and discovery. Then, having identified
some target problem, the practitioner works interactively with an
automated assistant to find proofs and establish facts. Finally, an
automated proof checker is used to check the correctness of all final
proofs prior to being submitted for publication and being made
available to the rest of the mathematical community via the creation
of new entries in a repository of formalized mathematics. It is indeed
a matter of time before the application of automated proof assistants
becomes an everyday affair in the life of the mathematician; it is the
grand challenge of the automated reasoning community to make it happen
sooner than later.</p>

<p>
Besides formal verification, or <em>certification</em>, another important aspect of a proof is the <em>explanation</em> it provides; that is, the reasons it gives as to why the given statement is actually true. This, needless to say, is an important source of insight and for many mathematicians it may be the single most valuable aspect of a proof as it allows them to gain a better understanding of the nature of the statement being established and of the mathematical theory and objects involved; moreover, the approach used in the proof has the potential of being applicable to the proving of other mathematical results. So when it comes to building theorem provers to be used by the mathematical community, perhaps there should be less emphasis on the provers as certifiers, i.e. as proof checkers, and place more emphasis on the provers as proof solvers, i.e. as assistants in helping the mathematician complete proofs and explain the steps in doing so. Assuming that a prover were to be powerful enough to successfully attack proofs in the mathematician&rsquo;s area of research, it would be very desirable yet admittedly extremely challenging if the prover were to also use the very same notation, methods, and techniques of proof-solving used by the mathematician herself. One could safely bet that mathematicians would be more receptive to this type of human-oriented theorem prover because the prover would work the same way the mathematician does. More mathematicians may initially approach such a prover simply out of sheer curiosity; that is, just to see how the prover would go about proving a previously established result. This would certainly be of much interest to students of mathematics since they may need to see how a given problem (say, from their textbook) has been solved and, by inspecting the proof, want to learn how to do it on their own.
</p>
<p>
Virtually all automated theorem provers nowadays go about building their proofs in ways far more akin to machines than to humans (e.g. resolution-driven, connection methods). There are some systems that, after establishing a fact, can present the higher-level steps in the proof in a form more amenable to humans and do so by translating the machine-oriented steps into a human-readable format. The approach has merit but it has a significant limitation: How deep into the proof can one continue asking for an explanation before the translation breaks down? An alternative approach could try to address the situation head on: Why not build a system that directly proves theorems the way mathematicians actually do it? This is indeed a very tall order but the question is not new and it has been taken up in various forms by a small minority of researchers going back to the early days of automated theorem proving, including Bledsoe 1977 (investigations into non-resolution methods), Boyer and Moore 1979 (induction by recursive term rewriting), Bundy <em>et al</em>. 1991 (automated inductive theorem proving), Clarke and Zhao 1994 (integration of theorem provers with symbolic algebra systems), Portoraro 1994 (automated advice to students building symbolic logic proofs), Portoraro 1998 (strategic proof construction the way teachers of symbolic logic do and teach it), Pelletier 1998 (building proofs in the predicate calculus the way humans do it), Beeson 2001 (proof generation using mathematical methods), Buchberger <em>et al</em>. 2016 (computer-assisted natural-style mathematics), and others. More recently, Ganesalingam and Gowers 2017 describes a theorem prover that solves and presents proofs of elementary problems in metric space theory where the program&rsquo;s approach is hard to distinguish from what a mathematician might prove and write. To illustrate, below is the program&rsquo;s proof that the intersection of two open subsets of a metric space is itself open, and it is given as it was both solved and written by the program:
</p>

<blockquote>
<p>
<strong><em>Proof</em></strong>. Let \(x\) be an element of \(A\cap B\). Then \(x \in A\) and \(x \in B\). Therefore, since \(A\) is open, there exists \(\eta > 0\) such that \(u \in A\) whenever \(d(x, u) \lt \eta\) and since \(B\) is open, there exists \(\theta > 0\) such that \(v \in B\) whenever \(d(x, v) \lt \theta\). We would like to find \(\delta > 0\) s.t. \(y \in A\cap B\) whenever \(d(x, y) \lt \delta\). But \(y \in A\cap B\) if and only if \(y \in A\) and \(y \in B\). We know that \(y\cap A\) whenever \(d(x, y) \lt \eta\) and that \(y\cap B\) whenever \(d(x, y) \lt \theta\). Assume now that \(d(x, y) \lt \delta\). Then \(d(x, y) \lt \eta\) if \(\delta \le \eta\) and \(d(x, y) \lt \theta\) if \(\delta \le \theta\). We may therefore take \(\delta = \text{min}\{\eta , \theta \}\) and we are done.
</p>
</blockquote>

<p>
Impressive as it may be, the authors acknowledge a number of shortcomings and many outstanding challenges in the building and presentation of such proofs even for elementary problems in mathematics, and the reader is referred to their article for details. As we have already mentioned, building increasingly powerful provers that can attack problems in advanced areas of mathematical research and doing so in a human-oriented fashion is admittedly extremely challenging but also, we need to add, a very worthwhile, promising, and rewarding line of research. Embracing this kind of provers by mathematicians will have clear practical applications both in research and education. There will be philosophical implications too, especially the moment the provers are endowed with the additional ability to ask for assistance when getting stuck in a proof and, when this happens, we will be pressed to ask: Who is interacting with whom, the human with the machine or vice versa? The experience of interacting with a theorem prover will have been extended to a new realm, becoming truly two-sided, more intimate and richer, more of a <em>collaboration</em> than an interaction: the dawn of <em>collaborative theorem proving</em>.
</p>

<h3><a name="AI">4.8 Artificial Intelligence</a></h3>

<p>
Since its inception, the field of automated theorem proving has had
important applications in the larger field of artificial intelligence
(AI). Automated deduction is at the heart of AI applications like
logic programming (see <a href="#LogPro"> Section 4.1 Logic Programming</a>) where computation is equated with deduction; robotics and
problem solving (Green 1969) where the steps to achieve goals are
steps extracted from proofs; deductive databases (Minker <em>et
al</em>. 2014) where factual knowledge is expressed as atomic clauses
and inference rules, and new facts are inferred by deduction; expert
systems (Giarratano &amp; Riley 2004) where human expertise in a given
domain (e.g. blood infections) is captured as a collection of IF-THEN
deduction rules and where conclusions (e.g. diagnoses) are obtained by
the application of the inference rules; and many others. An
application of automated reasoning in AI which is bound to have deep
philosophical implications is the increased use of BDI computational
logics for describing the beliefs, desires, and intentions of
intelligent agents and multi-agent systems (Meyer 2014) and, in
particular, endowing future intelligent systems, such as
decision-support systems or robots, with legal and ethical behaviour.
Deontic logic can be automated for the task (Furbach <em>et al</em>.
2014) but given that there is no agreement on a universal system of
deontic logic, ethics &ldquo;code designers&rdquo; need a way to
experiment with the different deontic systems (i.e., to lay out axioms
and see what conclusions follow from them) to help them identify the
desired ethic code for the specific application at hand;
(Benzm&uuml;ller <em>et al</em>. 2018) discusses an environment for this. If
actual, physical, robots were to be used in these experiments, the
term &ldquo;deontic laboratory&rdquo; would be quite descriptive
albeit somewhat eerie.</p>

<p>
Restricting the proof search space has always been a key consideration
in the implementation of automated deduction, and traditional
AI-approaches to search have been an integral part of theorem provers.
The main idea is to prevent the prover from pursuing unfruitful
reasoning paths. A dual aspect of search is to try to look for a
previously proved result that could be useful in the completion of the
current proof. Automatically identifying those results is no easy task
and it becomes less easy as the size of the problem domain, and the
number of already established results, grows. This is not a happy
situation particularly in light of the growing trend to build large
libraries of theorems such as the Mizar Problems for Theorem Proving
(MPTP) (Urban <em>et al</em>. 2010, Bancerek &amp; Rudnicki 2003) or the
Isabelle/HOL mathematical library (Meng &amp; Paulson 2008), so
developing techniques for the discovery, evaluation, and selection of
existing suitable definitions, premises and lemmas in large libraries
of formal mathematics as discussed in (K&uuml;hlwein <em>et al</em>.
2012) is an important line of research. </p>

<p>
Among many other methods, and in stark contrast to automated provers,
mathematicians combine induction heuristics with deductive techniques
when attacking a problem. The former helps them guide the
proof-finding effort while the latter allows them to close proof gaps.
And of course all this happens in the presence of the very large body
of knowledge that the human possesses. For an automated prover, the
analogous counterpart to the mathematician&rsquo;s body of knowledge is a
large library like MPTP. An analogous approach to using inductive
heuristics would be to endow the theorem prover with inductive,
data-driven, machine learning abilities. Urban &amp; Vyskocil 2012
run a number of experiments to determine any gains that may result
from such an approach. For this, they use MPTP and theorem provers
like E and SPASS enhanced with symbol-based machine learning
mechanisms. A detailed presentation and statistical results can be
found in the above reference but in summary, and quoting the authors,
&ldquo;this experiment demonstrates a very real and quite unique
benefit of large formal mathematical libraries for conducting novel
integration of AI methods. As the machine learner is trained on
previous proofs, it recommends relevant premises from the large
library that (according to the past experience) should be useful for
proving new conjectures.&rdquo; Urban 2007 discusses MaLARea (a
Machine Learner for Automated Reasoning), a meta-system that also
combines inductive and deductive reasoning methods. MaLARea is
intended to be used in large theories, i.e. problems with a large
number of symbols, definitions, premises, lemmas, and theorems. The
system works in cycles where results proved deductively in a given
iteration are then used by the inductive machine-learning component to
place restrictions in the search space for the next theorem-proving
cycle. Albeit simple in design, the first version of MaLARea solved
142 problems out of 252 in the MPTP Challenge, outperforming the more
seasoned provers E (89 problems solved) and SPASS (81 problems
solved). Machine learning premise-selection methods trained on the considerable amount of mathematical knowledge encoded in Flyspeck&rsquo;s library of proofs, when combined with theorem provers, provides an AI-type system capable of proving a wide range of mathematical conjectures: Almost 40% of the 14,185 theorems can be proved automatically without any guidance from the user within 30 seconds on a 14-CPU workstation (Kaliszyk &amp; Urban 2014). Machine learning techniques can also be applied successfully to the problem of selecting good heuristics in the building of first-order proofs (Bridge, Holden &amp; Paulson 2014).</p>
<p>
The relationship between automated deduction and machine learning is reciprocal and the former has something to offer to the latter too. To mention one contribution, deep learning has become the technique of choice when it comes to applications in image recognition, language processing, and others, and there is theoretical evidence of its superiority over shallow learning. Such mathematical proofs can be formalized using theorem-proving systems like e.g. Isabelle/HOL while at the same time can contribute to the growth of their libraries with formalized results that can be used for further work aimed to secure the foundations of machine learning (Bentkamp, Blanchette &amp; Klakow 2019).
</p>

<p>
Besides using large mathematical libraries, tapping into web-based
semantic ontologies is another possible source of knowledge. Pease
&amp; Sutcliffe 2007 discuss ways for making the SUMO ontology
suitable for first-order theorem proving, and describes work on
translating SUMO into TPTP. An added benefit of successfully reasoning
over large semantic ontologies is that this promotes the application
of automated reasoning into other fields of science. Tapping into its
full potential, however, will require a closer alignment of methods
from automated reasoning and artificial intelligence.</p>

<h2><a name="Con">5. Conclusion</a></h2>

<p>
Automated reasoning is a mature yet still growing field that provides a healthy
interplay between basic research and application. Automated deduction
is being conducted using a multiplicity of theorem-proving methods,
including resolution, sequent calculi, natural deduction, matrix
connection methods, term rewriting, mathematical induction, and
others. These methods are implemented using a variety of logic
formalisms such as first-order logic, type theory and higher-order
logic, clause and Horn logic, non-classical logics, and so on.
Automated reasoning programs are being applied to solve a growing
number of problems in formal logic, mathematics and computer science,
logic programming, software and hardware verification, circuit design,
exact philosophy, and many others. One of the results of this variety
of formalisms and automated deduction methods has been the
proliferation of a large number of theorem proving programs. To test
the capabilities of these different programs, selections of problems
have been proposed against which their performance can be measured
(McCharen, Overbeek &amp; Wos 1976, Pelletier 1986). The TPTP
(Sutcliffe &amp; Suttner 1998, Sutcliffe 2017) is a library of such problems that is
updated on a regular basis. There is also a competition among
automated theorem provers held regularly at the CADE conference
(Pelletier, Sutcliffe &amp; Suttner 2002; Sutcliffe 2016, in Other
Internet Resources); the problems for the competition are selected from the TPTP library and range from problems in clause normal form (CNF), fist-order form (FOF), typed first-order form (TFF), monomorphic typed higher-order form (TH0), and others. There is a similar library and competition for
SMT solvers (Barret <em>et al</em>. 2013).</p>

<p>
Initially, computers were used to aid scientists with their complex
and often tedious numerical calculations. The power of the machines
was then extended from the numeric into the symbolic domain where
infinite-precision computations performed by computer algebra programs
have become an everyday affair. The goal of automated reasoning has
been to further extend the machine&rsquo;s reach into the realm of deduction
where they can be used as reasoning assistants in helping their users
establish truth through proof.</p>
</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Alama, J., P. Oppenheimer, and E. Zalta, &ldquo;Automating
Leibniz&rsquo;s Theory of Concepts&rdquo;, <em>CADE 25:
Proceedings of the 25th International Conference on Automated
Deduction</em>, (Lecture Notes in Artificial Intelligence: Volume
9195), A. Felty and A. Middeldorp (eds.), Berlin: Springer, pp. 73&ndash;97.</li>

<li>Anderson, C. A., 1990, &ldquo;Some Emendations of G&ouml;del&rsquo;s
Ontological Proof&rdquo;, <em>Faith and Philosophy</em>, 7(3):
291&ndash;303.</li>

<li>Anderson, A. R. and N. D. Belnap, 1962, &ldquo;The Pure Calculus
of Entailment&rdquo;, <em>Journal of Symbolic Logic</em>, 27:
19&ndash;52.</li>

<li>Andrews, P. B., 1981, &ldquo;Theorem-Proving via General
Matings&rdquo;, <em>Journal of the Association for Computing
Machinery</em>, 28 (2): 193&ndash;214.</li>

<li>Andrews, P. B., M. Bishop and C. E. Brown, 2006, &ldquo;TPS: A Hybrid
Automatic-Interactive System for Developing Proofs&rdquo;, <em>Journal
of Applied Logic</em>, 4: 367&ndash;395. </li>

<li>Andrews, P. B., M. Bishop, S. Issar, D. Nesmith, F. Pfenning and
H. Xi, 1996, &ldquo;TPS: A Theorem-Proving System for Classical Type
Theory&rdquo;, <em>Journal of Automated Reasoning</em>, 16 (3):
321&ndash;353.</li>

<li>Appel, K., and W. Haken, 1977, &ldquo;Every Planar Map is Four
Colorable Part I. Discharging&rdquo;, <em>Illinois Journal of
Mathematics</em>, 21: 429&ndash;490.</li>

<li>
Aransay, J., J. Divans&oacute;n, 2017, &ldquo;A Formalization in HOL of the Fundamental Theorem of Linear Algebra and Its Application to the Solution of the Least Squares Problem&rdquo;, <em>Journal of Automated Reasoning</em>, 58 (4): 509&ndash;535.
</li>

<li>Avigad, J. and J. Harrison, 2014, &ldquo;Formally Verified
Mathematics&rdquo;, <em>Communications of the ACM</em>, 57 (4):
66&ndash;75.</li>

<li>
Avigad, J., J. H&ouml;lzl and L. Serafin, 2017, &ldquo;A Formally Verified Proof of the Central Limit Theorem&rdquo;, <em>Journal of Automated Reasoning</em>, 59 (4): 389&ndash;423.
</li>

<li>Baader, F. and T. Nipkow, 1998, <em>Term Rewriting and All
That</em>, Cambridge: Cambridge University Press.</li>

<li>Bachmair, L. and H. Ganzinger, 1994, &ldquo;Rewrite-Based
Equational Theorem Proving with Selection and Simplification&rdquo;,
<em>Journal of Logic and Computation</em>, 4 (3): 217&ndash;247.</li>

<li>Ballarin, C., 2014, &ldquo;Locales: A Module System for
Mathematical Theories&rdquo;, <em>Journal of Automated Reasoning</em>,
52 (2): 123&ndash;153.</li>

<li>Bancerek, G. and P. Rudnicki, 2003, &ldquo;Information Retrieval
in MML&rdquo;, <em>Proceedings of the Second International Conference
on Mathematical Knowledge Management</em>, LNCS 2594, Heidelberg:
Springer-Verlag, pp. 119-132 </li>

<li>Bancerek, G., C. Byli&#324;ski, A. Grabowski, A. Korni&#322;owicz,
R. Matuszewski, A. Naumowicz and K. P&#261;k, 2018, &ldquo;The Role of
the Mizar Mathematical Library for Interactive Proof Development in
Mizar&rdquo;, <em>Journal of Automated Reasoning (Special Issue:
Milestones in Interactive Theorem Proving)</em>, 61 (9):
9&ndash;31.</li>

<li>Barret C., M. Deters, L. de Moura, A. Oliveras and A. Stump, 2013,
&ldquo;6 Years of SMT-COMP&rdquo;, <em>Journal of Automated
Reasoning</em>, 50 (3): 243&ndash;277.</li>

<li>Basin, D. A. and T. Walsh, 1996, &ldquo;A Calculus for and
Termination of Rippling&rdquo;, <em>Journal of Automated
Reasoning</em>, 16 (1&ndash;2): 147&ndash;180.</li>

<li>Bauer, A., E. Clarke and X. Zhao, 1998, &ldquo;Analytica: An
Experiment in Combining Theorem Proving and Symbolic
Computation&rdquo;, <em>Journal of Automated Reasoning</em>, 21:
295&ndash;325.</li>

<li>Beckert, B., R. Hanle and P.H. Schmitt (eds.), 2007,
&ldquo;Verification of Object-Oriented Software: The KeY
Approach&rdquo;, <em>Lecture Notes in Artificial Intelligence</em>
(Volume 4334), Berlin: Springer-Verlag.</li>

<li>
Beeson M., 2001, &ldquo;Automatic Derivation of the Irrationality of e&rdquo;, <em>Journal of Symbolic Computation</em>, 32 (4): 333&ndash;349.
</li>

<li>
Beeson,M. and L. Wos, 2017, &ldquo;Finding Proofs in Tarskian Geometry&rdquo;, <em>Journal of Automated Reasoning</em>, 58 (1), 181&ndash;207.
</li>

<li>
Bentkamp, A., J.C. Blanchette and D. Klakow, 2019, &ldquo;A Formal Proof of the Expressiveness of Deep Learning&rdquo;, <em>Journal of Automated Reasoning</em>, 63 (2), 347&ndash;368.
</li>

<li>
Bentkamp, A., J. Blanchette, S. Tourret, P. Vukmirovi&cacute; and U. Waldmann, 2021, &ldquo;Superposition with Lambdas&rdquo;, <em>Journal of Automated Reasoning</em>, 65 (7), 893&ndash;940.
</li>

<li>
Benzm&uuml;ller, C., 2019, &ldquo;Universal (Meta-) Logical Reasoning: Recent Successes&rdquo;, <em>Science of Computer Programming</em>, Vol. 172, 48&ndash;62.
</li>

<li>Benzm&uuml;ller, C. and B. W. Paleo, 2014, &ldquo;Automating
G&ouml;del&rsquo;s Ontological Proof of God&rsquo;s Existence with Higher-Order
Automated Theorem Provers&rdquo;, <em>ECAI 2014: Proceedings of the
21st European Conference on Artificial Intelligence</em>, T. Schaub <em>et
al</em>. (eds.), IOS Press, pp. 93&ndash;98.</li>

<li>&ndash;&ndash;&ndash;, 2015, &ldquo;Higher-Order
Modal Logics: Automation and Applications&rdquo;, <em>Reasoning Web
2015</em>, LNCS 9203, W. Faber and A. Paschke (eds.), pp.
32&ndash;74.</li>

<li>Benzm&uuml;ller C., X. Parent and L. van der Torre, 2018, &ldquo;A
Deontic Logic Reasoning Infrastructure&rdquo;, <em>CiE2018:
Proceedings of the 14th Conference on Computability in Europe</em>,
LNCS 10936, F. Manea <em>et al</em>. (eds.), pp. 60&ndash;69.</li>

<li>Benzm&uuml;ller C. and L. C. Paulson, 2013, &ldquo;Quantified
Multimodal Logics in Simple Type Theory&rdquo;, <em>Logica
Universalis</em>, 7 (1): 7&ndash;20.</li>

<li>
Benzm&uuml;ller, C. and D. S. Scott, 2020, &ldquo;Automating Free Logic in HOL, with an Experimental Application in Category Theory&rdquo;, <em>Journal of Automated Reasoning</em>, 64 (1), 53&ndash;72.
</li>

<li>
Benzm&uuml;ller, C., A. Steen and M. Wisniewski, 2017, &ldquo;Leo-III version 1.1 (system description)&rdquo;, <em>Logic for Programming, Artificial Intelligence, and Reasoning (LPAR)&mdash;Short Papers</em>, T. Eiter, D. Sands, G. Sutcliffe and A. Voronkov (eds.), Kalpa Publications in Computing, Volume 1: 11&ndash;26.
</li>

<li>Benzm&uuml;ller, C., N. Sultana, L. C. Paulson and F. Thei&szlig;,
2015, &ldquo;The Higher-Order Prover LEO-II&rdquo;, <em>Journal of
Automated Reasoning</em>, 55 (4): 389&ndash;404.</li>

<li>Berndt, B., 1985, <em>Ramanujan&rsquo;s Notebooks</em> (Part I), Berlin:
Springer-Verlag, pp. 25-43.</li>

<li>
Beyer, D., M. Dangl and P. Wendler, 2018, &ldquo;A Unifying View on SMT-Based Software Verification&rdquo;, <em>Journal of Automated Reasoning</em>, 60 (3): 299&ndash;335.
</li>

<li>
Beyer, D., M. Dangl and P. Wendler, 2021, &ldquo;Correction to: A Unifying View on SMT-Based Software Verification&rdquo;, <em>Journal of Automated Reasoning</em>, 65 (3): 461.
</li>

<li>Bibel, W., 1981, &ldquo;On Matrices with Connections&rdquo;,
<em>Journal of the Association of Computing Machinery</em>, 28 (4):
633&ndash;645.</li>

<li>Blanchette, J. C., S. B&ouml;hme and L. C. Paulson, 2013,
&ldquo;Extending Sledgehammer with SMT Solvers&rdquo;, <em>Journal of
Automated Reasoning</em>, 51 (1): 109&ndash;128.</li>

<li>Blanchette, J. C. and T. Nipkow, 2010, &ldquo;Nitpick: A
Counterexample Generator for Higher-Order Logic Based on a Relational
Model Finder&rdquo;, <em>ITP2010: First International Conference on
Interactive Theorem Proving</em>, LNCS 6172, M. Kaufmann and L. C.
Paulson (eds.), pp. 131&ndash;146.</li>

<li>Bledsoe, W. W., 1977, &ldquo;Non-resolution Theorem
Proving&rdquo;, <em>Artificial Intelligence</em>, 9: 1&ndash;35.</li>

<li>Bledsoe, W. W. and M. Tyson, 1975, &ldquo;The UT Interactive
Prover&rdquo;, <em>Memo ATP-17A</em>, Department of Mathematics,
University of Texas.</li>

<li>
Boender, J., F. Kamm&uuml;ller and R. Nagarajan, 2015, &ldquo;Formalization of Quantum Protocols using Coq&rdquo;, <em>12th International Workshop on Quantum Physics and Logic (QPL)</em>, Oxford, arXiv preprint arXiv:1511.01568.
</li>

<li>Bofill, M., R. Nieuwenhuis, A. Oliveras, E. Rodriguez-Carbonell
and A. Rubio, 2008, &ldquo;A Write-Based Solver for SAT Modulo the
Theory of Arrays&rdquo;, <em>Formal Methods in Computer-Aided Design
(FMCAD&rsquo;08)</em>, pp. 1&ndash;8.</li>

<li>Bonacina, M. P., 1999, &ldquo;A Taxonomy of Theorem-Proving
Strategies&rdquo;, <em>Artificial Intelligence Today</em>, (Lecture
Notes in Computer Science: Volume 1600), Berlin: Springer-Verlag, pp.
43&ndash;84.</li>

<li>
Bordg, A., H. Lachnitt and Y. He, 2021, &ldquo;Certified Quantum Computation in Isabelle/HOL&rdquo;, <em>Journal of Automated Reasoning</em>, 65 (5): 691&ndash;709.
</li>

<li>Boyer R., <em>et al</em>., 1994, &ldquo;The QED Manifesto&rdquo;,
<em>CADE-12: Proceedings of the 12th International Conference on
Automated Deduction</em>, (Lecture Notes in Artificial Intelligence:
Volume 814), A. Bundy (ed.), Berlin: Springer-Verlag, pp.
238&ndash;251.</li>

<li>Boyer, R. S., M. Kaufmann and J. S. Moore, 1995, &ldquo;The
Boyer-Moore Theorem Prover and its Interactive Enhancement&rdquo;,
<em>Computers and Mathematics with Applications</em>, 29:
27&ndash;62.</li>

<li>Boyer, R.S. and J. S. Moore, 1979, <em>A Computational Logic</em>,
New York: Academic Press.</li>

<li>
Brakensiek, J., M. Heule, J. Mackey and D. Narv&aacute;ez, 2022, &ldquo;The Resolution of Keller&rsquo;s Conjecture&rdquo;, <em>Journal of Automated Reasoning</em>, 66 (3): 277&ndash;300.
</li>

<li>
Bridge, J.P., S.B. Holden and L.C. Paulson, 2014, &ldquo;Machine Learning for First-Order Theorem Proving&rdquo;, <em>Journal of Automated Reasoning</em>, 53 (2), 141&ndash;172.
</li>

<li>Brown, C. E., 2012, &ldquo;Satallax: An Automatic Higher-Order
Prover&rdquo;, <em>Automated Reasoning: Proceedings of the 6th
International Joint Conference on Automated Reasoning (IJCAR
2012)</em>, LNAI 7364, B. Gramlich <em>et al</em>. (eds.), pp. 111&ndash;117,
Springer-Verlag.</li>

<li>&ndash;&ndash;&ndash;, 2013, &ldquo;Reducing Higher-Order Theorem Proving
to a Sequence of SAT Problems&rdquo;, <em>Journal of Automated
Reasoning</em>, 51 (1): 57&ndash;77.</li>

<li>
Buchberger B., T. Jebelean, T. Kutsia, A. Maletzky and W. Windsteiger, 2016, &ldquo;Theorema 2.0: Computer-Assisted Natural-Style Mathematics&rdquo;, <em>Journal of Formalized Reasoning</em>, 9 (1): 149&ndash;185.
</li>

<li>Bundy, A., 2011, &ldquo;Automated theorem proving: a practical
tool for the working mathematician?&rdquo;, <em>Annals of Mathematics
and Artificial Intelligence</em>, 61 (1): 3&ndash;14.</li>

<li>Bundy, A., F. van Harmelen, J. Hesketh and A. Smaill, 1991,
&ldquo;Experiments with Proof Plans for Induction&rdquo;, <em>Journal
of Automated Reasoning</em>, 7 (3): 303&ndash;324.</li>

<li>Bundy, A., A. Stevens, F. van Harmelen, A. Ireland and A. Smaill,
1993, &ldquo;Rippling: A Heuristic for Guiding Inductive
Proofs&rdquo;, <em>Artificial Intelligence</em>, 62:
185&ndash;253.</li>

<li>
Buresh-Oppenheim, J. and T. Pitassi, 2007, &ldquo;The Complexity of Resolution Refinements&rdquo;, <em>Journal of Symbolic Logic</em>, 72 (4): 1336&ndash;1352.
</li>

<li>
Chan, HL. and M. Norrish, 2019, &ldquo;Classification of Finite Fields with Applications&rdquo;, <em>Journal of Automated Reasoning</em>, 63 (3): 667&ndash;693.
</li>

<li>Chang, C. L. and R. C. T. Lee, 1973, <em>Symbolic Logic and
Mechanical Theorem Proving</em>, New York: Academic Press.</li>

<li>Chou, S., 1987, <em>Mechanical Geometry Theorem Proving</em>,
Dordrecht: Kluwer Academic Publishers.</li>

<li>Church, A., 1936a, &ldquo;An unsolvable problem of elementary
number theory&rdquo;, <em>American Journal of Mathematics</em>, 58
(2): 345&ndash;363.</li>

<li>&ndash;&ndash;&ndash;, 1936b, &ldquo;A note on the
Entscheidungsproblem&rdquo;, <em>Journal of Symbolic Logic</em>, 1
(1): 40&ndash;41.</li>

<li>&ndash;&ndash;&ndash;, 1940, &ldquo;A Formulation of the Simple Theory of
Types&rdquo;, <em>Journal of Symbolic Logic</em>, 5: 56&ndash;68.</li>

<li>Claessen, K. and N. S&ouml;rensson, 2003, &ldquo;New Techniques
that Improve MACE-style Finite Model Finding&rdquo;, <em>Proceedings
of the CADE-19 Workshop: Model Computation &ndash; Principles,
Algorithms, Applications</em>, P. Baumgartner and C. Fermueller
(eds.)</li>

<li>Clarke, E. and X. Zhao, 1994, &ldquo;Combining Symbolic
Computation and Theorem Proving: Some Problems of Ramanujan&rdquo;,
<em>CADE-12: Proceedings of the 12th International Conference on
Automated Deduction</em>, (Lecture Notes in Artificial Intelligence:
Volume 814), A. Bundy (ed.), Berlin: Springer-Verlag, pp.
758-763.</li>

<li>Clocksin, W. F. and C. S. Mellish, 1981, <em>Programming in
Prolog</em>, Berlin: Springer-Verlag.</li>

<li>Colmerauer, A., H. Kanoui, R. Pasero and P. Roussel, 1973, <em>Un
Syst&egrave;me de Communication Homme-machine en Fran&ccedil;ais</em>,
Rapport, Groupe Intelligence Artificielle, Universit&eacute; d&rsquo;Aix
Marseille.</li>

<li>Constable, R. L., S. F. Allen, H. M. Bromley, W.R. Cleaveland, J.
F. Cremer, R. W. Harper, D. J. Howe, T. B. Knoblock, N. P. Mendler, P.
Panangaden, J. T. Sasaki and S. F. Smith, 1986, <em>Implementing
Mathematics with the Nuprl Proof Development System</em>, Englewood
Cliffs, NJ: Prentice Hall.</li>

<li>Cook, S. A., 1971, &ldquo;The complexity of Theorem-Proving
Procedures&rdquo;, <em>Proceedings of the 3rd Annual ACM Symposium on
Theory of Computing</em>, New York: Association for Computing
Machinery, pp. 151&ndash;158.</li>

<li>Coquand, T. and G. Huet, 1988, &ldquo;The Calculus of
Constructions&rdquo;, <em>Information and Computation - Semantics of
Data Types</em>, A. R. Meyer (ed.), 76 (2&ndash;3): 95&ndash;120.</li>

<li>Coquand, T. and C. Paulin-Mohring, 1988, &ldquo;Inductively
Defined Types&rdquo;, <em>COLOG88: Proceedings of the International
Conference on Computer Logic</em>, P. Martin-L&ouml;f and G. Mints
(eds.), LNCS 417, pp. 50&ndash;66.</li>

<li>Davis, M., G. Logemann and D. Loveland, 1962, &ldquo;A Machine
Program for Theorem-Proving&rdquo;, <em>Communications of the
Association for Computing Machinery</em>, 5 (7): 394&ndash;397.</li>

<li>Davis, M. and H. Putnam, 1960, &ldquo;A Computing Procedure for
Quantification Theory&rdquo;, <em>Journal of the Association for
Computing Machinery</em>, 7 (3): 201&ndash;215.</li>

<li>de Bruijn, N. G., 1968, &ldquo;Automath, a Language for
Mathematics&rdquo;, in <em>Automation of Reasoning (Volume 2)</em>, J.
Siekmann and G. Wrighston (eds.), Berlin: Springer-Verlag, 1983, pp.
159&ndash;200.</li>

<li>de Moura, L., 2007, &ldquo;Developing Efficient SMT
Solvers&rdquo;, <em>Proceedings of the CADE-21 Workshop on Empirically
Successful Automated Reasoning in Large Theories</em>, G. Sutcliffe,
J. Urban and S. Schulz (eds.), Bremen.</li>

<li>Denney, E., B. Fischer and J. Schumann, 2004, &ldquo;Using
Automated Theorem Provers to Certify Auto-generated Aerospace
Software&rdquo;, <em>Automated Reasoning, Second International Joint
Conference (IJCAR)</em> (Lecture Notes in Artificial Intelligence:
Volume 3097), D. Basin and M. Rusinowitch (eds.), Berlin:
Springer-Verlag, pp. 198-212.</li>

<li>Denney, E., J. Power and K. Tourlas, 2006, &ldquo;Hiproofs: A
Hierarchical Notion of Proof Tree&rdquo;, <em>Proceedings of the 21st
Annual Conference on Mathematical Foundations of Programming Semantics
(MFPS XXI)</em> (Electronic Notes in Theoretical Computer Science,
Vol. 155), pp. 341&ndash;359.</li>

<li>
Deutsch, D., 1982, &ldquo;Quantum theory, the Church-Turing principle and the universal quantum computer&rdquo;, <em>Proceedings of the Royal Society of London A</em>, 400: 97&ndash;117.
</li>

<li>
Dieks, D., 1982, &ldquo;Communication by EPR devices&rdquo;, <em>Physics Letters A</em>, 92: 271&ndash;272.
</li>

<li>
Eisert, J., M. Wilkens and M. Lewenstein, 1999, &ldquo;Quantum games and quantum strategies&rdquo;, <em>Physical Review Letters</em>, 83: 3077&ndash;3080.
</li>

<li>
&ndash;&ndash;&ndash;, 2020, &ldquo;Erratum: quantum games and quantum strategies&rdquo;, [<em>Physical Review Letters</em>, 83: 3077&ndash;3080], <em>Physical Review Letters</em>, 124: 139901.
</li>

<li>Ernst, Z., B. Fitelson, K. Harris and L. Wos, 2002,
&ldquo;Shortest Axiomatizations of Implicational S4 and S5&rdquo;,
<em>Notre Dame Journal of Formal Logic</em>, 43 (3):
169&ndash;179.</li>

<li>Farmer, W. M., J. D. Guttman and F. J. Thayer, 1993, &ldquo;IMPS:
An Interactive Mathematical Proof System&rdquo;, <em>Journal of
Automated Reasoning</em>, 11 (2): 213&ndash;248.</li>

<li>Fitelson B. and E. Zalta, 2007, &ldquo;Steps Toward a
Computational Metaphysics&rdquo;, <em>Journal of Philosophical
Logic</em>, 36 (2): 227&ndash;247.</li>

<li>Fitting, M., 1990, <em>First-Order Logic and Automated Theorem
Proving</em>, Berlin: Springer-Verlag.</li>

<li>&ndash;&ndash;&ndash;, 2002, <em>Types, Tableaus and G&ouml;del&rsquo;s God</em>.
Kluwer.</li>

<li>Fuenmayor, D. and C. Benzm&uuml;ller, 2017, &ldquo;Automating
Emendations of the Ontological Argument in Intensional Higher-Order
Modal Logic&rdquo;, <em>KI 2017: Advances in Artificial Intelligence -
Proceedings of the 40th Annual German Conference on AI</em>, LNCS
10505, G. Kern-Isberner <em>et al</em>. (eds.), pp. 114-127.</li>

<li>Furbach , U., 1994, &ldquo;Theory Reasoning in First Order
Calculi&rdquo;, <em>Management and Processing of Complex Data
Structures</em>, (Lecture Notes in Computer Science Volume 777), pp.
139&ndash;156.</li>

<li>Furbach, U., C. Schon and F. Stolzenburg, 2014, &ldquo;Automated
Reasoning in Deontic Logic&rdquo;, <em>MIWAI2014: Proceedings of the
8th Multi-disciplinary International Workshop on Artificial
Intelligence</em>, LNAI 8875, M. N. Murty <em>et al</em>. (eds.), pp.
57&ndash;68.</li>

<li>
Ganesalingam, M. and W. T. Gowers, 2017, &ldquo;A Fully Automatic Theorem Prover with Human-Style Output&rdquo;, <em>Journal of Automated Reasoning</em>, 58 (2): 253&ndash;291.
</li>

<li>Ganzinger, H., G. Hagen, R. Nieuwenhuis, A. Oliveras, C. Tinelli,
2004, &ldquo;DPLL(T): Fast Decision Procedures&rdquo;, <em>Computer
Aided Verification</em>, (Lecture Notes in Computer Science: Volume
3114), pp. 175&ndash;188.</li>

<li>Gentzen, G., 1935, &ldquo;Investigations into Logical
Deduction&rdquo;, in Szabo 1969, pp. 68&ndash;131.</li>

<li>Giarratano, J. and G. Riley, 2004, <em>Expert Systems: Principles
and Programming</em>, 4th edition, Boston, MA: PWS Publishing Co.</li>

<li>G&ouml;del, K., 1970, &ldquo;Appendix A: Notes in Kurt
G&ouml;del&rsquo;s Hand&ldquo;, in Sobel 2004, pp. 144&ndash;145.</li>

<li>Gordon, M. J. C. and T. F. Melham, eds., 1993, <em>Introduction to
HOL: A Theorem Proving Environment for Higher Order Logic</em>,
Cambridge: Cambridge University Press.</li>

<li>Gordon, M. J. C., A. J. Milner and C. P. Wadsworth, 1979,
<em>Edinburgh LCF: A Mechanised Logic of Computation</em> (LNCS 78),
Berlin: Springer-Verlag.</li>

<li>Gorenstein, D., 1982, <em>Finite Simple Groups: An Introduction to
their Classification</em> (University Series in Mathematics), New
York: Plenum Press.</li>

<li>Green, C., 1969, &ldquo;Application of Theorem Proving to Problem
Solving&rdquo;, <em>IJCAI&rsquo;69 Proceedings of the 1st international
joint conference on Artificial intelligence</em>, San Francisco:
Morgan Kaufmann, pp. 219&ndash;239</li>

<li>Haack, S., 1978, <em>Philosophy of Logics</em>, Cambridge:
Cambridge University Press.</li>

<li>Hales, T. C., 2005a, &ldquo;A proof of the Kepler
Conjecture&rdquo;, <em>Annals of Mathematics</em>, 162 (3):
1065&ndash;1185.</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Introduction to the Flyspeck
Project&rdquo;, <em>Dagstuhl Seminar Proceedings 05021: Mathematics,
Algorithms, Proofs</em>, T. Coquand <em>et al</em>. (eds.)</li>

<li>Hales, T. C. <em>et al</em>., 2015, &ldquo;A Formal Proof of the

Kepler Conjecture&rdquo;, <em>arXiv:1501.02.02155 9 [mat.MG]</em>,
Cornell University Library.</li>

<li>Harrison, J., 2000, &ldquo;High-Level Verification Using Theorem

Proving and Formalized Mathematics&rdquo;, <em>CADE-17: Proceedings of
the 17th International Conference on Automated Deduction</em>,
(Lecture Notes in Artificial Intelligence: Volume 1831), D. McAllester
(ed.), Berlin: Springer-Verlag, pp. 1-6.</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Verification: Industrial
Applications&rdquo;, <em>Proof Technology and Computation</em>, H.

Schwichtenberg and K. Spies (eds.), Amsterdam: IOS Press, pp.
161&ndash;205.</li>

<li>&ndash;&ndash;&ndash;, 2009, &ldquo;Formalizing an Analytic Proof of the

Prime Number Theorem&rdquo;, <em>Journal of Automated Reasoning
(Special Issue: A Festschrift for Michael J. C. Gordon)</em>, 43 (3):
243&ndash;261.</li>

<li>Harrison, J. and L. Th&eacute;ry, 1998, &ldquo;A Skeptic&rsquo;s
Approach to Combining HOL and Maple&rdquo;, <em>Journal of Automated

Reasoning</em>, 21: 279&ndash;294.</li>

<li>Herbrand, J., 1930, <em>Recherches sur la Theorie de la
Demonstration</em>, Travaux de la Societ&eacute; des Sciences at des
Lettres de Varsovie, Classe III, Science Math&eacute;matique et
Physique, No. 33, 128.</li>

<li>Heule, M. J. H. and O. Kullmann, 2017, &ldquo;The Science of Brute

Force&rdquo;, <em>Communications of the ACM</em>, 60 (8):
70&ndash;79.</li>

<li>Heule, M. J. H., O. Kullmann and V. W. Marek, 2016, &ldquo;Solving
and Verifying the Boolean Pythagorean Triples problem via
Cube-and-Conquer&rdquo;, <em>Theory and Applications of Satisfiability

Testing &mdash; SAT 2016, 19th International Conference</em>, LNCS
9710, N. Creignou and D. Le Berre (eds.), pp. 228&ndash;245.</li>

<li>Hilbert, D. and W. Ackermann, 1928, <em>Principles of Mathematical
Logic</em>, L. Hammond, G. Leckie, and F. Steinhardt (trans.), New
York: Chelsea Publishing Co., 1950.</li>

<li>Huet, G. P., 1975, &ldquo;A Unification Algorithm for Typed
\(\lambda\)-calculus&rdquo;, <em>Theoretical Computer Science</em>, 1:
27&ndash;57.</li>

<li>
Kaliszyk, C. and J. Urban, 2014, &ldquo;Learning-Assisted Automated Reasoning with Flyspeck&rdquo;, <em>Journal of Automated Reasoning</em>, 53 (2), 173&ndash;213.
</li>

<li>Kanckos, A., and B. W. Paleo, 2017, &ldquo;Variants of
G&ouml;del&rsquo;s Ontological Proof in a Natural Deduction Calculus&rdquo;,
<em>Studia Logica</em>, (3): 553&ndash;586.</li>

<li>Kerber, M., Kohlhase and V. Sorge, 1998, &ldquo;Integrating
Computer Algebra into Proof Planning&rdquo;, <em>Journal of Automated
Reasoning</em>, 21: 327&ndash;355.</li>

<li>
Kirchner, D., 2017, &ldquo;Representation and Partial Automation of the Principia Logico-Metaphysica in Isabelle/HOL&rdquo;, <em>Archive of Formal Proofs</em>. Formal proof development. ISSN: 2150&ndash;914x. URL: http://isa-afp.org/entries/PLM.html.
</li>

<li>
&ndash;&ndash;&ndash;, 2021, <em>Computer-Verified Foundations of Metaphysics and an Ontology of Natural Numbers in Isabelle/HOL</em>, Ph.D. Dissertation, Fachbereich Mathematik und Informatik, Freie Universit&auml;t Berlin.
</li>

<li>
Kirchner, D., C. Benzm&uuml;ller and E. Zalta, 2019, &ldquo;Computer Science and Metaphysics: A Cross-Fertilization&rdquo;, <em>Open Philosophy</em>, 2: 230&ndash;251.
</li>

<li>
&ndash;&ndash;&ndash;, 2020, &ldquo;Mechanizing Principia Logico-Metaphysica in Functional Type Theory", <em>Review of Symbolic Logic</em>, 13 (1): 206&ndash;18.
</li>

<li>Knuth, D. and P. B. Bendix, 1970, &ldquo;Simple Word Problems in
Universal Algebras&rdquo;, in <em>Computational Problems in Abstract
Algebra</em>, J. Leech (ed.), Oxford, New York: Pergamon Press, pp.
263&ndash;297.</li>

<li>Kleene, S. C., 1962, <em>Introduction to Metamathematics</em>,
Amsterdam: North-Holland.</li>

<li>Kov&aacute;cs, L. and A. Voronkov, 2013, &ldquo;First-Order
Theorem Proving and VAMPIRE&rdquo;, <em>CAV 2013: Proceedings of the
International Conference on Computer Aided Verification</em>, N.
Sharygina and H. Veith (eds.), LNCS 8044, pp. 1&ndash;35.</li>

<li>Kowalski, R., 1974, &ldquo;Predicate Logic as a Programming
Language&rdquo;, <em>Proceedings of the International Federation for
Information Processing</em> (Proc. IFIP &rsquo;74), Amsterdam: North
Holland, pp. 569&ndash;574.</li>

<li>K&uuml;chlin, W. and C. Sinz, 2000, &ldquo;Proving Consistency
Assertions for Automotive Product Data Management&rdquo;, <em>Journal
of Automated Reasoning</em> (Special Issue: Satisfiability in the Year
2000), I. P. Gent and T. Walsh (eds.), 24 (1&ndash;2):
145&ndash;163.</li>

<li>K&uuml;hlwein, D., T. van Laarhoven, E. Tsivtsivadze, J. Urban and
T. Heskes, 2012, &ldquo;Overview and Evaluation of Premise Selection
Techniques for Large Theory Mathematics&rdquo;, <em>Automated
Reasoning: 6th International Joint Conference, IJCAR 2012</em>,
(Lecture Notes in Computer Science: Volume 7364), B. Gramlich, D.
Miller and U. Sattler (eds.), Manchester, UK: Springer-Verlag, pp.
378&ndash;392.</li>

<li>Lemmon, E. J., C. A. Meredith, D. Meredith, A. N. Prioir and I.
Thomas, 1957, <em>Calculi of Pure Strict Implication</em>, Philosophy
Dept., Canterbury University, Christchurch, New Zealand.</li>

<li>Lloyd, J. W., 1984, <em>Foundations of Logic Programming</em>,
Berlin: Springer-Verlag.</li>

<li>Loveland, D. W., 1969, &ldquo;A Simplified Format for the Model
Elimination Procedure&rdquo;, <em>Journal of the Association for
Computing Machinery</em>, 16: 349&ndash;363.</li>

<li>&ndash;&ndash;&ndash;, 1970, &ldquo;A Linear Format for
Resolution&rdquo;, <em>Proceedings of the IRIA Symposium on Automatic
Demonstration</em>, New York: Springer-Verlag, pp. 147-162.</li>

<li>&ndash;&ndash;&ndash;, 1978, <em>Automated Theorem Proving: A Logical
Basis</em>, Amsterdam: North Holland.</li>

<li>Luckham, D., 1970, &ldquo;Refinements in Resolution Theory&rdquo;,
<em>Proceedings of the IRIA Symposium on Automatic Demonstration</em>,
New York: Springer-Verlag, pp. 163-190.</li>

<li>
Maggesi, M., 2018, &ldquo;A Formalization of Metric Spaces in HOL Light&rdquo;, <em>Journal of Automated Reasoning</em>, 60 (2): 237&ndash;254.
</li>

<li>Martin-L&ouml;f, P., 1982, &ldquo;Constructive Mathematics and
Computer Programming&rdquo;, <em>Logic, Methodology and Philosophy of
Science</em> (Volume IV), Amsterdam: North-Holland, pp. 153-175.</li>

<li>Massacci, F. and L. Marraro, 2000, &ldquo;Logical Cryptanalysis:
Encoding and Analysis of the U.S. Data Encryption Standard&rdquo;,
<em>Journal of Automated Reasoning</em> (Special Issue: Satisfiability
in the Year 2000), I. P. Gent and T. Walsh (eds.), 24 (1&ndash;2):
165&ndash;203.</li>

<li>McCarthy, J., 1962, &ldquo;Towards a Mathematical Science of
Computation&rdquo;, <em>International Federation for Information
Processing Congress</em> (Munich, 1962), Amsterdam: North Holland, pp.
21&ndash;28.</li>

<li>McCharen, J. D., R. A. Overbeek and L. A. Wos, 1976,
&ldquo;Problems and Experiments for and with Automated Theorem-Proving
Programs&rdquo;, <em>IEEE Transactions on Computers</em> 8:
773&ndash;782.</li>

<li>McCune, W., 1997, &ldquo;Solution of the Robbins Problem&rdquo;,
<em>Journal of Automated Reasoning</em>, 19 (3): 263&ndash;276.</li>

<li>&ndash;&ndash;&ndash;, 2001, <em>MACE 2.0 Reference Manual and Guide</em>,
Mathematics and Computer Science Division, ANL/MSC-TM-249, Argonne
National Laboratory.</li>

<li>McRobie, M. A., 1991, &ldquo;Automated Reasoning and Nonclassical
Logics: Introduction&rdquo;, <em>Journal of Automated Reasoning</em>,
7 (4): 447&ndash;451.</li>

<li>Meng, J. and L. C. Paulson, 2008, &ldquo;Translating higher-order
clauses to first-order clauses&rdquo;, <em>Journal of Automated
Reasoning</em>, 40 (1): 35&ndash;60.</li>

<li>Meredith, C. A. and A. N. Prior, 1964, &ldquo;Investigations into
Implicational S5&rdquo;, <em>Z. Math. Logik Grundlagen Math.</em>,
10:203&ndash;220.</li>

<li>Meyer, J.-J. Ch., 2014, &ldquo;Logics for Intelligent Agents and
Multi-Agent Systems&rdquo;, <em>Handbook of the History of Logic,
Volume 9: Computational Logic</em>, J. Siekmann (ed.), pp.
629&ndash;658, Elsevier.</li>

<li>Miller, D. and G. Nadathur, 1988, &ldquo;An Overview of
\(\lambda\)Prolog&rdquo;, <em>Proceedings of the Fifth International
Logic Programming Conference &mdash; Fifth Symposium in Logic
Programming</em>, R. Bowen and R. Kowalski (eds.), Cambridge, MA: MIT
Press.</li>

<li>Minker, J., D. Seipel and C. Zaniolo, 2014, &ldquo;Logic and
Databases: A History of Deductive Databases&rdquo;, <em>Handbook of
the History of Logic, Volume 9: Computational Logic</em>, J. Siekmann
(ed.), pp. 571&ndash;627, Elsevier.</li>

<li>Muzalewski, M., 1993, <em>An Outline of PC Mizar</em>, Fondation
Philippe le Hodey, Brussels.</li>

<li>Nipkow, T., L. C. Paulson and M. Wenzel, 2002,
&ldquo;Isabelle/HOL: A Proof Assistant for Higher-Order Logic&ldquo;,
LNCS Vol. 2283, pp. 207&ndash;208.</li>

<li>Nivens, A. J., 1974, &ldquo;A Human-Oriented Logic for Automatic
Theorem Proving&rdquo;, <em>Journal of the Association of Computing
Machinery</em>, 21 (4): 606&ndash;621.</li>

<li>Oppenheimer, P. and E. Zalta, 2011, &ldquo;A
Computationally-Discovered Simplification of the Ontological
Argument&rdquo;, <em>Australasian Journal of Philosophy</em>, 89 (2):
333&ndash;349.</li>

<li>Paulson, L. C., 1990, &ldquo;Isabelle: The Next 700 Theorem
Provers&rdquo;, <em>Logic and Computer Science</em>, P. Odifreddi
(ed.), Academic Press, pp. 361&ndash;386.</li>

<li>&ndash;&ndash;&ndash;, 1994, <em>Isabelle: A Generic Theorem Prover</em>
(Lecture Notes in Computer Science: Volume 828), Berlin:
Springer-Verlag.</li>

<li>&ndash;&ndash;&ndash;, 2010. &ldquo;Three Years of Experience with
Sledgehammer, a Practical Link Between Automatic and Interactive
Theorem Provers&rdquo;, <em>PAAR-2010</em>, B. Konev <em>et al</em>. (eds.),
pp. 1&ndash;10.</li>

<li>Paulson, L. C. and K. Grabczewski, 1996, &ldquo;Mechanizing Set
Theory&rdquo;, <em>Journal of Automated Reasoning</em>, 17 (3):
291&ndash;323.</li>

<li>Pease, A. and G. Sutcliffe, 2007, &ldquo;First Order Reasoning on
a Large Ontology&rdquo;, <em>Proceedings of the CADE-21 Workshop on
Empirically Successful Automated Reasoning in Large Theories</em>
(Volume 257), G. Sutcliffe and J. Urban (eds.), Bremen.</li>

<li>Pelletier, F. J., 1986, &ldquo;Seventy-Five Problems for Testing
Automatic Theorem Provers&rdquo;, <em>Journal of Automated
Reasoning</em>, 2 (2): 191&ndash;216.</li>

<li>&ndash;&ndash;&ndash;, 1998, &ldquo;Natural Deduction Theorem Proving
in THINKER&rdquo;, <em>Studia Logica</em>, 60 (1): 3&ndash;43.</li>

<li>Pelletier, F. J., G. Sutcliffe and A. P. Hazen, 2017,
&ldquo;Automated Reasoning for the Dialetheic Logic RM3&rdquo;,
<em>Proceedings of the Thirtieth International Florida Artificial
Intelligence Research Society Conference</em>, V. Rus and Z. Markov
(eds.), pp. 110&ndash;115.</li>

<li>Pelletier, F. J., G. Sutcliffe, and C. Suttner, 2002, &ldquo;The
Development of CASC&rdquo;, <em>AI Communications</em>, 15
(2&ndash;3): 79&ndash;90.</li>

<li>Peterson, J. G., 1977, <em>The Possible Shortest Single Axiom for
EC-Tautologies</em>, Report 105, Department of Mathematics, University
of Auckland.</li>

<li>Pollock, J., 1989, &ldquo;OSCAR: A General Theory of
Rationality&rdquo;, <em>Journal of Experimental &amp; Theoretical
Artificial Intelligence</em>, 1 (3): 209&ndash;226</li>

<li>&ndash;&ndash;&ndash;, 1995, <em>Cognitive Carpentry</em>, Cambridge, MA:
Bradford/MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Against Optimality: Logical Foundations
for Decision-Theoretic Planning in Autonomous Agents&rdquo;,
<em>Computational Intelligence</em>, 22(1): 1&ndash;25.</li>

<li>Portoraro, F. D., 1994, &ldquo;Symlog: Automated Advice in
Fitch-style Proof Construction&rdquo;, <em>CADE-12: Proceedings of the
12th International Conference on Automated Deduction</em>, (Lecture
Notes in Artificial Intelligence: Volume 814), A. Bundy (ed.), Berlin:
Springer-Verlag, pp. 802-806.</li>

<li>&ndash;&ndash;&ndash;, 1998, &ldquo;Strategic Construction of
Fitch-style Proofs&rdquo;, <em>Studia Logica</em>, 60 (1):
45&ndash;66.</li>

<li>Prasad, M., A. Biere and A. Gupta, 2005, &ldquo;A Survey of Recent
Advances in SAT-Based Formal Verification&rdquo;, <em>International
Journal on Software Tools for Technology Transfer</em>, 7 (2):
156&ndash;173.</li>

<li>Prawitz, D., 1965, <em>Natural Deduction: A Proof Theoretical
Study</em>, Stockholm: Almqvist &amp; Wiksell.</li>

<li>Quaife, A., 1992, <em>Automated Development of Fundamental
Mathematical Theories</em>, Kluwer Academic Publishers.</li>

<li>Robinson, J. A., 1965, &ldquo;A Machine Oriented Logic Based on
the Resolution Principle&rdquo;, <em>Journal of the Association of
Computing Machinery</em>, 12: 23&ndash;41.</li>

<li>&ndash;&ndash;&ndash;, 1965, &ldquo;Automatic Deduction with
Hyper-resolution&rdquo;, <em>Internat. J. Comput. Math.</em>, 1:
227&ndash;234.</li>

<li>Robinson, J. A. and A. Voronkov (eds.), 2001, <em>Handbook of
Automated Reasoning: Volumes I and II</em>, Cambridge, MA: MIT Press.
</li>

<li>Schmitt, P. and I. Tonin, 2007, &ldquo;Verifying the Mondex Case
Study&rdquo;, <em>Proceedings of the Fifth IEEE International
Conference on Software Engineering and Formal Methods</em>, IEEE
Computer Society, pp. 47&ndash;58.</li>

<li>Schulz, S., 2004, &ldquo;System Abstract: E 0.81&rdquo;,
<em>Proceedings of the 2nd International Joint Conference on Automated
Reasoning</em> (Lecture Notes in Artificial Intelligence: Volume
3097), D. Basin and M. Rusinowitch (eds.), Berlin: Springer-Verlag,
pp.223-228.</li>

<li>Scott, D., 1972, &ldquo;Appendix B: Notes in Dana Scott&rsquo;s
Hand&rdquo;, in Sobel 2004, pp. 145&ndash;146.</li>

<li>Sieg, W. and J. Byrnes, 1996, <em>Normal Natural Deduction Proofs
(in Classical Logic)</em>, Report CMU-PHIL 74, Department of
Philosophy, Carnegie-Mellon University.</li>

<li>Slaney, J. K., 1984, &ldquo;3,088 Varieties: A Solution to the
Ackerman Constant Problem&rdquo;, <em>Journal of Symbolic Logic</em>,
50: 487&ndash;501.</li>

<li>Sobel, J. H., 2004, <em>Logic and Theism: Arguments for and
Against Beliefs in God</em>, Cambridge University Press.</li>

<li>
Steen, A. and C. Benzm&uuml;ller, 2021, &ldquo;Extensional Higher-Order Paramodulation in Leo-III&rdquo;, <em>Journal of Automated Reasoning</em>, 65 (6): 775&ndash;807.
</li>


<li>Stickel, M. E., 1992, &ldquo;A Prolog Technology Theorem Prover: A
New Exposition and Implementation in Prolog&rdquo;, <em>Theoretical
Computer Science</em>, 104: 109&ndash;128.</li>

<li>Suppes, P., <em>et al</em>., 1981, &ldquo;Part I: Interactive
Theorem Proving in CAI Courses&rdquo;, <em>University-Level
Computer-Assisted Instruction at Stanford: 1968&ndash;1980</em>, P.
Suppes (ed.), Institute for the Mathematical Study of the Social
Sciences, Stanford University.</li>

<li>
Sutcliffe, G., 2017, &ldquo;The TPTP Problem Library and Associated Infrastructure&rdquo;, <em>Journal of Automated Reasoning</em>, 59 (4): 483&ndash;502.
</li>

<li>Sutcliffe, G. and C. Benzm&uuml;ller, 2010, &ldquo;Automated
Reasoning in Higher-Order Logic Using TPTP THF Infrastructure&rdquo;,
<em>Journal of Formalized Reasoning</em>, 43 (4): 337&ndash;362.</li>

<li>Sutcliffe, G. and C. Suttner, 1998, &ldquo;The TPTP Problem
Library &ndash; CNF Release v1.2.1&rdquo;, <em>Journal of Automated
Reasoning</em>, 21 (2): 177&ndash;203.</li>

<li>Szabo, M. E. (ed.), 1969, <em>The Collected Papers of Gerhard
Gentzen</em>, Amsterdam: North-Holland.</li>

<li>Trybulec, A., 1978, &ldquo;The Mizar Logic Information
Language&rdquo;, <em>Bulletin of the Association for Literary
Linguistic Computing</em>, 6(2): 136&ndash;140.</li>

<li>Trybulec, A. and H. Blair, 1985, &ldquo;Computer Assisted
Reasoning with Mizar&rdquo;, <em>Proceedings of the 9th International
Joint Conference on Artificial Intelligence</em>, (IJCAI-85: Volume
1), Los Angeles, pp. 26&ndash;28.</li>

<li>Turing, A., 1936, &ldquo;On computable numbers, with an
application to the Entscheidungsproblem&rdquo;, <em>Proceedings of the
London Mathematical Society</em>, 42 (2): 230&ndash;265.</li>

<li>Urban, J., 2007, &ldquo;MaLARea: A Metasystem for Automated
Reasoning in Large Theories&rdquo;, <em>Proceedings of the CADE-21
Workshop on Empirically Successful Automated Reasoning in Large
Theories</em>, J. Urban, G. Sutcliffe and S. Schulz (eds.), pp.
45&ndash;58.</li>

<li>Urban, J., K. Hoder, A. Voronkov, 2010, &ldquo;Evaluation of
Automated Theorem Proving on the Mizar Mathematical Library&rdquo;,
<em>Mathematical Software &ndash; ICMS 2010: Proceedings of the Third
International Congress on Mathematical Software</em>, Kobe, Japan,
(Lecture Notes in Computer Science, Volume 6327), pp.
155&ndash;166.</li>

<li>Urban, J. and J. Vyskocil, 2012, &ldquo;Theorem Proving in Large
Formal Mathematics as an Emerging AI Field&rdquo;, <em>arXiv:1209.3914
[cs.AI]</em>, Report No. DPA-12271, Cornell University.</li>

<li>
Urquhart, A., 1987, &ldquo;Hard Examples for Resolution&rdquo;, <em>Journal of the ACM</em>, 34 (1): 209&ndash;219.
</li>

<li>&ndash;&ndash;&ndash;, 1994 (ed.), <em>The Collected Papers of Bertrand
Russell, Volume 4: Foundations of Logic, 1903-05</em>, Routledge,
London and New York.</li>

<li>van Benthem Jutting, L. S., 1977, <em>Checking Landau&rsquo;s
&ldquo;Grundlagen&rdquo; in the Automath system</em>, Ph.D. Thesis,
Eindhoven University of Technology; published in <em>Mathematical
Centre Tracts</em>, Number 83, Amsterdam: Mathematisch Centrum,
1979. </li>

<li>Voronkov, A., 1995, &ldquo;The Anatomy of Vampire: Implementing
Bottom-Up Procedures with Code Trees&rdquo;, <em>Journal of Automated
Reasoning</em>, 15 (2): 237&ndash;265.</li>

<li>Wallen, L. A., 1990, <em>Automated Deduction in Nonclassical
Logics</em>, Cambridge, MA: MIT Press.</li>

<li>Wang, H., 1960, &ldquo;Proving Theorems by Pattern Recognition
&ndash; I&rdquo;, in <em>Automation of Reasoning (Volume 1)</em>, J.
Siekmann and G. Wrightson (eds.), Berlin: Springer-Verlag, 1983, pp.
229&ndash;243.</li>

<li>&ndash;&ndash;&ndash;, 1960, &ldquo;Toward Mechanical
Mathematics&rdquo;, in <em>Automation of Reasoning</em> (Volume 1),
J. Siekmann and G. Wrightson (eds.), Berlin: Springer-Verlag, 1983,
pp. 244-264.</li>

<li>Wegner, B., 2011, &ldquo;Completeness of reference databases,
old-fashioned or not?&rdquo;, <em>Newsletter of the European
Mathematical Society</em>, 80: 50&ndash;52.</li>

<li>Wiedijk, F., 2006, <em>The Seventeen Provers of the World</em>,
(Lecture Notes in Artificial Intelligence: Volume 3600), F. Wiedijk
(ed.), New York: Springer-Verlag.</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;The QED Manifesto
Revisited&rdquo;, <em>Studies in Logic, Grammar and Rhetoric</em>, 10
(23): 121&ndash;133.</li>

<li>
Wooters, W.K. and W. H. Zurek, 1982, &ldquo;A single quantum cannot be cloned&rdquo;, <em>Nature</em>, 299: 802&ndash;803.
</li>

<li>Wos, L. (ed.), 2001, <em>Journal of Automated Reasoning</em>
(Special Issue: Advances in Logic Through Automated Reasoning), 27
(2).</li>

<li>Wos, L., D. Carson and G. R. Robinson, 1965, &ldquo;Efficiency and
Completeness of the Set of Support Strategy in Theorem Proving&rdquo;,
<em>Journal of the Association of Computing Machinery</em>, 12:
698&ndash;709.</li>

<li>Wos, L., R. Overbeek, E. Lusk and J. Boyle, 1984, <em>Automated
Reasoning: Introduction and Applications</em>, Englewood Cliffs, NJ:
Prentice-Hall.</li>

<li>Wos, L., D. Ulrich, and B. Fitelson, 2002, &ldquo;Vanquishing the
XCB Question; The Methodological Discovery of the Last Shortest Single
Axiom for the Equivalential Calculus&rdquo;, <em>Journal of Automated
Reasoning</em>, 29 (2):107&ndash;124.</li>

<li>Wos, L., S. Winker, R. Veroff, B. Smith and L. Henschen, 1983,
&ldquo;Questions Concerning Possible Shortest Single Axiom for the
Equivalential Calculus: An Application of Automated Theorem Proving to
Infinite Domains&rdquo;, <em>Notre Dame Journal of Formal Logic</em>,
24: 205&ndash;223.</li>

<li>Yoo, J., E. Jee and S. Cha, 2009, &ldquo;Formal Modeling and
Verification of Safety-Critical Software&rdquo;, <em>IEEE
Software</em>, 26 (3): 42&ndash;49.</li>

<li>
Zalta, E., 1983, <em>Abstract Objects: An Introduction to Axiomatic Metaphysics</em>, Synthese Library, SYLI Volume 160, Springer.
</li>

<li>
&ndash;&ndash;&ndash;, 1999, &ldquo;Natural Numbers and Natural Cardinals as Abstract Objects: A Partial Reconstruction of Frege&rsquo;s Grundgesetze in Object Theory&rdquo;, <em>Journal of Philosophical Logic</em>, 28 (6): 619&ndash;660.
</li>

<li>
&ndash;&ndash;&ndash;, 2018, &ldquo;How Computational Investigations Improved an Ontology&rdquo;, <em>2018 Annual Meeting of the International Association for Computing and Philosophy</em>, Warsaw, Polska Akademia Nauk (PAN), Copernicus Center,
</li>

<li>
&ndash;&ndash;&ndash;, 2022, <em>Principia Logico-Metaphysica</em>, Draft/Excerpt dated September 2, 2022, URL: http://mally.stanford.edu/principia.pdf
</li>

<li>Zhang, L. and S. Malik, 2002, &ldquo;The Quest for Efficient
Boolean Satisfiability Solvers&rdquo;, <em>CADE-18: Proceedings of the
18th International Conference on Automated Deduction</em>, (Lecture
Notes in Artificial Intelligence: Volume 2392), A. Voronkov (ed.),
Berlin: Springer-Verlag, pp. 295-313.</li>
</ul>

</div> 

<div id="academic-tools">

<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=reasoning-automated" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/reasoning-automated/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=reasoning-automated&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/reasoning-automated/" target="other">Enhanced bibliography for this entry</a>
at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>


</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<h3>Publications</h3>

<ul>

<li>Hales, T. C., 2005b, <a href="http://code.google.com/p/flyspeck/wiki/FlyspeckFactSheet" target="other"><em>The Flyspeck Project Fact Sheet</em></a>
</li>

<li>Hales, T. C., 2014, <a href="http://code.google.com/p/flyspeck/wiki/AnnouncingCompletion" target="other"><em>Flyspeck</em></a></li>

<li>Martin, U. and A. Pease, 2013,
 &ldquo;<a href="http://arxiv.org/abs/1305.0904" target="other">What does mathoverflow tell us about the production of mathematics?</a>,&rdquo;
 <em>Computing Research Repository</em>, at arxiv.org.</li>

<li>Sutcliffe, G., 2014, <em>Proceedings of the 7th IJCAR Automated
Theorem Proving System Competition (CASC-J7)</em>,
 <a href="http://www.cs.miami.edu/~tptp/CASC/J7/Proceedings.pdf" target="other">available online</a>,
 pp. 1&ndash;36.</li>

<li>Sutcliffe, G., 2016, <em>Proceedings of the 8th IJCAR Automated
Theorem Proving System Competition (CASC-J8)</em>,
 <a href="http://www.cs.miami.edu/~tptp/CASC/J8/Proceedings.pdf" target="other">available online</a>,
 pp. 1&ndash;40.</li>
</ul>

<h3>Web Sites</h3>

<ul>

 <li><a href="http://www.cs.utexas.edu/users/moore/acl2/" target="other">ACL2: A Computational Logic</a></li>
 
 <li><a href="http://wiki.portal.chalmers.se/agda/pmwiki.php" target="other">Alfa/Agda</a></li>
 
 <li><a href="http://coq.inria.fr/" target="other">The Coq Proof Assistant</a></li>
 
 <li><a href="http://cvc4.cs.stanford.edu/web/" target="other">CVC4</a></li>
 
 <li><a href="http://wwwlehre.dhbw-stuttgart.de/~sschulz/E/E.html" target="other">E Theorem Prover</a></li>
 
 <li><a href="http://www.cs.unm.edu/~mccune/eqp/" target="other">EQP Equational Prover</a></li>
 
 <li><a href="http://www.cl.cam.ac.uk/research/hvg/HOL/" target="other">HOL Automated Reasoning Group</a></li>
 
 <li><a href="http://www.cl.cam.ac.uk/~jrh13/hol-light/" target="other">HOL Light</a></li>
 
 <li><a href="http://imps.mcmaster.ca" target="other">IMPS: An Interactive Mathematical Proof System</a></li>
 
 <li><a href="http://www.cs.man.ac.uk/~korovink/iprover/" target="other">iProver</a></li>
 
 <li><a href="http://www.cl.cam.ac.uk/research/hvg/Isabelle/" target="other">Isabelle</a></li>
 
 <li><a href="http://www.leancop.de/" target="other">leanCoP</a></li>
 
 <li><a href="http://www.cl.cam.ac.uk/~lp15/Grants/LEO-II/index.html" target="other">LEO-II</a></li>
 
 <li><a href="http://page.mi.fu-berlin.de/lex/leo3/" target="other">LEO-III</a></li>
 
 <li><a href="http://us.metamath.org/" target="other">Metamath</a></li>
 
 <li><a href="http://www.cl.cam.ac.uk/~lp15/papers/Arith/" target="other">MetiTarski</a></li>
 
 <li><a href="http://www.minlog-system.de" target="other">The Minlog System</a></li>
 
 <li><a href="http://www.mizar.org/" target="other">The Mizar Project</a></li>
 
 <li><a href="http://www.nuprl.org/" target="other">The Nuprl Project</a></li>
 
 <li><a href="http://vlsicad.eecs.umich.edu/BK/Slots/cache/www.cs.chalmers.se/~koen/paradox/" target="other">Paradox</a></li>
 
 <li><a href="http://www.cs.unm.edu/~mccune/prover9/" target="other">Prover 9 and Mace 4</a></li>
 
 <li><a href="http://pvs.csl.sri.com/" target="other">PVS Specification and Verification System</a></li>
 
 <li><a href="http://www.ps.uni-saarland.de/~cebrown/satallax/" target="other">Satallax</a></li>
 
<li><a href="https://isabelle.in.tum.de/website-Isabelle2009-1/sledgehammer.html" target="other">Sledgehammer</a></li>

 <li><a href="http://www.spass-prover.org/" target="other">SPASS</a></li>
 
 <li><a href="http://gtps.math.cmu.edu/tps.html" target="other">TPS Theorem Proving System</a></li>
 
 <li><a href="http://vprover.github.io/" target="other">Vampire</a></li>
 
 <li><a href="http://www.waldmeister.org/" target="other">Waldmeister</a></li>
 
 <li><a href="http://yices.csl.sri.com/" target="other">Yices 2</a></li>
 
 <li><a href="http://github.com/Z3Prover/" target="other">Z3</a></li>
 
 <li><a href="http://www.cs.miami.edu/~tptp/CASC/" target="other">The CADE ATP System Competition</a></li>
 
 <li><a href="http://www.cs.miami.edu/~tptp/" target="other">The TPTP Problem Library for Automated Theorem Proving</a></li>
 
 <li><a href="http://smtlib.cs.uiowa.edu/" target="other">The SMT-LIB Satisfiability Modulo Theories Library</a></li>
 
 <li><a href="http://www.cs.ru.nl/~freek/qed/qed.html" target="other">The QED Manifesto</a></li>
 
 <li><a href="http://www.cadeinc.org/" target="other">CADE: The Conference on Automated Deduction</a></li>
 
 <li><a href="http://ijcar.org/" target="other">IJAR: The International Joint Conference on Automated Reasoning</a></li>
 </ul>
</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../logic-ai/">artificial intelligence: logic and</a> |
 <a href="../logic-classical/">logic: classical</a> |
 <a href="../logic-modal/">logic: modal</a> |
 <a href="../reasoning-defeasible/">reasoning: defeasible</a>

</p>

</div> 

<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJax.js?config=TeX-MML-AM_CHTML"></script>


</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2024</a> by

<br />
<a href="http://www.symlog.ca/Profile/Fred.htm" target="other">Frederic Portoraro</a>
&lt;<a href="m&#97;ilto:fred&#37;2eportoraro&#37;40symlog&#37;2eca"><em>fred<abbr title=" dot ">&#46;</abbr>portoraro<abbr title=" at ">&#64;</abbr>symlog<abbr title=" dot ">&#46;</abbr>ca</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
            <li role="menuitem"><a href="../../new.html">What's New</a></li>
            <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li role="menuitem"><a href="../../published.html">Chronological</a></li>
            <li role="menuitem"><a href="../../archives/">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
            <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
            <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
            <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
            <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
            <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
            <li role="menuitem"><a href="../../accessibility.html">Accessibility</a></li>
            <li role="menuitem"><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
            <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
            <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2024</a> by <a href="https://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>
</html>
