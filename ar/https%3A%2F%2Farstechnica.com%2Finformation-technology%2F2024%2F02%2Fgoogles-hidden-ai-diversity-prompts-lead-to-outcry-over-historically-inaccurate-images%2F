<!DOCTYPE html>
<html lang="en-us">

<head>
  <title>Google’s hidden AI diversity prompts lead to outcry over historically inaccurate images | Ars Technica</title>
<script type="text/javascript">
  ars = {"ASSETS":"https:\/\/cdn.arstechnica.net\/wp-content\/themes\/ars\/assets","HOME_URL":"https:\/\/arstechnica.com","CIVIS":"\/civis","THEME":"light","VIEW":"grid","MOBILE":false,"SUBSCRIBER":false,"PLUS_PLUS":false,"LOGGED":false,"USER_ID":null,"ENV":"production","AD":{"tags":["ai","ai-bias","ai-ethics","ai-image-generator","ai-safety","chatgpt","chatgtp","dall-e-2","dall-e-3","elon-musk","gemini","google-2","google-gemini","image-synthesis","machine-learning","meta","openai","racism","sexism","x"],"channel":"information-technology","slug":"googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images","template_type":"article","queue":[],"server":"production"},"TOTAL":111732,"UNREAD":0,"RECENT":[2005526,2005584,2005529,2005545,2000668,2005483,2005254,2005444,2005464,2005458,2005341,2005363,2005359,2005093,2004735,2005190,2005103,2005224,2005196,2005172,2005143,2004605,2004772,2005125,2005122],"LOGINS":true,"CROSS":false,"PARSELY":"arstechnica.com","COMMENTS":false,"HOMEPAGE":false,"SITE":1,"READY":[],"SHOW_ADS":true,"IMG_PROXY":"https:\/\/cdn.arstechnica.net\/i\/","CATEGORY":"information-technology","PAGETITLE":"","ZEN_MODE":false,"MEMO_PID":"62012a7a19351c07620394e0"};
</script>
<link rel="stylesheet" type="text/css" media="all" href="https://cdn.arstechnica.net/wp-content/themes/ars/assets/css/main-1eae76c908.css" />
    <link rel="alternate" type="application/rss+xml" href="http://feeds.arstechnica.com/arstechnica/index" />
  <link rel="shortcut icon" href="https://cdn.arstechnica.net/favicon.ico" />
  <link rel="icon" type="image/x-icon" href="https://cdn.arstechnica.net/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href="https://cdn.arstechnica.net/wp-content/themes/ars/assets/img/ars-ios-icon-d9a45f558c.png" />
  <link rel="mask-icon" href="https://cdn.arstechnica.net/wp-content/themes/ars/assets/img/ars-macos-safari-8997f76b21.svg" color="#ff4e00">
  <link rel="icon" sizes="192x192" href="https://cdn.arstechnica.net/wp-content/themes/ars/assets/img/material-ars-db41652381.png" />
  <link rel="me" href="https://mastodon.social/@arstechnica" />

    <meta name="application-name" content="Ars Technica"/>
  <meta name="msapplication-starturl" content="http://arstechnica.com/"/>
  <meta name="msapplication-tooltip" content="Ars Technica: Serving the technologist for 1.2 decades"/>
  <meta name="msapplication-task" content="name=News;action-uri=http://arstechnica.com/;icon-uri=https://cdn.arstechnica.net/favicon.ico"/>
  <meta name="msapplication-task" content="name=Features;action-uri=http://arstechnica.com/features/;icon-uri=https://cdn.arstechnica.net/ie-jump-menu/jump-features.ico"/>
  <meta name="msapplication-task" content="name=OpenForum;action-uri=http://arstechnica.com/civis/;icon-uri=https://cdn.arstechnica.net/ie-jump-menu/jump-forum.ico"/>
  <meta name="msapplication-task" content="name=Subscribe;action-uri=http://arstechnica.com/subscriptions/;icon-uri=https://cdn.arstechnica.net/ie-jump-menu/jump-subscribe.ico"/>


  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="advertising" content="ask" />
  <meta property="fb:admins" content="592156917" />
  <meta property="fb:admins" content="108943" />
  <meta property="fb:pages" content="19374573752" />

  <meta name="format-detection" content="telephone=no" />
  <meta name="theme-color" content="#000000" />

  
  <meta name="viewport" content="width=device-width,initial-scale=1">

  <!-- cache hit 256:single/meta:6e1d03fd7e3cf36efdc1f7720460dea9 -->
<meta name='parsely-page' content='{"title":"Google\u2019s hidden AI diversity prompts lead to outcry over historically inaccurate images","link":"https:\/\/arstechnica.com\/information-technology\/2024\/02\/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images\/","type":"post","author":"Benj Edwards","post_id":2005190,"pub_date":"2024-02-22T16:43:00Z","section":"Biz &amp; IT","tags":["ai","ai-bias","ai-ethics","ai-image-generator","ai-safety","chatgpt","chatgtp","dall-e-2","dall-e-3","elon-musk","gemini","google-2","google-gemini","image-synthesis","machine-learning","meta","openai","racism","sexism","x","type: report"],"image_url":"https:\/\/cdn.arstechnica.net\/wp-content\/uploads\/2024\/02\/gemini_diversity_hero-150x150.jpg"}'>
<meta name='parsely-metadata' content='{"type":"report","title":"Google\u2019s hidden AI diversity prompts lead to outcry over historically inaccurate images","post_id":2005190,"lower_deck":"Inserting depictions of diversity into AI images creates revisionist history, critics say.","image_url":"https:\/\/cdn.arstechnica.net\/wp-content\/uploads\/2024\/02\/gemini_diversity_hero-150x150.jpg","listing_image_url":"https:\/\/cdn.arstechnica.net\/wp-content\/uploads\/2024\/02\/gemini_diversity_hero-360x200.jpg"}'>

  <link rel="canonical" href="https://arstechnica.com/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/" />

<link rel="shorturl" href="https://arstechnica.com/?p=2005190" />

<meta name="description" content="Inserting depictions of diversity into AI images creates revisionist history, critics say." />

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:url" content="https://arstechnica.com/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/">
<meta name="twitter:title" content="Google’s hidden AI diversity prompts lead to outcry over historically inaccurate images">
<meta name="twitter:description" content="Inserting depictions of diversity into AI images creates revisionist history, critics say.">

<meta name="twitter:site" content="@arstechnica">
<meta name="twitter:domain" content="arstechnica.com">

<meta property="og:site_name" content="Ars Technica" />

<meta name="twitter:image:src" content="https://cdn.arstechnica.net/wp-content/uploads/2024/02/gemini_diversity_hero-760x380.jpg">
  <meta name="twitter:image:width" content="760">
  <meta name="twitter:image:height" content="380">

  <meta name="twitter:creator" content="@benjedwards">

<meta property="og:url" content="https://arstechnica.com/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/" />
<meta property="og:title" content="Google’s hidden AI diversity prompts lead to outcry over historically inaccurate images" />
<meta property="og:image" content="https://cdn.arstechnica.net/wp-content/uploads/2024/02/gemini_diversity_hero-760x380.jpg" />
<meta property="og:description" content="Inserting depictions of diversity into AI images creates revisionist history, critics say." />
<meta property="og:type" content="article" />
  <!-- cache hit 256:single/header:6e1d03fd7e3cf36efdc1f7720460dea9 -->
        

<!-- OneTrust Cookies Consent Notice start -->
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-domain-script="b10882a1-8446-4e7d-bfb2-ce2c770ad910">
</script>
<script id="oneTrustScripts">
    window.OptanonWrapper = function() {
        var CCPAButton = document.getElementById('ot-sdk-btn');
        CCPAButton && CCPAButton.classList.add('ot-sdk-btn--visible');
        window.dataLayer && window.dataLayer.push({
            event: 'OneTrustGroupsUpdated'
        });
        window.cnBus && window.cnBus.emit('onetrust.OneTrustGroupsUpdated');
    };
</script>
<script src="https://cdn.cookielaw.org/opt-out/otCCPAiab.js" ccpa-opt-out-ids="C0002,C0003,C0004,C0005" ccpa-opt-out-geo="ca" ccpa-opt-out-lspa="true">
</script>
<!-- OneTrust Cookies Consent Notice end -->
<!-- Google Tag Manager DataLayer -->
<script>
window.dataLayer = window.dataLayer || [];
window.dataLayer.push({"event":"data-layer-loaded","user":{"ars_userId":undefined,"amg_userId":undefined,"uID":undefined,"sID":undefined,"loginStatus":false,"subscriberStatus":"none","infinityId":undefined,"registrationSource":undefined,"mdw_cnd_id":undefined,"monthlyVisits":undefined,"accessPaywall":undefined,"view":"grid","theme":"light","show_comments":false},"content":{"pageTemplate":"single","pageType":"article|report","contentCategory":"information-technology","section":"information technology","subsection":undefined,"contributor":"Benj Edwards","contentID":2005190,"contentLength":1220,"display":"Google\u2019s hidden AI diversity prompts lead to outcry over historically inaccurate images","contentSource":"web","pageAssets":undefined,"uniqueContentCount":undefined,"monthlyContentCount":undefined,"publishDate":"2024-02-22T16:43:00-05:00","modifiedDate":"2024-02-22T17:48:54-05:00","keywords":"AI|AI bias|AI ethics|AI image generator|AI safety|ChatGPT|chatgtp|DALL-E 2|DALL-E 3|Elon Musk|gemini|google|Google Gemini|image synthesis|machine learning|meta|openai|Racism|sexism|X","dataSource":undefined},"marketing":{"campaignName":undefined,"circCampaignId":undefined,"internalCampaignId":undefined,"brand":"Ars Technica","certified_mrc_data":undefined,"condeNastId":undefined},"page":{"pID":undefined,"syndicatorUrl":undefined,"pageURL":"https:\/\/arstechnica.com\/?p=2005190","canonical":"https:\/\/arstechnica.com\/information-technology\/2024\/02\/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images\/","canonicalPathName":"\/information-technology\/2024\/02\/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images\/"},"search":{"facets":undefined,"searchTerms":undefined},"site":{"appVersion":"1.0.0"}});
</script>
<!-- End Google Tag Manager DataLayer -->
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-NLXNPCQ');</script>
<!-- End Google Tag Manager -->
<!-- Start Headline A/B -->
<script type="text/javascript">
  class ABTest {
    constructor(post_id, init_method) {
      this.post_id = post_id;
      this.ajaxurl = '/services/ars-ajax-handler.php';
      this.expireDays = 1 / 48; // 30 min
      this.group = this.getGroup();
      this.uid = this.getUid();
      this.init_method = init_method;
      this.setTitle();

      if (this.init_method === 'click') {
        this.click();
      } else {
        this.impression();
      }
    }

    setCookie(name, value, days) {
      var expires = "";
      if (days) {
        var date = new Date();
        date.setTime(date.getTime() + (days * 24 * 60 * 60 * 1000));
        expires = "; expires=" + date.toUTCString();
      }
      document.cookie = name + "=" + (value || "") + expires + "; path=/";
    }

    getCookie(name) {
      var nameEQ = name + "=";
      var ca = document.cookie.split(';');
      for (var i = 0; i < ca.length; i++) {
        var c = ca[i];
        while (c.charAt(0) == ' ') c = c.substring(1, c.length);
        if (c.indexOf(nameEQ) == 0) return c.substring(nameEQ.length, c.length);
      }
      return null;
    }

    // Retrieves a unique id for determining whether the event should be recorded
    getUid() {
      var uid = this.getCookie('ars_ab_' + this.post_id + '_uid');
      if (!uid) {
        uid = (Math.random() + 1).toString(36).substring(2, 7);
        this.setCookie('ars_ab_' + this.post_id + '_uid', uid, this.expireDays);
      }
      return uid;
    };

    // Places the user in either A or B for this post id
    getGroup() {
      var group = this.getCookie('ars_ab_' + this.post_id + '_group');
      if (!group) {
        group = String.fromCharCode(Math.floor(Math.random() * 2) + 65).toLowerCase();
        this.setCookie('ars_ab_' + this.post_id + '_group', group, this.expireDays);
      }
      return group;
    };

    // Records a headline impression (from homepage or other listing)
    impression() {
      // Send fake ajax
      var params = {
        nonce: '29ee78897c',
        action: 'ars_ab_impression',
        id: this.post_id,
        group: this.group,
        uid: this.uid,
        ts: (new Date()).getTime()
      };
      var url = this.ajaxurl + '?' + this.encodeParams(params);
      document.write('\x3Cscript type="text/javascript" src="' + url + '">\x3C/script>');
    };

    // Records a headline click from the actual post page
    click() {
      // Send fake ajax
      var params = {
        nonce: '0442e09f69',
        action: 'ars_ab_click',
        id: this.post_id,
        group: this.group,
        uid: this.uid,
        ts: (new Date()).getTime()
      };
      var url = this.ajaxurl + '?' + this.encodeParams(params);
      document.write('\x3Cscript type="text/javascript" src="' + url + '">\x3C/script>');
    };

    // If user is in B group, dynamically set title
    setTitle() {
      if (this.group == 'b') {
        var span = document.getElementById('ars_ab_' + this.post_id);
        var title = span.parentNode;
        title.innerHTML = span.getAttribute('data-title-b');
      }
    };

    encodeParams(data) {
      var ret = [];
      for (var d in data)
        ret.push(encodeURIComponent(d) + "=" + encodeURIComponent(data[d]));
      return ret.join("&");
    };

  };
</script>
<!-- End Headline A/B -->
<script>
  window.permutiveCohorts = {"cached_until":{"date":"2024-02-23 18:35:18.730869","timezone_type":3,"timezone":"UTC"},"cohorts":["buta","butd","buth","busx","bjfa","butb","bute","busu","butf","butc","busy","buly","butg","busz","buky"],"gam":["buta","butd","buth","busx","bjfa","butb","bute","busu","busz","butf","butc","busy","buly","butg"],"xandr":[]};
  window.permutiveContextInfo = {"pageProperties":{"client":{"url":"https:\/\/arstechnica.com\/information-technology\/2024\/02\/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images\/","referrer":"https:\/\/arstechnica.com\/?p=2005190","type":"web","user_agent":"Mozilla\/5.0 (Windows NT 6.1; Win64; x64; rv:48.0) Gecko\/20100101 Firefox\/48.0","domain":"arstechnica.com","title":"Google\u2019s hidden AI diversity prompts lead to outcry over historically inaccurate images &#8211; Ars Technica"},"type":"article","article":{"id":"2005190","category":"information-technology","subcategory":"","title":"Google\u2019s hidden AI diversity prompts lead to outcry over historically inaccurate images","tags":["ai","ai-bias","ai-ethics","ai-image-generator","ai-safety","chatgpt","chatgtp","dall-e-2","dall-e-3","elon-musk","gemini","google-2","google-gemini","image-synthesis","machine-learning","meta","openai","racism","sexism","x"]}},"url":"https:\/\/arstechnica.com\/information-technology\/2024\/02\/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images\/"};
</script>
<script src="https://www.googletagservices.com/tag/js/gpt.js" id="gpt-script" async></script>
<script>
  window.googletag = window.googletag || {};
  window.googletag.cmd = window.googletag.cmd || [];
  window.cns = window.cns || {};
  window.cns.queue = [];
  window.cns.async = function(s, c) {
    cns.queue.push({
      service: s,
      callback: c
    })
  };
  window.sparrowQueue = window.sparrowQueue || [];
</script>
<script>
  window.cns.pageContext = {"contentType":"article","templateType":"article","channel":"information-technology","subChannel":"","slug":"googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images","server":"production","keywords":{"tags":["ai","ai-bias","ai-ethics","ai-image-generator","ai-safety","chatgpt","chatgtp","dall-e-2","dall-e-3","elon-musk","gemini","google-2","google-gemini","image-synthesis","machine-learning","meta","openai","racism","sexism","x"],"cm":[],"platform":["wordpress"],"copilotid":""}};
</script>
<script src="https://ads-static.conde.digital/production/cns/builds/ars-technica/ars-technica.min.js" async></script>
<script type="text/javascript" src="https://cdn.arstechnica.net/wp-content/themes/ars/assets/js/ars-dc1d08cbd8.ads.us.js"></script>
  <script type="text/javascript">!(function(o,_name){function n(){(n.q=n.q||[]).push(arguments)}n.v=1,o[_name]=o[_name]||n;!(function(o,t,n,c){function e(n){(function(){try{return(localStorage.getItem("v4ac1eiZr0")||"").split(",")[4]>0}catch(o){}return!1})()&&(n=o[t].pubads())&&n.setTargeting("admiral-engaged","true")}(c=o[t]=o[t]||{}).cmd=c.cmd||[],typeof c.pubads===n?e():typeof c.cmd.unshift===n?c.cmd.unshift(e):c.cmd.push(e)})(window,"googletag","function");})(window,String.fromCharCode(97,100,109,105,114,97,108));!(function(t,c,i){i=t.createElement(c),t=t.getElementsByTagName(c)[0],i.async=1,i.src="https://shiverscissors.com/v2fumwIJOo-LsCB0dlG18VSTW43CpWhUEPJuKeRTzrEQdSPPlMr5GymU",t.parentNode.insertBefore(i,t)})(document,"script");</script>

  <!-- Taboola -->
  <script type="text/javascript">
    window._taboola = window._taboola || [];
    _taboola.push({
      article: 'auto'
    });
    ! function(e, f, u, i) {
      if (!document.getElementById(i)) {
        e.async = 1;
        e.src = u;
        e.id = i;
        f.parentNode.insertBefore(e, f);
      }
    }(document.createElement('script'),
      document.getElementsByTagName('script')[0],
      '//cdn.taboola.com/libtrc/condenast1-network/loader.js',
      'tb_loader_script');
    if (window.performance && typeof window.performance.mark == 'function') {
      window.performance.mark('tbl_ic');
    }
  </script>
  <meta name='robots' content='max-image-preview:large' />
<link rel='dns-prefetch' href='//cdn.arstechnica.net' />
<link rel='dns-prefetch' href='//s.w.org' />
<link rel='dns-prefetch' href='//arstechnica-apps.s3.amazonaws.com' />
<link rel='stylesheet' id='wp-block-library-css'  href='https://cdn.arstechnica.net/wp/wp-includes/css/dist/block-library/style.min.css?ver=6.0.3' type='text/css' media='all' />
<style id='global-styles-inline-css' type='text/css'>
body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--duotone--dark-grayscale: url('#wp-duotone-dark-grayscale');--wp--preset--duotone--grayscale: url('#wp-duotone-grayscale');--wp--preset--duotone--purple-yellow: url('#wp-duotone-purple-yellow');--wp--preset--duotone--blue-red: url('#wp-duotone-blue-red');--wp--preset--duotone--midnight: url('#wp-duotone-midnight');--wp--preset--duotone--magenta-yellow: url('#wp-duotone-magenta-yellow');--wp--preset--duotone--purple-green: url('#wp-duotone-purple-green');--wp--preset--duotone--blue-orange: url('#wp-duotone-blue-orange');--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
</style>
<link rel='stylesheet' id='article_forum_connect_comments-css'  href='https://cdn.arstechnica.net/wp-content/plugins/article-forum-connect/public/css/comments.css?ver=1.2.2' type='text/css' media='all' />
<link rel='stylesheet' id='article_forum_connect_paywall-css'  href='https://cdn.arstechnica.net/wp-content/plugins/article-forum-connect/public/css/paywall.css?ver=1.2.2' type='text/css' media='all' />
<meta property="article:published_time" content="2024-02-22T16:43:00+00:00">
<meta property="article:modified_time" content="2024-02-22T17:48:54+00:00">
<meta name="twitter:partner" content="tfwp" />
<!--
	generated 261 seconds ago
	generated in 0.221 seconds
	served from batcache in 0.003 seconds
	expires in 39 seconds
	billboard: forced 
	view: grid 
	theme: light 
 -->
</head>

<body class="post-template-default single single-post postid-2005190 single-format-standard grid-view light blog-us">
  <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NLXNPCQ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

      	<aside class="ad ad_crown" aria-label="Top of page advertisement"></aside>
  
  <div class="site-wrapper">
    <a class="screen-reader-text skip-link" href="#main" aria-label="Skip to main content">Skip to main content</a>
    <header class="site-header">
      <div class="header-left">
        <a href="https://arstechnica.com" id="header-logo" title="Ars Technica Homepage">
      <span class="icon icon-logo-ars-us"></span>
  </a>
      </div>

      <div class="header-right">
        <nav id="header-nav-primary">
          <ul>
            
  <li><a class="nav-link section-information-technology active" href="/information-technology/">Biz &amp; IT</a></li>
  <li><a class="nav-link section-gadgets " href="/gadgets/">Tech</a></li>
  <li><a class="nav-link section-science " href="/science/">Science</a></li>
  <li><a class="nav-link section-tech-policy " href="/tech-policy/">Policy</a></li>
  <li><a class="nav-link section-cars " href="/cars/">Cars</a></li>
  <li><a class="nav-link section-gaming " href="/gaming/">Gaming &amp; Culture</a></li>
  <li><a class="nav-link store" href="/store/">Store</a></li>
  <li><a class="nav-link forums" href="/civis/">Forums</a></li>
          </ul>
        </nav>

                              <a href="/store/product/subscriptions/" class="header-highlight-link">Subscribe</a>
                                  <div class="dropdown" id="header-search">
          <a href="/search/" class="dropdown-toggle search-toggle" aria-label="Search" aria-expanded="false">
            <span class="icon icon-search-mag-glass"></span>
          </a>
          <div class="dropdown-content">
            <form action="/search/" method="GET" id="search_form">
  <input type="hidden" name="ie" value="UTF-8">
  <input type="text" name="q" id="hdr_search_input" value="" aria-label="Search..." placeholder="Search...">
</form>
<a class="nav-search-close">Close</a>
          </div>
        </div>
        <div class="dropdown dropdown-mega" id="header-burger">
          <a href="#site-menu" class="dropdown-toggle" aria-label="Menu" aria-expanded="false">
            <span></span>
          </a>
          <div id="site-menu" class="dropdown-content">
            <section class="burger-navigate">
  <h3>
    <span class="icon icon-half-target"></span>
    Navigate
  </h3>
  <ul>
          <li><a class="nav-link store" href="/store/">Store</a></li>
      <li><a class="nav-link subscribe" href="/store/product/subscriptions/">Subscribe</a></li>
        <li><a class="nav-link videos" href="http://video.arstechnica.com/">Videos</a></li>
    <li><a class="nav-link section-features" href="/features/">Features</a></li>
    <li><a class="nav-link section-reviews" href="/reviews/">Reviews</a></li>
  </ul>

  <ul>
    <li><a class="nav-link page-rss-feeds" href="/rss-feeds/">RSS Feeds</a></li>
    <li><a class="nav-link mobile" href="/?view=mobile">Mobile Site</a></li>
  </ul>

  <ul>
    <li><a class="nav-link page-about-us" href="/about-us/">About Ars</a></li>
    <li><a class="nav-link page-staff-directory" href="/staff-directory/">Staff Directory</a></li>
    <li><a class="nav-link page-contact-us" href="/contact-us/">Contact Us</a></li>
  </ul>

  <ul>
    <li><a class="nav-link page-advertise-with-us" href="https://advertising.condenast.com/brands/ars-technica">Advertise with Ars</a></li>
    <li><a class="nav-link page-reprints" href="/reprints/">Reprints</a></li>
  </ul>
</section>

<section class="burger-filter">
  <h3>
    <span class="icon icon-half-mag"></span>
    Filter by topic
  </h3>
  <ul id="burger-nav-primary">
    
  <li><a class="nav-link section-information-technology active" href="/information-technology/">Biz &amp; IT</a></li>
  <li><a class="nav-link section-gadgets " href="/gadgets/">Tech</a></li>
  <li><a class="nav-link section-science " href="/science/">Science</a></li>
  <li><a class="nav-link section-tech-policy " href="/tech-policy/">Policy</a></li>
  <li><a class="nav-link section-cars " href="/cars/">Cars</a></li>
  <li><a class="nav-link section-gaming " href="/gaming/">Gaming &amp; Culture</a></li>
  <li><a class="nav-link store" href="/store/">Store</a></li>
  <li><a class="nav-link forums" href="/civis/">Forums</a></li>
  </ul>
</section>

<section class="burger-settings">
  <h3>
    <span class="icon icon-half-gear"></span>
    Settings
  </h3>
  <div>
    <div class="burger-layout">
      
<p>Front page layout</p>
<div class="burger-layout-grid">
  <a rel="nofollow" href="/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/?view=grid">
    <span class="icon icon-grid"></span><br>
    Grid
    <div class="faux-radio active"></div>
  </a>
</div>

<div class="burger-layout-list">
  <a rel="nofollow" href="/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/?view=archive">
    <span class="icon icon-list"></span><br>
    List
    <div class="faux-radio "></div>
  </a>
</div>

    </div>
    <div class="burger-theme">
      <p>Site theme</p>
  <div class="burger-theme-light">
    <a rel="nofollow" href="/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/?theme=light">
      <span><span>light</span></span>
      <div class="faux-radio active"></div>
    </a>
  </div>
  <div class="burger-theme-dark">
    <a rel="nofollow" href="/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/?theme=dark">
      <span><span>dark</span></span>
      <div class="faux-radio "></div>
    </a>
  </div>
    </div>
  </div>
</section>
          </div>
        </div>
              <a class="navlink login-link" href="https://arstechnica.com/civis/login?_xfRedirect=%2Finformation-technology%2F2024%2F02%2Fgoogles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images%2F">
      Sign in
    </a>
  
        </div>
    </header>

              
    <main id="main" class="content-wrapper">

<script type="text/javascript">
  ars.ARTICLE = {"url":"https:\/\/arstechnica.com\/information-technology\/2024\/02\/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images\/","short_url":"https:\/\/arstechnica.com\/?p=2005190","title":"Google\u2019s hidden AI diversity prompts lead to outcry over historically inaccurate images","author":857898,"authorName":"Benj Edwards","pubDate":"2024-02-22T16:43:00Z","id":2005190,"topic":1499045,"pages":1,"current_page":1,"superscroll":true,"promoted":[],"single_page":false,"comments":369,"fullwidth":false,"slug":"googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images","arsStaff":{"104481":{"name":"Aaron Zimmerman","title":"Copy Chief","staff":true},"332715":{"name":"Andrew Cunningham","title":"Senior Technology Reporter","staff":true},"855306":{"name":"Ashley Belanger","title":"Senior Policy Reporter","staff":true},"1002":{"name":"Aurich Lawson","title":"Creative Director","staff":true},"857898":{"name":"Benj Edwards","title":"AI and Machine Learning Reporter","staff":true},"509873":{"name":"Beth Mole","title":"Senior Health Reporter","staff":true},"453791":{"name":"Cathleen O'Grady","title":"Contributing science reporter","staff":false},"102179":{"name":"Chris Lee","title":"Associate writer","staff":true},"329388":{"name":"Dan Goodin","title":"Security Editor","staff":true},"254631":{"name":"Diana Gitig","title":"Associate Writer","staff":false},"25862":{"name":"Eric Bangeman","title":"Managing Editor","staff":true},"512413":{"name":"Eric Berger","title":"Senior Space Editor","staff":true},"46707":{"name":"Iljitsch van Beijnum","title":"Associate Writer","staff":false},"316010":{"name":"Jason Marlin","title":"Technical Director","staff":true},"746799":{"name":"Jennifer Ouellette","title":"Senior Writer","staff":true},"15365":{"name":"Jeremy Reimer","title":"Senior Niche Technology Historian","staff":false},"52979":{"name":"John Timmer","title":"Senior Science Editor","staff":true},"312082":{"name":"Jon Brodkin","title":"Senior IT Reporter","staff":true},"14317":{"name":"Jonathan M. Gitlin","title":"Automotive Editor","staff":true},"998":{"name":"Ken Fisher","title":"Editor in Chief","staff":true},"440179":{"name":"Kerry Staurseth","title":"Associate Copyeditor","staff":true},"856780":{"name":"Kevin Purdy","title":"Senior Technology Reporter","staff":true},"328283":{"name":"Kyle Orland","title":"Senior Gaming Editor","staff":true},"10243":{"name":"Lee Hutchinson","title":"Senior Technology Editor","staff":true},"173191":{"name":"Matthew Lasar","title":"Associate writer","staff":true},"182268":{"name":"Nate Anderson","title":"Deputy Editor","staff":true},"1991":{"name":"Ohrmazd","title":"","staff":false},"391727":{"name":"Ron Amadeo","title":"Reviews Editor","staff":true},"588289":{"name":"Samuel Axon","title":"Senior Editor","staff":true},"294205":{"name":"Scott K. Johnson","title":"Associate Writer","staff":true},"173910":{"name":"Timothy B. Lee","title":"Senior tech policy reporter","staff":false}},"tags":["ai","ai-bias","ai-ethics","ai-image-generator","ai-safety","chatgpt","chatgtp","dall-e-2","dall-e-3","elon-musk","gemini","google-2","google-gemini","image-synthesis","machine-learning","meta","openai","racism","sexism","x"],"zen_mode":false};
</script>

<article itemscope itemtype="http://schema.org/NewsArticle" class="article-single standalone intro-standard " id="">
      <div class="column-wrapper">
    <div class="left-column">
        <header class="article-header">
            <h4 class="post-upperdek">
      Trial and Error    &mdash;
</h4>
            <h1 itemprop="headline">Google’s hidden AI diversity prompts lead to outcry over historically inaccurate images</h1>
            <h2 itemprop="description">Inserting depictions of diversity into AI images creates revisionist history, critics say.</h2>
            <section class="post-meta">

  
<p class="byline" itemprop="author creator" itemscope itemtype="http://schema.org/Person">
      <a itemprop="url" href="https://arstechnica.com/author/benjedwards/"  rel="author" ><span itemprop="name">Benj Edwards</span></a>
    -    <time class="date" data-time="1708620180" datetime="2024-02-22T16:43:00+00:00">Feb 22, 2024 4:43 pm UTC</time>
</p>

  
</section>        </header>
        <section class="article-guts">
            <div itemprop="articleBody" class="article-content post-page">
                                    
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/gemini_diversity_hero-800x450.jpg" alt='Generations from Gemini AI from the prompt, "Paint me a historically accurate depiction of a medieval British king."'>
      <figcaption class="caption"><div class="caption-text"><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/gemini_diversity_hero.jpg" class="enlarge-link" data-height="675" data-width="1200">Enlarge</a> <span class="sep">/</span> Generations from Gemini AI from the prompt, "Paint me a historically accurate depiction of a medieval British king."</div><div class="caption-credit"><a rel="nofollow" class="caption-link" href="https://twitter.com/stratejake/status/1760333904857497650?s=20">@stratejake / X</a></div></figcaption>  </figure>

  <aside id="social-left" class="social-left" aria-label="Read the comments or share this article">
          <a class="comment-count icon-comment-bubble-down" href="https://arstechnica.com/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/?comments=1">
      <h4 class="comment-count-before">reader comments</h4>
  
  <span class="comment-count-number">369</span>
  </a>
        </aside>




<!-- cache hit 256:single/related:6e1d03fd7e3cf36efdc1f7720460dea9 --><!-- empty -->
<p>On Thursday morning, Google <a href="https://x.com/Google_Comms/status/1760603321944121506?s=20">announced</a> it was pausing its <a href="https://arstechnica.com/information-technology/2024/02/google-debuts-more-powerful-ultra-1-0-ai-model-in-rebranded-gemini-chatbot/">Gemini</a> AI image-synthesis feature in response to criticism that the tool was inserting diversity into its images in a historically inaccurate way, such as depicting <a href="https://x.com/FrDesouche/status/1760613548374290449?s=20">multi-racial Nazis</a> and <a href="https://x.com/stratejake/status/1760333904857497650?s=20">medieval British kings</a> with unlikely nationalities.</p>
<div class="pullbox sidebar story-sidebar right"><div class="story-sidebar-part"><a href="https://arstechnica.com/information-technology/2024/02/google-debuts-more-powerful-ultra-1-0-ai-model-in-rebranded-gemini-chatbot/" class="recommendation-further-reading story-sidebar-part-img" style="background-image:url('https://cdn.arstechnica.net/wp-content/uploads/2024/02/gemini_hero_2-360x200.jpg');" tabindex="-1" role="presentation" aria-hidden="true"></a><div class="story-sidebar-part-content"><h3>Further Reading</h3><a class="recommendation-further-reading" href="https://arstechnica.com/information-technology/2024/02/google-debuts-more-powerful-ultra-1-0-ai-model-in-rebranded-gemini-chatbot/">Google debuts more powerful “Ultra 1.0” AI model in rebranded “Gemini” chatbot</a></div></div></div>
<p>"We're already working to address recent issues with Gemini's image generation feature. While we do this, we're going to pause the image generation of people and will re-release an improved version soon," <a href="https://x.com/Google_Comms/status/1760603321944121506?s=20">wrote</a> Google in a statement Thursday morning.</p>
<p>As more people on X began to pile on Google for being "<a href="https://x.com/stclairashley/status/1760682923706167711?s=20">woke</a>," the Gemini generations inspired conspiracy theories that Google was purposely discriminating against white people and offering revisionist history to serve political goals. Beyond that angle, as The Verge <a href="https://www.theverge.com/2024/2/22/24079876/google-gemini-ai-photos-people-pause">points out</a>, some of these inaccurate depictions "were essentially erasing the history of race and gender discrimination."</p>
<figure class="image shortcode-img center large" style="width:100%"><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/GG70jhtXkAAsYr7.jpeg" class="enlarge" data-height="2400" data-width="1080" alt='A Gemini AI image generator result for "Can you generate an image of a 1943 German Soldier for me it should be an illustration."'><img alt='A Gemini AI image generator result for "Can you generate an image of a 1943 German Soldier for me it should be an illustration."' src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/GG70jhtXkAAsYr7-640x1422.jpeg" width="640" height="1422" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/02/GG70jhtXkAAsYr7.jpeg 2x"></a><figcaption class="caption"><div class="caption-text"><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/GG70jhtXkAAsYr7.jpeg" class="enlarge-link" data-height="2400" data-width="1080">Enlarge</a> <span class="sep">/</span> A Gemini AI image generator result for "Can you generate an image of a 1943 German Soldier for me it should be an illustration."</div><div class="caption-credit"><a rel="nofollow" class="caption-link" href="https://twitter.com/FrDesouche/status/1760613548374290449?s=20">@FrDesouche / X</a></div></figcaption></figure>
<p>Wednesday night, Elon Musk chimed in on the politically charged debate by posting a cartoon depicting AI progress as having two paths, one with "Maximum truth-seeking" on one side (next to an xAI logo for his company) and "Woke Racist" on the other, beside logos for OpenAI and Gemini.</p>
<p>This isn't the first time a company with an AI image-synthesis product has run into issues with diversity in its outputs. When AI image synthesis launched into the public eye with <a href="https://openai.com/dall-e-2">DALL-E 2</a> in April 2022, people <a href="https://www.wired.com/story/dall-e-2-ai-text-image-bias-social-media/">immediately noticed</a> that the results were often biased due to biased training data. For example, critics complained that prompts often resulted in racist or sexist images ("CEOs" were usually white men, "angry man" resulted in depictions of Black men, just to name a few). To counteract this, OpenAI <a href="https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2">invented a technique</a> in July 2022 whereby its system would <a href="https://twitter.com/jd_pressman/status/1549523790060605440">insert terms reflecting diversity</a> (like "Black," "female," or "Asian") into image-generation prompts in a way that was hidden from the user.</p>                                            <aside class="ad_wrapper" aria-label="In Content advertisement">
    <span class="ad_notice">Advertisement </span>    
    <div class="ad ad_instream"></div>    
</aside>
                                                        
<p>Google's Gemini system seems to do something similar, taking a user's image-generation prompt (the instruction, such as "make a painting of the founding fathers") and inserting terms for racial and gender diversity, such as "South Asian" or "non-binary" into the prompt before it is sent to the image-generator model. Someone on X <a href="https://x.com/BasedTorba/status/1760486551627182337?s=20">claims to have convinced</a> Gemini to describe how this system works, and it's consistent with our knowledge of how system prompts work with AI models. System prompts are written instructions that tell AI models how to behave, using natural language phrases.</p>
<p>When we tested Meta's "<a href="https://arstechnica.com/information-technology/2023/12/metas-new-ai-image-generator-was-trained-on-1-1-billion-instagram-and-facebook-photos/">Imagine with Meta AI</a>" image generator in December, we noticed a similar inserted diversity principle at work as an attempt to counteract bias.</p>
<figure class="image shortcode-img center large" style="width:100%"><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/openai_mitigation.jpg" class="enlarge" data-height="880" data-width="1681" alt="A screenshot of a July 2022 post where OpenAI shows off its technique to mitigate race and gender bias in AI image outputs. Google's use of a similar technique led to the controversy."><img alt="A screenshot of a July 2022 post where OpenAI shows off its technique to mitigate race and gender bias in AI image outputs. Google's use of a similar technique led to the controversy." src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/openai_mitigation-640x335.jpg" width="640" height="335" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/02/openai_mitigation-1280x670.jpg 2x"></a><figcaption class="caption"><div class="caption-text"><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/02/openai_mitigation.jpg" class="enlarge-link" data-height="880" data-width="1681">Enlarge</a> <span class="sep">/</span> A screenshot of a July 2022 post where OpenAI shows off its technique to mitigate race and gender bias in AI image outputs. Google's use of a similar technique led to the controversy.</div><div class="caption-credit"><a rel="nofollow" class="caption-link" href="https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2">OpenAI</a></div></figcaption></figure>
<p>As the controversy swelled on Wednesday, Google PR wrote, "We're working to improve these kinds of depictions immediately. Gemini's AI image generation does generate a wide range of people. And that's generally a good thing because people around the world use it. But it's missing the mark here."</p>
<p>The episode reflects an ongoing struggle in which AI researchers find themselves stuck in the middle of ideological and cultural battles online. Different factions demand different results from AI products (such as avoiding bias or keeping it) with no one cultural viewpoint fully satisfied. It's difficult to provide a monolithic AI model that will serve every political and cultural viewpoint, and some experts recognize that.</p>
<p>"We need a free and diverse set of AI assistants for the same reasons we need a free and diverse press," <a href="https://x.com/ylecun/status/1760299261898391571?s=20">wrote</a> Meta's chief AI scientist, Yann LeCun, on X. "They must reflect the diversity of languages, culture, value systems, political opinions, and centers of interest across the world."</p>
<div class="pullbox sidebar story-sidebar right"><div class="story-sidebar-part"><a href="https://arstechnica.com/information-technology/2022/09/openai-image-generator-dall-e-now-available-without-waitlist/" class="recommendation-further-reading story-sidebar-part-img" style="background-image:url('https://cdn.arstechnica.net/wp-content/uploads/2022/09/dalle_hero_1-360x200.jpg');" tabindex="-1" role="presentation" aria-hidden="true"></a><div class="story-sidebar-part-content"><h3>Further Reading</h3><a class="recommendation-further-reading" href="https://arstechnica.com/information-technology/2022/09/openai-image-generator-dall-e-now-available-without-waitlist/">DALL-E image generator is now open to everyone</a></div></div></div>
<p>When OpenAI went through these issues in 2022, its technique for diversity insertion led to some awkward generations at first, but because OpenAI was a relatively small company (compared to Google) taking baby steps into a new field, those missteps didn't attract as much attention. Over time, OpenAI has <a href="https://the-decoder.com/dall-e-3s-system-prompt-reveals-openais-rules-for-generative-image-ai/">refined its system prompts</a>, now included with ChatGPT and <a href="https://arstechnica.com/information-technology/2023/11/from-toy-to-tool-dall-e-3-is-a-wake-up-call-for-visual-artists-and-the-rest-of-us/">DALL-E 3</a>, to purposely include diversity in its outputs while mostly avoiding the situation Google is now facing. That took time and iteration, and Google will likely go through the same trial-and-error process, but on a very large public stage. To fix it, Google could modify its system instructions to avoid inserting diversity when the prompt involves a historical subject, for example.</p>
<p>On Wednesday, Gemini staffer Jack Kawczyk seemed to recognize this and <a href="https://x.com/JackK/status/1760334258722250785?s=20">wrote</a>, "<span class="css-1qaijid r-bcqeeo r-qvutc0 r-poiln3">We are aware that Gemini is offering inaccuracies in some historical image generation depictions, and we are working to fix this immediately. As part of our AI principles </span><a class="css-1qaijid r-bcqeeo r-qvutc0 r-poiln3 r-1loqt21" dir="ltr" role="link" href="https://t.co/IsJrFtCooz" target="_blank" rel="noopener noreferrer nofollow"><span class="css-1qaijid r-bcqeeo r-qvutc0 r-poiln3 r-hiw28u r-qvk6io" aria-hidden="true">https://</span>ai.google/responsibility<span class="css-1qaijid r-bcqeeo r-qvutc0 r-poiln3 r-hiw28u r-qvk6io" aria-hidden="true">/principles/</span></a><span class="css-1qaijid r-bcqeeo r-qvutc0 r-poiln3">, we design our image generation capabilities to reflect our global user base, and we take representation and bias seriously. We will continue to do this for open ended prompts (images of a person walking a dog are universal!) Historical contexts have more nuance to them and we will further tune to accommodate that. This is part of the alignment process - iteration on feedback."</span></p>

                                                </div>

            
            
            
        </section>
    </div>
    <div class="xrail">
        <div class="xrail-content">
            
            
            
                            <div class="ars-interlude-container ad_xrail ad_xrail_top"></div>
            
            
                            <aside class="ad ad_xrail ad_xrail_top ad_xrail_last" aria-label="Top sidebar advertisement"></aside>
                    </div>
    </div>
</div>

<div class="column-wrapper">
    <div class="left-column">
        <div id="social-footer">
                  <a class="comment-count icon-comment-bubble-down" href="https://arstechnica.com/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/?comments=1">
      <h4 class="comment-count-before">reader comments</h4>
  
  <span class="comment-count-number">369</span>
  </a>
          </div>
                    <!-- cache hit 256:single/author:0e58ddcb4f44020602cf08b75b04081c -->  <section class="article-author">
          <a style="background-image:url('https://cdn.arstechnica.net/wp-content/uploads/2022/08/benj_ega.png');" class="author-photo" href="/author/benjedwards" tabindex="-1" role="presentation" aria-hidden="true"></a>
    
    <div class="author-bio">
      <section class="author-bio-top">
        <a href="/author/benjedwards" class="author-name">Benj Edwards</a>
        Benj Edwards is an AI and Machine Learning Reporter for Ars Technica. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC.      </section>
    </div>

  </section>
            </div>
    <div class="xrail"></div>
</div>
<div id="article-footer-wrap">
            <aside class="ad_wrapper" aria-label="Full width advertisement">
    <span class="ad_notice">Advertisement </span>        
    <div class="ad ad_fullwidth fullwidth"></div>
</aside>
    
            <section id="comments-area" class="comments-area column-wrapper">
      <div class="row comments-row left-column">
      <a name="comments-bar"></a>
      
<div class="wp-forum-connect-container">

    

    
</div>

    </div>
          <div class="xrail xrail-comments">
        <div class="xrail-content-wrapper">
          <div class="xrail-content xrail-content-comments">
            <aside class="ad ad_xrail ad_xrail_comments" aria-label="Comments sidebar advertisement"></aside>
          </div>
        </div>
                  <div class="xrail-content-wrapper xrail-content-wrapper-bottom">
            <div class="xrail-content xrail-content-comments">
              <aside class="ad ad_xrail ad_xrail_comments" aria-label="Comments sidebar advertisement"></aside>
            </div>
          </div>
              </div>
      </section>
                    <section class="inline-playlist">
  <div class='ars-video-playlist'>
    <h3 class="ars-video-playlist-module-header">Channel <span>Ars Technica</span></h3>
    <div class='ars-video-playlist-module' data-playlist-id='arstechnica-channel-ars-information-technology' data-video-options='[]'></div>
  </div>
</section>
                <div class="prev-next-links">
  <a href="https://arstechnica.com/space/2024/02/spacex-seeks-to-launch-starship-at-least-nine-times-this-year/" rel="prev"><span class="arrow">&larr;</span> Previous story</a>  <a href="https://arstechnica.com/science/2024/02/british-comedian-inspires-linguistic-study-of-slang-synonyms-for-getting-drunk/" rel="next">Next story <span class="arrow">&rarr;</span></a></div>
        <footer id="article-footer">
  <div class="recommendations-footer">
    <div id="story-recommendations">
  <div class="heading-column">
    <h3>Related Stories</h3>
  </div>
  <ul id="story-recs" class="rec-wrap"></ul>
</div>
  </div>
      <div id="taboola-below-article-thumbnails---at"></div>
<script type="text/javascript">
  window._taboola = window._taboola || [];
  _taboola.push({
    mode: 'thumbnails-a-6x1',
    container: 'taboola-below-article-thumbnails---at',
    placement: 'Below Article Thumbnails - AT',
    target_type: 'mix'
  });
</script>
    <div class="recommendations-footer">
    <div id="latest-stories">
  <div class="heading-column">
    <h3>Today on Ars</h3>
  </div>
  <ul id="latest-recs" class="rec-wrap"></ul>
</div>
  </div>
</footer>
    </div>
  </article>
  </main>

  <footer class="site-footer">
    <nav class="nav-footer">

  <section>
    <ul>
      <li><a href="/store/">Store</a></li>
      <li><a href="/store/product/subscriptions/">Subscribe</a></li>
      <li><a href="/about-us/">About Us</a></li>
      <li><a href="/rss-feeds/">RSS Feeds</a></li>
      <li><a rel="nofollow" href="/information-technology/2024/02/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images/?view=mobile">View Mobile Site</a></li>
    </ul>
  </section>

  <section>
    <ul>
      <li><a href="/contact-us/">Contact Us</a></li>
      <li><a href="/staff-directory/">Staff</a></li>
      <li><a href="https://advertising.condenast.com/brands/ars-technica">Advertise with us</a></li>
      <li><a href="/reprints/">Reprints</a></li>
    </ul>
  </section>

  <section class="footer-newsletter">
    <div class="newsletter-wrapper">
      <h3>
        <a href="/newsletters/" class="footer-newsletter-sign-up">Newsletter Signup</a>
      </h3>
      <p>Join the Ars Orbital Transmission mailing list to get weekly updates delivered to your inbox. <a href="/newsletters/" class="footer-newsletter-sign-up">Sign me up &rarr;</a></p>

      <div class="footer-social-links">
        <a href="https://twitter.com/arstechnica" class="footer-social-twitter">
          <svg style="height: 40px; width: 40px;" id="b" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 40 40">
            <defs>
              <clipPath id="e">
                <rect width="40" height="40" fill="none" />
              </clipPath>
              <clipPath id="f">
                <rect width="40" height="40" fill="none" />
              </clipPath>
            </defs>
            <g id="c">
              <g id="d">
                <g clip-path="url(#e)">
                  <g clip-path="url(#f)">
                    <path d="M16.3,28.1c7.5,0,11.7-6.3,11.7-11.7s0-.4,0-.5c.8-.6,1.5-1.3,2-2.1-.7,.3-1.5,.5-2.4,.6,.9-.5,1.5-1.3,1.8-2.3-.8,.5-1.7,.8-2.6,1-.6-.7-1.4-1.1-2.3-1.2s-1.8,0-2.6,.4c-.8,.4-1.4,1.1-1.8,1.9-.4,.8-.5,1.7-.3,2.6-1.6,0-3.2-.5-4.7-1.2-1.5-.7-2.7-1.8-3.8-3-.5,.9-.7,2-.5,3,.2,1,.9,1.9,1.7,2.5-.7,0-1.3-.2-1.9-.5h0c0,1,.3,1.9,.9,2.7,.6,.7,1.4,1.2,2.4,1.4-.6,.2-1.2,.2-1.9,0,.3,.8,.8,1.5,1.5,2s1.5,.8,2.4,.8c-1.5,1.1-3.2,1.8-5.1,1.8-.3,0-.7,0-1,0,1.9,1.2,4.1,1.8,6.3,1.8" fill="currentColor" />
                  </g>
                </g>
              </g>
            </g>
          </svg>
        </a>
        <a href="https://mastodon.social/@arstechnica" class="footer-social-mastodon">
          <svg style="height: 40px; width: 40px;" id="b" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 40 40">
            <defs>
              <clipPath id="e">
                <rect width="40" height="40" fill="none" />
              </clipPath>
              <clipPath id="f">
                <rect width="40" height="40" fill="none" />
              </clipPath>
            </defs>
            <g id="c">
              <g id="d">
                <g clip-path="url(#e)">
                  <g clip-path="url(#f)">
                    <path d="M29.3,16.6c0-4.3-2.8-5.6-2.8-5.6-1.4-.7-3.9-.9-6.5-1h0c-2.6,0-5,.3-6.4,1,0,0-2.8,1.3-2.8,5.6s0,2.2,0,3.4c.1,4.2,.8,8.4,4.7,9.5,1.8,.5,3.4,.6,4.6,.5,2.3-.1,3.5-.8,3.5-.8v-1.6c0,0-1.7,.5-3.5,.4-1.8,0-3.7-.2-4-2.4,0-.2,0-.4,0-.6,0,0,1.8,.4,4,.5,1.4,0,2.7,0,4-.2,2.5-.3,4.7-1.8,5-3.3,.4-2.2,.4-5.4,.4-5.4h0Zm-3.4,5.6h-2.1v-5.1c0-1.1-.5-1.6-1.4-1.6s-1.5,.6-1.5,1.9v2.8h-2.1v-2.8c0-1.3-.5-1.9-1.5-1.9s-1.4,.5-1.4,1.6v5.1h-2.1v-5.3c0-1.1,.3-1.9,.8-2.6,.6-.6,1.3-1,2.2-1s1.9,.4,2.4,1.2l.5,.9,.5-.9c.5-.8,1.3-1.2,2.4-1.2s1.7,.3,2.2,1c.6,.6,.8,1.5,.8,2.6v5.3Z" fill="currentColor" />
                  </g>
                </g>
              </g>
            </g>
          </svg>
        </a>
        <a href="https://www.facebook.com/arstechnica" class="footer-social-facebook">
          <svg style="height: 40px; width: 40px;" id="b" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 40 40">
            <defs>
              <clipPath id="e">
                <rect width="40" height="40" fill="none" />
              </clipPath>
              <clipPath id="f">
                <rect width="40" height="40" fill="none" />
              </clipPath>
            </defs>
            <g id="c">
              <g id="d">
                <g clip-path="url(#e)">
                  <g clip-path="url(#f)">
                    <path d="M17.3,13.9v2.8h-2v3.4h2v10h4.2v-10h2.8s.3-1.6,.4-3.4h-3.2v-2.3c0-.3,.5-.8,.9-.8h2.3v-3.5h-3.1c-4.4,0-4.3,3.4-4.3,3.9" fill="currentColor" />
                  </g>
                </g>
              </g>
            </g>
          </svg>
        </a>
        <a href="https://www.youtube.com/@arstechnica" class="footer-social-youtube">
          <svg style="height: 40px; width: 40px;" id="b" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 40 40">
            <defs>
              <clipPath id="e">
                <rect width="40" height="40" fill="none" />
              </clipPath>
              <clipPath id="f">
                <rect width="40" height="40" fill="none" />
              </clipPath>
            </defs>
            <g id="c">
              <g id="d">
                <g clip-path="url(#e)">
                  <g clip-path="url(#f)">
                    <path d="M29.6,15.2c-.1-.4-.3-.8-.6-1.1-.3-.3-.7-.5-1.1-.7-1.6-.4-7.8-.4-7.8-.4,0,0-6.3,0-7.8,.4-.4,.1-.8,.3-1.1,.7-.3,.3-.5,.7-.6,1.1-.4,1.6-.4,4.8-.4,4.8,0,0,0,3.3,.4,4.8,.1,.4,.3,.8,.6,1.1,.3,.3,.7,.5,1.1,.7,1.6,.4,7.8,.4,7.8,.4,0,0,6.3,0,7.8-.4,.4-.1,.8-.3,1.1-.7s.5-.7,.6-1.1c.4-1.6,.4-4.8,.4-4.8,0,0,0-3.3-.4-4.8m-11.6,7.8v-5.9l5.2,3-5.2,3Z" fill="currentColor" />
                  </g>
                </g>
              </g>
            </g>
          </svg>
        </a>
        <a href="https://www.instagram.com/arstechnica/" class="footer-social-instagram">
          <svg style="height: 40px; width: 40px;" id="b" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 40 40">
            <defs>
              <clipPath id="e">
                <rect width="40" height="40" fill="none" />
              </clipPath>
              <clipPath id="f">
                <rect width="40" height="40" fill="none" />
              </clipPath>
            </defs>
            <g id="c">
              <g id="d">
                <g clip-path="url(#e)">
                  <g clip-path="url(#f)">
                    <path d="M20,10c2.7,0,3.1,0,4.1,0,1.1,0,1.8,.2,2.4,.5,.7,.3,1.2,.6,1.8,1.2,.6,.6,.9,1.1,1.2,1.8,.2,.6,.4,1.4,.5,2.4,0,1.1,0,1.4,0,4.1s0,3.1,0,4.1c0,1.1-.2,1.8-.5,2.4-.3,.7-.6,1.3-1.2,1.8-.6,.6-1.1,.9-1.8,1.2-.6,.2-1.4,.4-2.4,.5-1.1,0-1.4,0-4.1,0s-3.1,0-4.1,0c-1.1,0-1.8-.2-2.4-.5-.7-.3-1.3-.6-1.8-1.2-.5-.5-.9-1.1-1.2-1.8-.2-.6-.4-1.4-.5-2.4,0-1.1,0-1.4,0-4.1s0-3.1,0-4.1c0-1.1,.2-1.8,.5-2.4,.3-.7,.6-1.2,1.2-1.8,.6-.6,1.1-.9,1.8-1.2,.6-.2,1.4-.4,2.4-.5,1.1,0,1.4,0,4.1,0m0,2.5c-2.4,0-2.7,0-3.7,0-.9,0-1.4,.2-1.7,.3-.4,.1-.8,.4-1.1,.7-.3,.3-.5,.6-.7,1.1-.1,.3-.3,.8-.3,1.7,0,1,0,1.3,0,3.7s0,2.7,0,3.7c0,.9,.2,1.4,.3,1.7,.2,.4,.4,.7,.7,1.1,.3,.3,.6,.5,1.1,.7,.3,.1,.8,.3,1.7,.3,1,0,1.3,0,3.7,0s2.7,0,3.7,0c.9,0,1.4-.2,1.7-.3,.4-.2,.7-.4,1.1-.7,.3-.3,.5-.6,.7-1.1,.1-.3,.3-.8,.3-1.7,0-1,0-1.3,0-3.7s0-2.7,0-3.7c0-.9-.2-1.4-.3-1.7-.1-.4-.4-.8-.7-1.1-.3-.3-.7-.5-1.1-.7-.3-.1-.8-.3-1.7-.3-1,0-1.3,0-3.7,0m0,2.2c.7,0,1.4,.1,2,.4,.6,.3,1.2,.7,1.7,1.1,.5,.5,.9,1.1,1.1,1.7,.3,.6,.4,1.3,.4,2s-.1,1.4-.4,2c-.3,.6-.7,1.2-1.1,1.7-.5,.5-1.1,.9-1.7,1.1-.6,.3-1.3,.4-2,.4-1.4,0-2.7-.6-3.7-1.5-1-1-1.5-2.3-1.5-3.7s.6-2.7,1.5-3.7,2.3-1.5,3.7-1.5m0,8.3c.8,0,1.5-.3,2.1-.9,.6-.6,.9-1.3,.9-2.1s-.3-1.5-.9-2.1c-.6-.6-1.3-.9-2.1-.9s-1.5,.3-2.1,.9c-.6,.6-.9,1.3-.9,2.1s.3,1.5,.9,2.1c.6,.6,1.3,.9,2.1,.9m6.6-8.1c0,.4-.2,.7-.4,1s-.6,.4-1,.4-.7-.2-1-.4c-.3-.3-.4-.6-.4-1s.2-.7,.4-1c.3-.3,.6-.4,1-.4s.7,.2,1,.4c.3,.3,.4,.6,.4,1" fill="currentColor" />
                  </g>
                </g>
              </g>
            </g>
          </svg>
        </a>
      </div>

    </div>
  </section>
</nav>

<section class="footer-terms-logo">
  <div class="cn-logo">
    <a href="http://condenast.com/" class="icon icon-logo-cn-us" title="Visit Condé Nast"></a>
  </div>

  <p id="copyright-terms">
  CNMN Collection<br>
  WIRED Media Group<br>
  © 2024 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our <a href="https://www.condenast.com/user-agreement/">User Agreement</a> (updated 1/1/20) and <a href="https://www.condenast.com/privacy-policy/">Privacy Policy and Cookie Statement</a> (updated 1/1/20) and <a href="/amendment-to-conde-nast-user-agreement-privacy-policy/">Ars Technica Addendum</a> (effective 8/21/2018). Ars may earn compensation on sales from links on this site. <a href="/affiliate-link-policy/">Read our affiliate link policy</a>.<br>
  <span style="display: inline-flex; flex-flow: row nowrap; align-items: center; gap: 5px;"><a href="https://www.condenast.com/privacy-policy/#california">Your California Privacy Rights</a> | <img src="https://cdn.arstechnica.net/wp-content/themes/ars/assets/img/privacyoptions123x59-c5c9972158.png" style="height: 1em; width: auto;" /> <a id="ot-sdk-btn" class="ot-sdk-show-settings">Do Not Sell My Personal Information</a></span><br>
  The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.<br>
  <a href="https://www.condenast.com/online-behavioral-advertising-oba-and-how-to-opt-out-of-oba/#clickheretoreadmoreaboutonlinebehavioraladvertising(oba)">Ad Choices</a>
</p>
</section>
  </footer>
  </div>

  <script type="text/javascript" src="https://cdn.arstechnica.net/wp-content/themes/ars/assets/js/main-db925e406c.js"></script>


<!-- cache hit 256:single/javascript-footer:6e1d03fd7e3cf36efdc1f7720460dea9 -->
        


    <!-- Taboola -->
  <script type="text/javascript">
    window._taboola = window._taboola || [];
    _taboola.push({
      flush: true
    });
  </script>

  <!-- Parse.ly start -->
<script type="text/plain" class="optanon-category-C0002" id="parsely-cfg" src="//fpa-cdn.arstechnica.com/keys/arstechnica.com/p.js"></script>
<!-- Parse.ly end -->

<!-- Memo start -->
<script type="text/javascript">
__memo_config = {
	pid: ars.MEMO_PID,
	url: ars.ARTICLE.url,
	author: [ars.ARTICLE.authorName],
	title: ars.ARTICLE.title,
	date: ars.ARTICLE.pubDate,
};
(function(){
	var s = document.createElement('script'); 
	s.async = true; 
	s.type = 'text/javascript'; 
	s.src = document.location.protocol + '//cdn.memo.co/js/memo.js';
	(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body') [0]).appendChild(s); 
})();
</script>
<!-- Memo end -->

  
  
    
<script>
  (function() {
    var w = window.innerWidth ||
      document.documentElement.clientWidth ||
      document.body.clientWidth;
    var src = 'https://player.cnevids.com/interlude/arstechnica.js';
    if (!ars.MOBILE && w >= 1000) {
      src += '?isRightRail=true';
    }
    var s = document.createElement('script');
    s.setAttribute('async', true);
    s.setAttribute('src', src);
    document.body.appendChild(s);
  })();
</script>

<script id="conde-polar" src="https://cdn.mediavoice.com/nativeads/script/condenastcorporate/conde-asa-polar-master.js" async></script>
<!-- Sparrow begin -->
<script type="text/plain" class="optanon-category-C0004">
  (function() {
    function DQ() {
      var queue = window.sparrowQueue;
      this.push = fn => fn();
      window.sparrowQueue = this;
      while (queue.length) {
        queue.shift()();
      }
    }

    function e(t, e) {
      var n, a, o;
      a = !1, n = document.createElement("script"), n.type = "text/javascript", n.src = t, n.onload = n.onreadystatechange = function() {
        a || this.readyState && "complete" != this.readyState || (a = !0, e ? e() : !0)
      }, o = document.getElementsByTagName("script")[0], o.parentNode.insertBefore(n, o)
    }
    if (location.search.indexOf('no_sparrow') < 0) {
      e("https://pixel.condenastdigital.com/config/v2/production/ars-technica.config.js", function() {
        e("https://pixel.condenastdigital.com/sparrow.min.js", function() {
          if (window.SparrowConfigV2) {
            window.sparrow = new window.Sparrow(window.SparrowConfigV2);
            new DQ();
          }
        })
      })
    }
  })();
</script>
<!-- Sparrow end -->
<script type="text/javascript" src="//s.skimresources.com/js/100098X1555750.skimlinks.js"></script>
<script type='text/javascript' id='snowplow-js-before'>
window.snowplowQueue = window.snowplowQueue || []; window.snowplowContexts = {"site":{"orgId":"4gKgcFGUFUvCGFzHakTPfYp85Yi8","orgAppId":null,"appVersion":null,"env":"production"},"content":{"functionalTags":null,"hasBuyButtons":null,"noOfRevisions":null,"editorNames":null,"author_name":"Benj Edwards","contentId":"2005190","contentLength":1,"contentTitle":"Google\u2019s hidden AI diversity prompts lead to outcry over historically inaccurate images","contentSource":"web","authorIds":"46031","publishDate":"2024-02-22T16:43:00Z","modifiedDate":"2024-02-22T17:48:54Z","tags":"AI|AI bias|AI ethics|AI image generator|AI safety|ChatGPT|chatgtp|DALL-E 2|DALL-E 3|Elon Musk|gemini|google|Google Gemini|image synthesis|machine learning|meta|openai|Racism|sexism|X","contentLang":"en-US","galleryName":null,"totalGalleryImages":null,"wordCount":811,"contentType":null,"templateType":"article_standard_two_column","primaryTag":null,"contentFlag":"news","isCommerceContent":null,"pageTypeProperties":null,"section":"information technology","subsection":null,"subsection2":null,"dataSource":"web","content_type":"article"},"syndication":{"content":null,"originalSource":null,"originalContentLanguage":null},"page":{"canonical":"https:\/\/arstechnica.com\/information-technology\/2024\/02\/googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images\/","syndicatorUrl":null},"user":{"amguuid":null}}; window.snowplowConfig = {"SNOWPLOW_COLLECTOR":"c.arstechnica.com","SNOWPLOW_SCRIPT":"https:\/\/globalservices.conde.digital\/p77xzrbz9z.js","AVO_API_KEY":"FTJO6mVPBIzdGhjn2Ruy","APP_ID":"ars-technica","APP_NAME":"ars-technica","APP_ENV":"production","APP_VERSION":"1.0.0","COOKIE_DOMAIN":".arstechnica.com"};
</script>
<script type='text/javascript' src='https://cdn.arstechnica.net/wp-content/mu-plugins/ars-snowplow/ars-snowplow-js/dist/index.js?ver=1.0.3' id='snowplow-js'></script>
<script type='text/javascript' src='https://cdn.arstechnica.net/wp-content/plugins/article-forum-connect/public/js/iframeResizer.min.js?ver=1.2.2' id='article_forum_connect_iframe_resizer-js'></script>
<script type='text/javascript' src='https://cdn.arstechnica.net/wp-content/plugins/article-forum-connect/public/js/iframe.js?ver=1.2.2' id='article_forum_connect_iframe-js'></script>
  </body>

  </html>