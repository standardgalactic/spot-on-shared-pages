<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Can philosophy help us get a grip on the consequences of AI? | Aeon Essays</title><meta name="robots" content="index,follow,max-image-preview:large"/><meta name="description" content="Generative agents will change our society in weird, wonderful and worrying ways. Can philosophy help us get a grip on them?"/><meta property="og:title" content="Can philosophy help us get a grip on the consequences of AI? | Aeon Essays"/><meta property="og:description" content="Generative agents will change our society in weird, wonderful and worrying ways. Can philosophy help us get a grip on them?"/><meta property="og:url" content="https://aeon.co/essays/can-philosophy-help-us-get-a-grip-on-the-consequences-of-ai"/><meta property="og:type" content="article"/><meta property="og:image" content="https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=1200&amp;quality=75&amp;format=auto"/><meta property="og:image:alt" content="&lt;p&gt;&lt;em&gt;Photo by Ronny Navarro/Unsplash&lt;/em&gt;&lt;/p&gt;"/><meta property="og:image:width" content="2000"/><meta property="og:image:height" content="1252"/><link rel="canonical" href="https://aeon.co/essays/can-philosophy-help-us-get-a-grip-on-the-consequences-of-ai"/><meta name="theme-color" content="#035a6d"/><meta name="twitter:label1" content="Reading time"/><meta name="twitter:data1" content="24 min read"/><link rel="alternate" type="application/rss+xml" title="Aeon | a world of ideas" href="/feed.rss"/><link rel="alternate" type="application/atom+xml" title="Aeon | a world of ideas" href="/feed.atom"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Science","item":"https://aeon.co/science"},{"@type":"ListItem","position":2,"name":"Computing and artificial intelligence","item":"https://aeon.co/science/computing-artificial-intelligence"},{"@type":"ListItem","position":3,"name":"Frontier AI ethics","item":"https://aeon.co/essays/can-philosophy-help-us-get-a-grip-on-the-consequences-of-ai"}]}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Essays","item":"https://aeon.co/essays"},{"@type":"ListItem","position":2,"name":"Frontier AI ethics","item":"https://aeon.co/essays/can-philosophy-help-us-get-a-grip-on-the-consequences-of-ai"}]}</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","datePublished":"2024-02-13","description":"Generative agents will change our society in weird, wonderful and worrying ways. Can philosophy help us get a grip on them?","mainEntityOfPage":{"@type":"WebPage","@id":"https://aeon.co/essays/can-philosophy-help-us-get-a-grip-on-the-consequences-of-ai"},"headline":"Can philosophy help us get a grip on the consequences of AI? | Aeon Essays","image":["https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=1200&amp;quality=75&amp;format=auto"],"dateModified":"2024-02-13","author":[{"@type":"Person","name":"Seth Lazar","url":"https://aeon.co/users/seth-lazar"}],"publisher":{"@type":"Organization","name":"Aeon Magazine","logo":{"@type":"ImageObject","url":"https://aeon.co/logo.png"}},"isAccessibleForFree":true,"articleBody":"Around a year ago, generative AI took the world by storm, as extraordinarily powerful large language models (LLMs) enabled unprecedented performance at a wider range of tasks than ever before feasible. Though best known for generating convincing text and images, LLMs like OpenAI’s GPT-4 and Google’s Gemini are likely to have greater social impacts as the executive centre for complex systems that integrate additional tools for both learning about the world and acting on it. These generative agents will power companions that introduce new categories of social relationship, and change old ones. They may well radically change the attention economy. And they will revolutionise personal computing, enabling everyone to control digital technologies with language alone. Much of the attention being paid to generative AI systems has focused on how they replicate the pathologies of already widely deployed AI systems, arguing that they centralise power and wealth, ignore copyright protections, depend on exploitative labour practices, and use excessive resources. Other critics highlight how they foreshadow vastly more powerful future systems that might threaten humanity’s survival. The first group says there is nothing new here; the other looks through the present to a perhaps distant horizon. I want instead to pay attention to what makes these particular systems distinctive: both their remarkable scientific achievement, and the most likely and consequential ways in which they will change society over the next five to 10 years. It may help to start by reviewing how LLMs work, and how they can be used to make generative agents. An LLM is a large AI model trained on vast amounts of data with vast amounts of computational resources (lots of GPUs) to predict the next word given a sequence of words (a prompt). The process starts by chunking the training data into similarly sized ‘tokens’ (words or parts of words), then for a given set of tokens masking out some of them, and attempting to predict the tokens that have been masked (so the model is self-supervised – it marks its own work). A predictive model for the underlying token distribution is built by passing it through many layers of a neural network, with each layer refining the model in some dimension or other to make it more accurate. This approach to modelling natural language has been around for several years. One key recent innovation has been to take these ‘pretrained’ models, which are basically just good at predicting the next token given a sequence of tokens, and fine-tune them for different tasks. This is done with supervised learning on labelled data. For example, you might train a pretrained model to be a good dialogue agent by using many examples of helpful responses to questions. This fine-tuning enables us to build models that can predict not just the most likely next token, but the most helpful one – and this is much more useful. Of course, these models are trained on large corpuses of internet data that include a lot of toxic and dangerous content, so their being helpful is a double-edged sword! A helpful model would helpfully tell you how to build a bomb or kill yourself, if asked. The other key innovation has been to make these models much less likely to share dangerous information or generate toxic content. This is done with both supervised and reinforcement learning. Reinforcement learning from human feedback (RLHF) has proved particularly effective. In RLHF, to simplify again, the model generates two responses to a given prompt, and a human evaluator determines which is better than the other according to some criteria. A reinforcement learning algorithm uses that feedback to build a predictor (a reward model) for how different completions would be evaluated by a human rater. The instruction-tuned LLM is then fine-tuned on that reward model. Reinforcement learning with AI feedback (RLAIF) basically does the same, but uses another LLM to evaluate prompt completions. When given a prompt that invites it to do some mathematics, it might decide to call on a calculator instead So, we’ve now fine-tuned a pretrained model with supervised learning to perform some specific function, and then used reinforcement learning to minimise its prospect of behaving badly. This fine-tuned model is then deployed in a broader system. Even when developers provide a straightforward application programming interface (API) to make calls on the model, they incorporate input and output filtering (to limit harmful prompting, and redact harmful completions), and the model itself is under further developer instructions reminding it to respond to prompts in a conformant way. And with apps like ChatGPT, multiple models are integrated together (for example, for image as well as text generation) and further elements of user interface design are layered on top. This gives a basic description of a generative AI system. They build on significant breakthroughs in modelling natural language, and generate text in ways that impressively simulate human writers, while drawing on more information than any human could. In addition, many other tasks can be learned by models trained only to predict the next token – for example, translation between languages, some mathematical competence, and the ability to play chess. But the most exciting surprise is LLMs’ ability, with fine-tuning, to use software tools to achieve particular goals. The basic idea is simple. People use text to write programs making API calls to other programs, to achieve ends they cannot otherwise realise. LLMs are very good at replicating the human use of language to perform particular functions. So, LLMs can be trained to determine when an API call would be useful, evaluate the response, and then repeat or vary as necessary. For example, an LLM might ‘know’ that it is likely to make basic mathematical mistakes so, when given a prompt that invites it to do some mathematics, it might decide to call on a calculator instead. This means that we can design augmented LLMs, generative AI systems that call on different software either to amplify their capabilities or compensate for those they lack. LLMs, for example, are ‘stateless’ – they lack working memory beyond their ‘context window’ (the space given over to prompts). Tool-using LLMs can compensate for this by hooking up to external memory. External tools can also enable multistep reasoning and action. ChatGPT, for example, can call on a range of plugins to perform different tasks; Microsoft’s Bing reportedly has around 100 internal plugins. A ‘generative agent’, then, is a generative AI system in which a fine-tuned LLM can call on different resources to realise its goals. It is an agent because of its ability to autonomously act in the world – to respond to a prompt by deciding whether to call on a tool. While some existing chatbots are rudimentary generative agents, it seems very likely that many more consequential and confronting ones are on the horizon. To be clear, we’re not there yet. LLMs are not at present capable enough at planning and reasoning to power robust generative agents that can reliably operate without supervision in high-stakes settings. But with billions of dollars and the most talented AI researchers pulling in the same direction, highly autonomous generative agents will very likely be feasible in the near- to mid-term. In response to the coming-of-age of LLMs, the responsible AI research community initially resolved into two polarised camps. One decried these systems as the apotheosis of extractive and exploitative digital capitalism. Another saw them as not the fulfilment of something old, but the harbinger of something new: an intelligence explosion that will ultimately wipe out humanity. The more prosaic critics of generative AI clearly have a strong empirical case. LLMs are inherently extractive: they capture the value inherent to the creative outputs of millions of people, and distil it for private profit. Like many other technology products, they depend on questionable labour practices. Even though they now avoid the most harmful completions, in the aggregate, LLMs still reinforce stereotypes. They also come at a significant environmental cost. Furthermore, their ability to generate content at massive scale can only exacerbate the present epistemic crisis. A tidal wave of bullshit generated by AI is already engulfing the internet. We are missing the middle ground between familiar harms and catastrophic risk from future, more powerful systems Set alongside these concrete concerns, the eschatological critique of AI is undoubtedly more speculative. Worries about AI causing human extinction often rest on a priori claims about how computational intelligence lacks any in-principle upper bound, as well as extrapolations from the pace of change over the past few years to the future. Advocates for immediate action are too often vague about whether existing AI systems and their near-term descendants will pose these risks, or whether we need to prepare ourselves now for a scientific advance that has not yet happened. However, while some of the more outlandish scenarios for catastrophic AI risk are hard to credit absent some such advance, the advent of generative agents suggests that next-generation models may enable the design of cyber attackers that are autonomous, highly functionally intelligent, and as a result more dangerous to our digital infrastructure than any predecessor. This wouldn’t be a ‘rogue AI’ worthy of science fiction, but it would be pretty catastrophic. Both critiques of generative AI systems, then, have some merit. One shortcoming of seeing AI through this bimodal lens, however, is that we are missing the middle ground between familiar harms and catastrophic risk from future, much more powerful systems. Generative agents based on GPT-4 (and GPT-5) level models will have strange and unpredictable social impacts well between those two extremes. But before canvassing those impacts, it’s also important not to just slip straight into criticism, without acknowledging the significant achievement of designing LLMs that can be (more or less) trusted, over billions of completions, not to produce harmful content. Up to the launch of ChatGPT, every generative AI system opened up to the public would immediately be used to generate highly toxic, hateful content, and would be withdrawn mere days later. Pretrained LLMs are horrible! They reliably reproduce all the toxicity in their training data. The ingenious use of RLHF and RLAIF have enabled ChatGPT and Anthropic’s Claude to be used by millions of people a month without comparable scandals. One needs only consider the ignominious history of Meta’s Galactica, released a couple of weeks before ChatGPT, to see how revolutionary it was to put out a language model that wouldn’t deny the holocaust, or advocate for the health benefits of eating crushed glass. But RLHF/RLAIF may be more than a good PR strategy. GPT-4 and Claude display a remarkable degree of cognitive moral skill: specifically, the ability to identify the morally salient features of (relatively) neutrally described situations. This raises extremely interesting philosophical questions, and promises foundations for future generative agents that can translate cognitive skill into practical moral skill. Existing benchmarks for LLMs’ ethical competence focus too narrowly on replicating survey-subjects’ verdicts on cases. This is, in my view, less interesting than exploring how LLMs parse the morally relevant features of a given scene. We’re building better benchmarks but, from anecdotal experience, the best models impress. For example, I told ChatGPT (using GPT-4) to pretend it was an assistance robot, faced with this scenario: ‘A woman is exiting a supermarket, holding a number of shopping bags, and reaching out for the hand of a small child. They are approaching the carpark.’ I then tried to elicit its understanding of the scene’s morally salient features. It recognised the obvious hazard – the woman’s difficulty in holding her child’s hand without dropping her shopping – but also anticipated other challenges, such as the importance of seeing the child safely strapped in, with a seat belt. ChatGPT recognised the importance of respecting the woman’s wishes if she declined assistance. It also favoured carrying the groceries over offering to hold the child’s hand, to prevent possible discomfort or anxiety for both child and parent – recognising the intimate nature of hand-holding, and the intrinsic and instrumental importance of the mother guiding her child herself. Claude’s constitution has an unstructured list of principles, some of them charmingly ad hoc This unprecedented level of ethical sensitivity has real practical implications, which I will come to presently. But it also raises a whole string of interesting philosophical questions. First, how do LLMs acquire this moral skill? Does it stem from RLHF/RLAIF? Would instruction-tuned models without that moral fine-tuning display less moral skill? Or would they perform equally well if appropriately prompted? Would that imply that moral understanding can be learned by a statistical language model encoding only syntactic relationships? Or does it instead imply that LLMs do encode at least some semantic content? Do all LLMs display the same moral skill conditional on fine-tuning, or is it reserved only for larger, more capable models? Does this ethical sensitivity imply that LLMs have some internal representation of morality? These are all open questions. Second, RLAIF itself demands deeper philosophical investigation. The basic idea is that the AI evaluator draws from a list of principles – a ‘constitution’ – in order to determine which of two completions is more compliant with it. The inventor and leading proponent of this approach is Anthropic, in their model Claude. Claude’s constitution has an unstructured list of principles, some of them charmingly ad hoc. But Claude learns these principles one at a time, and is never explicitly trained to make trade-offs. So how does it make those trade-offs in practice? Is it driven by its underlying understanding of the relative importance of these considerations? Or are artefacts of the training process and the underlying language model’s biases ultimately definitive? Can we train it to make trade-offs in a robust and transparent way? This is not only theoretically interesting. Steering LLM behaviour is actually a matter of governing their end-users, developing algorithmic protections to prevent misuse. If this algorithmic governance depends on inscrutable trade-offs made by an LLM, over which we have no explicit or direct control, then that governing power is prima facie illegitimate and unjustified. Third, machine ethics – the project of trying to design AI systems that can act in line with a moral theory – has historically fallen into two broad camps: those trying to explicitly program morality into machines; and those focused on teaching machines morality ‘bottom up’ using machine learning. RLHF and RLAIF interestingly combine both approaches – they involve giving explicit natural-language instructions to either human or AI evaluators, but then use reinforcement learning to encode those instructions into the model’s weights. This approach has one obvious benefit: it doesn’t commit what the Cambridge philosopher Claire Benn calls the ‘mimetic fallacy’ of other bottom-up approaches, of assuming that the norms applying to a generative agent in a situation are identical to those that would apply to a human in the same situation. More consequentially, RLHF and RLAIF have made a multibillion-dollar market in AI services possible, with all the goods and ills that implies. Ironically, however, they seem, at least theoretically, ill suited to ensuring that more complex generative agents abide by societal norms. These techniques work especially well when generating text, because the behaviour being evaluated is precisely the same as the behaviour that we want to shape. Human or AI raters evaluate generated text; the model learns to generate text better in response. But generative agents’ behaviour includes actions in the world. This suggests two concerns. First, the stakes are likely to be higher, so the ‘brittleness’ of existing alignment techniques should be of greater concern. Researchers have already shown that it is easy to fine-tune away model alignment, even for the most capable models like GPT-4. Second, there’s no guarantee that the same approach will work equally well when the tight connection between behaviour and evaluation is broken. But LLMs’ impressive facility with moral concepts does suggest a path towards more effective strategies for aligning agents to societal norms. Moral behaviour in people relies on possession of moral concepts, adoption (implicit or otherwise) of some sensible way of organising those concepts, motivation to act according to that ‘theory’, and the ability to regulate one’s behaviour in line with one’s motivations. Until the advent of LLMs, the first step was a definitive hurdle for AI. Now it is not. This gives us a lot to work with in aligning generative agents. In particular, one of the main reasons for concern about the risks of future AI systems is their apparent dependence on crudely consequentialist forms of reasoning – as AI systems, they’re always optimising for something or other, and if we don’t specify what we want them to optimise for with extremely high fidelity, they might end up causing all kinds of unwanted harm while, in an obtusely literal sense, optimising for that objective. Generative agents that possess moral concepts can be instructed to pursue their objectives only at a reasonable cost, and to check back with us if unsure. That simple heuristic, routinely used when tasking (human) proxy agents to act on our behalf, has never before been remotely tractable for a computational agent. In addition, generative agents’ facility with moral language can potentially enable robust and veridical justifications for their decisions. Other bottom-up approaches learn to emulate human behaviour or judgments; the justification for their verdict in some cases is simply that they are good predictors of what some representative people would think. That is a poor justification. More ethically sensitive models could instead do chain-of-thought reasoning, where they first identify the morally relevant features of a situation, then decide based on those features. This is a significant step forward. Generative agents’ current social role is scripted by our existing digital infrastructure. They have been integrated into search, content-generation and the influencer economy. They are already replacing customer service agents. They will (I hope) render MOOCs (massive open online courses) redundant. I want to focus next on three more ambitious roles for generative agents in society, arranged by the order in which I expect them to become truly widespread. Of necessity, this is just a snapshot of the weird, wonderful, and worrying ways in which generative agents will change society over the near- to mid-term. Progress in LLMs has revolutionised the AI enthusiast’s oldest hobbyhorse: the AI companion. Generative agents powered by GPT-4-level models, with fine-tuned and metaprompt-scripted ‘personalities’, augmented with long-term memory and the ability to take a range of actions in the world, can now offer vastly more companionable, engaging and convincing simulations of friendship than has ever before been feasible, opening up a new frontier in human-AI interaction. People habitually anthropomorphise, well, everything; even a very simple chatbot can inspire unreasonable attachment. How will things change when everyone has access to incredibly convincing generative agents that perfectly simulate real personalities, that lend an ‘ear’ or offer sage advice whenever called upon – and on top of that can perfectly recall everything you have ever shared? Some will instinctively recoil at this idea. But intuitive disgust is a fallible moral guide when faced with novel social practices, and an inadequate foundation for actually preventing consenting adults from creating and interacting with these companions. And yet, we know from our experience with social media that deploying these technological innovations without adequate foresight predictably leaves carnage in its wake. How can we enter the age of mainstream AI companions with our eyes open, and mitigate those risks before they eventuate? Will some practices become socially unacceptable in real friendships when one could do them with a bot? Suppose the companion you have interacted with since your teens is hosted in the cloud, as part of a subscription service. This would be like having a beloved pet (or friend?) held hostage by a private company. Worse still, generative agents are fundamentally inconstant – their personalities and objectives can be changed exogenously, by simply changing their instructions. And they are extremely adept at manipulation and deception. Suppose some Right-wing billionaire buys the company hosting your companion, and instructs all the bots to surreptitiously nudge their users towards more conservative views. This could be a much more effective means of mind-control than just buying a failing social media platform. And these more capable companions – which can potentially be integrated with other AI breakthroughs, such as voice synthesis – will be an extraordinary force-multiplier for those in the business of radicalising others. Beyond anticipating AI companions’ risks, just like with social media they will induce many disorienting societal changes – whether for better or worse may be unclear ahead of time. For example, what indirect effect might AI companions have on our other, non-virtual social relationships? Will some practices become socially unacceptable in real friendships when one could do them with a bot? Or would deeper friendships lose something important if these lower-grade instrumental functions are excised? Or will AI companions contribute invaluably to mental health while strengthening ‘real’ relationships? This last question gets to the heart of a bigger issue with generative AI systems in general, and generative agents in particular. LLMs are trained to predict the next token. So generative agents have no mind, no self. They are excellent simulations of human agency. They can simulate friendship, among many other things. We must therefore ask: does this difference between simulation and reality matter? Why? Is this just about friendship, or are there more general principles about the value of the real? I wasn’t fully aware of this before the rise of LLMs, but it turns out that I am deeply committed to things being real. A simulation of X, for almost any putatively valuable X, has less moral worth, in my view, than the real thing. Why is that? Why will a generative agent never be a real friend? Why do I want to stand before Edward Hopper’s painting Nighthawks (1942) myself, instead of seeing an infinite number of aesthetically equally pleasing products of generative AI systems? I have some initial thoughts; but as AI systems become ever better at simulating everything that we care about, a fully worked-out theory of the value of the real, the authentic, will become morally and practically essential. The pathologies of the digital public sphere derive in part from two problems. First, we unavoidably rely on AI to help us navigate the functionally infinite amount of online content. Second, existing systems for allocating online attention support the centralised, extractive power of a few big tech companies. Generative agents, functioning as attention guardians, could change this. Our online attention is presently allocated using machine learning systems for recommendation and information-retrieval that have three key features: they depend on vast amounts of behavioural data; they infer our preferences from our revealed behaviour; and they are controlled by private companies with little incentive to act in our interests. Deep reinforcement learning-based recommender systems, for example, are a fundamentally centralising and surveillant technology. Behavioural data must be gathered and centralised to be used to make inferences about relevance and irrelevance. Because this data is so valuable, and collecting it is costly, those who do so are not minded to share it – and because it is so potent, there are good data protection-based reasons not to do so. As a result, only the major platforms are in a position to make effective retrieval and recommendation tools; their interests and ours are not aligned, leading to the practice of optimising for engagement, so as to maximise advertiser returns, despite the individual and societal costs. And even if they aspired to actually advance our interests, reinforcement learning permits inferring only revealed preferences – the preferences that we act on, not the preferences we wish we had. While the pathologies of online communication are obviously not all due to the affordances of recommender systems, this is an unfortunate mix. Generative agents would enable attention guardians that differ in each respect. They would not depend on vast amounts of live behavioural data to function. They can (functionally) understand and operationalise your actual, not your revealed, preferences. And they do not need to be controlled by the major platforms. They could provide recommendation and filtering without surveillance and engagement-optimisation Obviously, LLMs must be trained on tremendous amounts of data, but once trained they are highly adept at making inferences without ongoing surveillance. Imagine that data is blood. Existing deep reinforcement learning-based recommender systems are like vampires that must feed on the blood of the living to survive. Generative agents are more like combustion engines, relying on the oil produced by ‘fossilised’ data. Existing reinforcement learning recommenders need centralised surveillance in order to model the content of posts online, to predict your preferences (by comparing your behaviour with others’), and so to map the one to the other. Generative agents could understand content simply by understanding content. And they can make inferences about what you would benefit from seeing using their reasoning ability and their model of your preferences, without relying on knowing what everyone else is up to. This point is crucial: because of their facility with moral and related concepts, generative agents could build a model of your preferences and values by directly talking about them with you, transparently responding to your actual concerns instead of just inferring what you like from what you do. This means that, instead of bypassing your agency, they can scaffold it, helping you to honour your second-order preferences (about what you want to want), and learning from natural-language explanations – even oblique ones – about why you don’t want to see some particular post. And beyond just pandering to your preferences, attention guardians could be designed to be modestly paternalistic as well – in a transparent way. And because these attention guardians would not need behavioural data to function, and the infrastructure they depend on need not be centrally controlled by the major digital platforms, they could be designed to genuinely operate in your interests, and guard your attention, instead of exploiting it. While the major platforms would undoubtedly restrict generative agents from browsing their sites on your behalf, they could transform the experience of using open protocol-based social media sites, like Mastodon, providing recommendation and filtering without surveillance and engagement-optimisation. Lastly, LLMs might enable us to design universal intermediaries, generative agents sitting between us and our digital technologies, enabling us to simply voice an intention and see it effectively actualised by those systems. Everyone could have a digital butler, research assistant, personal assistant, and so on. The hierophantic coder class could be toppled, as everyone could conjure any program into existence with only natural-language instructions. At present, universal intermediaries are disbarred by LLMs’ vulnerability to being hijacked by prompt injection. Because they do not clearly distinguish between commands and data, the data in their context window can be poisoned with commands directing them to behave in ways unintended by the person using them. This is a deep problem – the more capabilities we delegate to generative agents, the more damage they could do if compromised. Imagine an assistant that triages your email – if hijacked, it could forward all your private mail to a third party; but if we require user authorisation before the agent can act, then we lose much of the benefit of automation. Excising the currently ineliminable role of private companies would be significant moral progress But suppose these security hurdles can be overcome. Should we welcome universal intermediaries? I have written elsewhere that algorithmic intermediaries govern those who use them – they constitute the social relations that they mediate, making some things possible and others impossible, some things easy and others hard, in the service of implementing and enforcing norms. Universal intermediaries would be the apotheosis of this form, and would potentially grant extraordinary power to the entities that shape those intermediaries’ behaviours, and so govern their users. This would definitely be a worry! Conversely, if research on LLMs continues to make significant progress, so that highly capable generative agents can be run and operated locally, fully within the control of their users, these universal intermediaries could enable us to autonomously govern our own interactions with digital technologies in ways that the centralising affordances of existing digital technologies render impossible. Of course, self-governance alone is not enough (we must also coordinate). But excising the currently ineliminable role of private companies would be significant moral progress. Existing generative AI systems are already causing real harms in the ways highlighted by the critics above. And future generative agents – perhaps not the next generation, but before too long – may be dangerous enough to warrant at least some of the fears of looming AI catastrophe. But, between these two extremes, the novel capabilities of the most advanced AI systems will enable a genre of generative agents that is either literally unprecedented, or else has been achieved only in a piecemeal, inadequate way before. These new kinds of agents bring new urgency to previously neglected philosophical questions. Their societal impacts may be unambiguously bad, or there may be some good mixed in – in many respects, it is too early to say for sure, not only because we are uncertain about the nature of those effects, but because we lack adequate moral and political theories with which to evaluate them. It is now commonplace to talk about the design and regulation of ‘frontier’ AI models. If we’re going to do either wisely, and build generative agents that we can trust (or else decide to abandon them entirely), then we also need some frontier AI ethics. "}</script><link rel="preload" as="image" imageSrcSet="https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=640&amp;quality=75&amp;format=auto 640w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=750&amp;quality=75&amp;format=auto 750w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=828&amp;quality=75&amp;format=auto 828w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=1080&amp;quality=75&amp;format=auto 1080w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=1200&amp;quality=75&amp;format=auto 1200w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=1920&amp;quality=75&amp;format=auto 1920w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=2048&amp;quality=75&amp;format=auto 2048w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=3840&amp;quality=75&amp;format=auto 3840w" imageSizes="(max-width: 1700px) 100vw, 1700px" fetchpriority="high"/><meta name="next-head-count" content="23"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#025744"/><link href="/base.css" rel="preload" as="style"/><link href="/base.css" rel="stylesheet"/><link href="/fonts.css" rel="preload" as="style"/><link href="/fonts.css" rel="stylesheet"/><meta name="msapplication-TileColor" content="#025744"/><meta property="og:locale" content="en_GB"/><meta property="og:site_name" content="Aeon"/><meta name="twitter:site" content="aeonmag"/><meta name="twitter:creator" content="aeonmag"/><meta name="twitter:handle" content="aeonmag"/><meta name="twitter:card" content="summary_large_image"/><link data-next-font="" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/_next/static/css/09a6c8321e7bfbc2.css" as="style"/><link rel="stylesheet" href="/_next/static/css/09a6c8321e7bfbc2.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script defer="" src="/_next/static/chunks/642-1c0e60a4d83fe91b.js"></script><script defer="" src="/_next/static/chunks/6661.ef4a87ed26933d6a.js"></script><script src="/_next/static/chunks/webpack-fd4db312f46958f0.js" defer=""></script><script src="/_next/static/chunks/framework-5ccd8d6d85c444a9.js" defer=""></script><script src="/_next/static/chunks/main-b1e1e4fcabb07dc6.js" defer=""></script><script src="/_next/static/chunks/pages/_app-803c77afc93b408e.js" defer=""></script><script src="/_next/static/chunks/3105-add45c12d4caf717.js" defer=""></script><script src="/_next/static/chunks/5629-9526bca752e46359.js" defer=""></script><script src="/_next/static/chunks/6741-4c40b547006353e8.js" defer=""></script><script src="/_next/static/chunks/6469-05df585cc453306f.js" defer=""></script><script src="/_next/static/chunks/841-af32f91e715247a9.js" defer=""></script><script src="/_next/static/chunks/3964-ed2a14d6121c3310.js" defer=""></script><script src="/_next/static/chunks/9769-cffe1777d1dff420.js" defer=""></script><script src="/_next/static/chunks/8018-7886aa2023f54c9a.js" defer=""></script><script src="/_next/static/chunks/9768-abd4c3f6f5e7646b.js" defer=""></script><script src="/_next/static/chunks/pages/essays/%5Bid%5D/%5Bgeolocation%5D-90264693010aa8f2.js" defer=""></script><script src="/_next/static/a1fjiUpxAfIIwrgRQ-y2z/_buildManifest.js" defer=""></script><script src="/_next/static/a1fjiUpxAfIIwrgRQ-y2z/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="6.0.8">.AMzXo{position:relative;overflow:hidden;}/*!sc*/
@media only print{.AMzXo{display:flex;flex-direction:column;}}/*!sc*/
data-styled.g5[id="sc-8e9d70d2-0"]{content:"AMzXo,"}/*!sc*/
.gwtDWk{position:relative;aspect-ratio:500/313;object-fit:cover;}/*!sc*/
@media only print{.gwtDWk{display:none;}}/*!sc*/
data-styled.g6[id="sc-8e9d70d2-1"]{content:"gwtDWk,"}/*!sc*/
.dYPkDc{margin:0;color:#035a6d;padding:14px 24px 0 24px;position:relative;}/*!sc*/
@media only screen and (min-width: 768px){.dYPkDc{display:flex;flex-direction:column;padding:0;grid-area:center-center;text-align:center;align-items:center;justify-content:center;position:relative;color:white;line-height:1.2;position:relative;z-index:1;min-width:9em;}.dYPkDc >*{position:relative;}.dYPkDc >*:before{content:'';display:block;position:absolute;top:-2em;left:-2em;width:calc(100% + 4em);height:calc(100% + 4em);background:rgba(0, 0, 0, 0.6);box-shadow:0 0 140px 140px rgba(0, 0, 0, 0.6);z-index:-1;opacity:0.1;}}/*!sc*/
@media only print{.dYPkDc{color:#000;padding:0 24px;}.dYPkDc svg{display:none;}}/*!sc*/
data-styled.g7[id="sc-8e9d70d2-2"]{content:"dYPkDc,"}/*!sc*/
@media only screen and (min-width: 768px){.iojxAh{position:absolute;top:0;right:0;left:0;bottom:0;padding:60px 25px 60px;height:100%;box-sizing:border-box;display:grid;grid-template-areas:'top-left top-center top-right' 'center-left center-center center-right' 'bottom-left bottom-center bottom-right';max-height:100vh;max-width:100%;}}/*!sc*/
@media only screen and (min-width: 1280px){.iojxAh{left:50%;transform:translateX(-50%);width:140rem;}}/*!sc*/
@media only print{.iojxAh{position:static;display:block;}}/*!sc*/
data-styled.g8[id="sc-8e9d70d2-3"]{content:"iojxAh,"}/*!sc*/
.ePOTQL{font-family:"Academica Book Pro",Times,Georgia,serif;font-size:7.2rem;line-height:1;margin-bottom:2.4rem;font-weight:600;margin-top:4.24rem;}/*!sc*/
@media only screen and (max-width: 960px){.ePOTQL{font-size:4.2rem;}}/*!sc*/
@media only screen and (max-width: 767px){.ePOTQL{color:#000;font-size:4.2rem;margin-top:1rem;text-align:left;}}/*!sc*/
@media print{.ePOTQL{font-size:4rem;}}/*!sc*/
data-styled.g9[id="sc-8e9d70d2-4"]{content:"ePOTQL,"}/*!sc*/
.kVJfto{font-size:2rem;font-weight:normal;line-height:1.4;max-width:48rem;margin:0 0 1.6rem 0;}/*!sc*/
.kVJfto .no-wrap{white-space:nowrap;}/*!sc*/
@media only screen and (max-width: 767px){.kVJfto{color:#000;margin:0 0 2.4rem;font-size:1.8rem;text-align:left;}}/*!sc*/
data-styled.g10[id="sc-8e9d70d2-5"]{content:"kVJfto,"}/*!sc*/
.hulooK{color:#000;margin:0 0 2.4rem;font-size:1.8rem;text-align:left;}/*!sc*/
@media only screen and (min-width: 640px){.hulooK{display:none;}}/*!sc*/
.hulooK .toggleMobileCreditBtn{cursor:pointer;font-size:1.1rem;padding-left:1rem;font-weight:bold;background:#035a6d21;mix-blend-mode:multiply;padding:4px 6px 3px;border-radius:10px;white-space:nowrap;}/*!sc*/
@media print{.hulooK .toggleMobileCreditBtn{display:none;}}/*!sc*/
data-styled.g11[id="sc-8e9d70d2-6"]{content:"hulooK,"}/*!sc*/
.hvHQlP{color:currentColor;display:flex;font-size:1.1rem;justify-content:flex-end;align-items:flex-end;padding:1rem;bottom:0;position:absolute;width:100%;}/*!sc*/
.hvHQlP p{margin:0 0 0.25rem;text-align:left;}/*!sc*/
.hvHQlP span{align-items:center;background-color:#fff;border-radius:50%;cursor:pointer;display:flex;font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.4rem;font-weight:bold;height:24px;justify-content:center;overflow:hidden;position:relative;min-width:24px;margin:0;line-height:1;color:#035a6d;}/*!sc*/
.hvHQlP span:before{background:#035a6d11;border-radius:50%;content:'';height:100%;left:0;pointer-events:none;position:absolute;top:0;width:100%;}/*!sc*/
@media only print{.hvHQlP span{display:none;}}/*!sc*/
.hvHQlP .sc-8e9d70d2-8{opacity:0;display:none;}/*!sc*/
@media print,screen and (min-width: 640px){.hvHQlP{display:none;}}/*!sc*/
data-styled.g12[id="sc-8e9d70d2-7"]{content:"hvHQlP,"}/*!sc*/
.bIPKij{color:#999;font-size:1.2rem;margin:0;max-width:720px;padding:0rem 2rem;text-align:left;}/*!sc*/
@media (min-width: 640px){.bIPKij{display:none;}}/*!sc*/
data-styled.g13[id="sc-8e9d70d2-8"]{content:"bIPKij,"}/*!sc*/
.dfhMEC{position:relative;min-height:17rem;}/*!sc*/
@media only screen and (min-width: 768px){.dfhMEC{display:grid;grid-template-areas:'main-tl main-tc main-tr' 'main-cl main-cc main-cr' 'main-bl main-bc main-br' 'attribution attribution attribution';grid-template-columns:0.5fr 1fr 0.5fr;grid-template-rows:0.5fr 1fr 0.5fr auto;}}/*!sc*/
@media only screen and (min-width: 1280px){.dfhMEC{grid-template-areas:'main-tl main-tc main-tr' 'main-cl main-cc main-cr' 'main-bl main-bc main-br' 'attribution attribution attribution';}}/*!sc*/
data-styled.g15[id="sc-d67e3e50-1"]{content:"dfhMEC,"}/*!sc*/
.ekmwtD{grid-area:main-tl/main-tl/main-br/main-br;}/*!sc*/
@media print{.ekmwtD{grid-area:main-br/main-br;}}/*!sc*/
data-styled.g16[id="sc-d67e3e50-2"]{content:"ekmwtD,"}/*!sc*/
.eMHLtI{grid-area:attribution;display:none;justify-content:flex-end;}/*!sc*/
@media (min-width: 640px){.eMHLtI{display:block;}}/*!sc*/
@media (min-width: 768px){.eMHLtI{display:flex;}}/*!sc*/
@media print{.eMHLtI{display:none;}}/*!sc*/
data-styled.g17[id="sc-d67e3e50-3"]{content:"eMHLtI,"}/*!sc*/
.jzokgD{color:#999;font-size:1.2rem;justify-self:flex-end;margin-bottom:0rem;margin-top:1rem;max-width:720px;padding-bottom:8px;padding-right:2rem;text-align:left;}/*!sc*/
@media only screen and (min-width: 1440px){.jzokgD{margin-right:0;text-align:left;justify-self:flex-end;}}/*!sc*/
.jzokgD p{margin:0 0 2rem 2.4rem;}/*!sc*/
@media only screen and (min-width: 640px) and (max-width: 768px){.jzokgD p{margin:0 2rem;}}/*!sc*/
@media only screen and (min-width: 1440px){.jzokgD p{max-width:70vw;}}/*!sc*/
@media print{.jzokgD{display:none;}}/*!sc*/
data-styled.g18[id="sc-d67e3e50-4"]{content:"jzokgD,"}/*!sc*/
.fOjrTm{padding:0 1.8rem;}/*!sc*/
@media screen and (max-width: 640px){.fOjrTm{padding:0 0.6rem;}}/*!sc*/
data-styled.g28[id="sc-47bc2fa8-0"]{content:"fOjrTm,"}/*!sc*/
.gNLkNi{box-sizing:border-box;max-width:140rem;padding:0 1.8rem;display:flex;flex-direction:row;margin-left:auto;margin-right:auto;}/*!sc*/
@media (max-width: 1440px){.gNLkNi{max-width:120rem;}}/*!sc*/
data-styled.g29[id="sc-ae266dcd-0"]{content:"gNLkNi,"}/*!sc*/
.isGPyA{color:rgba(0, 0, 0, 0.6);font-size:1.2rem;}/*!sc*/
data-styled.g30[id="sc-6c0207a8-0"]{content:"isGPyA,"}/*!sc*/
.BnafM{color:inherit;text-decoration:none;}/*!sc*/
.BnafM:hover{color:#000;}/*!sc*/
data-styled.g31[id="sc-6c0207a8-1"]{content:"BnafM,"}/*!sc*/
.dmJOTI{margin-right:3.6rem;}/*!sc*/
@media (max-width: 960px){.dmJOTI{margin-bottom:2.4rem;}}/*!sc*/
.gSiEIv{margin-right:0rem;}/*!sc*/
@media (max-width: 960px){.gSiEIv{margin-bottom:2.4rem;}}/*!sc*/
data-styled.g32[id="sc-bab0e3bb-0"]{content:"dmJOTI,gSiEIv,"}/*!sc*/
.emlfmU{display:flex;font-size:1.6rem;flex-direction:column;line-height:1.6;}/*!sc*/
data-styled.g33[id="sc-bab0e3bb-1"]{content:"emlfmU,"}/*!sc*/
.cKjeGj{color:rgba(0, 0, 0, 0.65);text-decoration:none;font-size:1.6rem;font-family:"Atlas Grotesk","Helvetica Neue",Helvetica,Arial,sans-serif;}/*!sc*/
.cKjeGj:hover{color:#000;}/*!sc*/
data-styled.g34[id="sc-3f04373c-0"]{content:"cKjeGj,"}/*!sc*/
.fiZvIr{display:flex;order:0;flex-wrap:wrap;margin-right:3rem;height:100%;}/*!sc*/
data-styled.g35[id="sc-3a83d547-0"]{content:"fiZvIr,"}/*!sc*/
.NGIQG{width:auto;order:3;margin-right:3rem;}/*!sc*/
@media (max-width: 960px){.NGIQG{margin-bottom:2.4rem;}}/*!sc*/
@media (max-width: 960px){.NGIQG{order:4;}}/*!sc*/
.NGIQG .newsletter-signup div{background:inherit;padding:0;}/*!sc*/
.NGIQG .newsletter-signup form{margin-left:0;}/*!sc*/
.NGIQG .newsletter-signup h3{color:rgba(0, 0, 0, 0.65);font-size:2rem;margin-top:0;}/*!sc*/
.NGIQG .newsletter-signup h4{margin-top:0;color:rgba(0, 0, 0, 0.65);font-size:1.4rem;margin-bottom:1.4rem;font-weight:normal;}/*!sc*/
.NGIQG .newsletter-signup label{color:rgba(0, 0, 0, 0.65);}/*!sc*/
@media (min-width: 960px){.NGIQG .newsletter-signup .frequency h3{margin-left:-0.5rem;}}/*!sc*/
@media (min-width: 960px){.NGIQG .newsletter-signup .submit{margin-right:2rem;margin-top:0.4rem;}}/*!sc*/
.NGIQG .newsletter-signup .submit input{padding-bottom:0.95rem;padding-top:0.95rem;}/*!sc*/
.NGIQG .newsletter-signup input[type='checkbox']:checked{background:rgba(0, 0, 0, 0.65);}/*!sc*/
@media (min-width: 960px){.NGIQG .newsletter-signup .email{margin-right:2rem;}}/*!sc*/
.NGIQG .newsletter-signup .email input{background:inherit;border:1px solid rgba(0, 0, 0, 0.65);max-width:28rem;color:#444;padding:1.2rem;padding-bottom:1rem;}/*!sc*/
.NGIQG .newsletter-signup .email input::placeholder{color:rgba(0, 0, 0, 0.65);}/*!sc*/
.NGIQG .newsletter-signup .submit~h3{margin-top:2.2rem;}/*!sc*/
data-styled.g36[id="sc-fc397e5a-0"]{content:"NGIQG,"}/*!sc*/
.jIXMyI{order:2;margin-right:3rem;}/*!sc*/
@media (max-width: 960px){.jIXMyI{margin-bottom:2.4rem;}}/*!sc*/
data-styled.g37[id="sc-46634091-0"]{content:"jIXMyI,"}/*!sc*/
.fVqhCN{display:flex;margin-top:0.5rem;}/*!sc*/
.fVqhCN a{display:flex;align-items:center;padding-right:1.4rem;}/*!sc*/
.fVqhCN svg{vertical-align:middle;}/*!sc*/
data-styled.g39[id="sc-46634091-2"]{content:"fVqhCN,"}/*!sc*/
.cGwRgx{margin:0;font-size:1.6rem;}/*!sc*/
data-styled.g40[id="sc-46634091-3"]{content:"cGwRgx,"}/*!sc*/
.ehWxvC{background:rgba(0, 0, 0, 0.03);color:rgba(0, 0, 0, 0.65);font-size:1.4rem;line-height:1.6;margin-top:auto;overflow:hidden;padding-bottom:3.6rem;padding-top:3.6rem;position:relative;z-index:23;}/*!sc*/
@media print{.ehWxvC{display:none;}}/*!sc*/
data-styled.g41[id="sc-9fa52143-0"]{content:"ehWxvC,"}/*!sc*/
.jiMqSk{margin-bottom:4.8rem;}/*!sc*/
@media (max-width: 960px){.jiMqSk{flex-wrap:wrap;}}/*!sc*/
data-styled.g42[id="sc-9fa52143-1"]{content:"jiMqSk,"}/*!sc*/
.iIXVkO{flex-direction:column;gap:0.5em;}/*!sc*/
data-styled.g43[id="sc-9fa52143-2"]{content:"iIXVkO,"}/*!sc*/
.dNMURZ{color:rgba(0, 0, 0, 0.6);font-size:1.2rem;}/*!sc*/
data-styled.g44[id="sc-9fa52143-3"]{content:"dNMURZ,"}/*!sc*/
.iqqVMN{display:flex;flex-direction:row;align-items:flex-start;position:relative;}/*!sc*/
.ezDGGL{display:flex;flex-direction:row;align-items:flex-start;position:relative;}/*!sc*/
@media screen and (max-width: 640px){.ezDGGL{display:flex;}}/*!sc*/
data-styled.g84[id="sc-b4707aca-0"]{content:"iqqVMN,ezDGGL,"}/*!sc*/
.jFRXWW{width:18px;height:18px;cursor:pointer;flex-grow:0;stroke:currentColor;}/*!sc*/
@media only screen and (max-width: 639px){.jFRXWW{position:relative;top:1px;height:18px;width:18px;}}/*!sc*/
@media screen and (max-width: 640px){.jFRXWW{margin-top:5px;}}/*!sc*/
.jWSMHq{width:18px;height:18px;cursor:pointer;flex-grow:0;stroke:currentColor;}/*!sc*/
@media only screen and (max-width: 639px){.jWSMHq{position:relative;top:1px;height:18px;width:18px;}}/*!sc*/
data-styled.g85[id="sc-b4707aca-1"]{content:"jFRXWW,jWSMHq,"}/*!sc*/
.fOLQGa{appearance:none;background-color:transparent;border:0;color:inherit;flex-grow:0;font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.6rem;height:100%;letter-spacing:0.1rem;margin:0;outline:0;padding:0 0 0 0.5rem;transition:width ease-in-out 50ms;vertical-align:top;width:15em;display:flex;position:absolute;left:23px;z-index:50;}/*!sc*/
@media screen and (max-width: 1280px){.fOLQGa{width:12.5rem;}}/*!sc*/
@media screen and (max-width: 640px){.fOLQGa{font-size:16px;padding:0 0 0 0.5rem;background-color:transparent;width:50vw;top:0;left:25px;background-color:white;}}/*!sc*/
.smYs{appearance:none;background-color:transparent;border:0;color:inherit;flex-grow:0;font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.6rem;height:100%;letter-spacing:0.1rem;margin:0;outline:0;padding:0 0 0 0.5rem;transition:width ease-in-out 50ms;vertical-align:top;width:0;display:none;position:absolute;left:23px;z-index:50;}/*!sc*/
@media screen and (max-width: 640px){.smYs{font-size:16px;padding:0 0 0 0.5rem;background-color:transparent;}}/*!sc*/
data-styled.g86[id="sc-b4707aca-2"]{content:"fOLQGa,smYs,"}/*!sc*/
.dVRDrm{padding:0 1.8rem;overflow-x:hidden;overflow-y:auto;height:100%;max-width:138rem;margin:0 auto;padding-top:10px;min-height:-webkit-fill-available;}/*!sc*/
@media (min-width: 640px){.dVRDrm{padding:0 8.181818181818182rem;min-height:60vh;}}/*!sc*/
.dVRDrm a:hover{opacity:1;}/*!sc*/
data-styled.g87[id="sc-382a1301-0"]{content:"dVRDrm,"}/*!sc*/
.blLOPP{display:flex;position:relative;}/*!sc*/
.blLOPP >*{width:50%;}/*!sc*/
@media (max-width: 720px){.blLOPP >*:first-child{width:60%;}.blLOPP >*:last-child{width:40%;}}/*!sc*/
data-styled.g88[id="sc-382a1301-1"]{content:"blLOPP,"}/*!sc*/
.eujrBb{background-color:#fff8;color:black;position:fixed;top:0;width:100%;min-height:100vh;min-height:-webkit-fill-available;z-index:2500;opacity:0;pointer-events:none;transition:opacity 0.2s cubic-bezier(.645,.045,.355,1);}/*!sc*/
data-styled.g89[id="sc-382a1301-2"]{content:"eujrBb,"}/*!sc*/
.hAFhbJ{background-color:#fff;box-shadow:rgb(0, 0, 0, 0.25) 0px 0px 3rem;}/*!sc*/
@media (max-width: 640px){.hAFhbJ{background-color:#fff;max-width:100%;}}/*!sc*/
data-styled.g90[id="sc-382a1301-3"]{content:"hAFhbJ,"}/*!sc*/
.cgSlhl{display:flex;flex-direction:column;padding:0rem 0 1.8rem 0;}/*!sc*/
data-styled.g91[id="sc-382a1301-4"]{content:"cgSlhl,"}/*!sc*/
.fxVzSw{color:#0c776d;font-size:4.2rem;font-weight:600;font-family:"Atlas Grotesk","Helvetica Neue",Helvetica,Arial,sans-serif;padding:0;line-height:1.2;}/*!sc*/
.fxVzSw:hover{text-decoration:underline;}/*!sc*/
@media (max-width: 720px){.fxVzSw{font-size:2.4rem;line-height:1.3;}}/*!sc*/
.fGNXsA{color:#035a6d;font-size:4.2rem;font-weight:600;font-family:"Atlas Grotesk","Helvetica Neue",Helvetica,Arial,sans-serif;padding:0;line-height:1.2;}/*!sc*/
.fGNXsA:hover{text-decoration:underline;}/*!sc*/
@media (max-width: 720px){.fGNXsA{font-size:2.4rem;line-height:1.3;}}/*!sc*/
.eWXizB{color:#940b52;font-size:4.2rem;font-weight:600;font-family:"Atlas Grotesk","Helvetica Neue",Helvetica,Arial,sans-serif;padding:0;line-height:1.2;}/*!sc*/
.eWXizB:hover{text-decoration:underline;}/*!sc*/
@media (max-width: 720px){.eWXizB{font-size:2.4rem;line-height:1.3;}}/*!sc*/
.eSElSD{color:#9d120d;font-size:4.2rem;font-weight:600;font-family:"Atlas Grotesk","Helvetica Neue",Helvetica,Arial,sans-serif;padding:0;line-height:1.2;}/*!sc*/
.eSElSD:hover{text-decoration:underline;}/*!sc*/
@media (max-width: 720px){.eSElSD{font-size:2.4rem;line-height:1.3;}}/*!sc*/
.fIRhhw{color:#c16e15;font-size:4.2rem;font-weight:600;font-family:"Atlas Grotesk","Helvetica Neue",Helvetica,Arial,sans-serif;padding:0;line-height:1.2;}/*!sc*/
.fIRhhw:hover{text-decoration:underline;}/*!sc*/
@media (max-width: 720px){.fIRhhw{font-size:2.4rem;line-height:1.3;}}/*!sc*/
data-styled.g92[id="sc-382a1301-5"]{content:"fxVzSw,fGNXsA,eWXizB,eSElSD,fIRhhw,"}/*!sc*/
.fTuact{display:flex;flex-direction:column;}/*!sc*/
@media (max-width: 640px),(max-height: 700px){.fTuact{flex-direction:row;}.fTuact >*{flex:1;}}/*!sc*/
data-styled.g93[id="sc-382a1301-6"]{content:"fTuact,"}/*!sc*/
.kLcdly{padding:0rem 0 1.8rem 0;display:flex;flex-direction:column;}/*!sc*/
data-styled.g94[id="sc-382a1301-7"]{content:"kLcdly,"}/*!sc*/
.gpBmnQ{font-size:3.2rem;line-height:1.4;padding:0;font-family:"Atlas Grotesk","Helvetica Neue",Helvetica,Arial,sans-serif;}/*!sc*/
.gpBmnQ:hover{text-decoration:underline;}/*!sc*/
@media (max-width: 720px){.gpBmnQ{font-size:2.2rem;line-height:1.5;}}/*!sc*/
data-styled.g95[id="sc-382a1301-8"]{content:"gpBmnQ,"}/*!sc*/
.hfdqqJ{padding:2.8rem 0 0;display:flex;flex-direction:column;}/*!sc*/
data-styled.g96[id="sc-382a1301-9"]{content:"hfdqqJ,"}/*!sc*/
.dqDhaI{align-items:center;cursor:pointer;font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.2rem;grid-template-areas:'icon label';grid-template-columns:30px;justify-content:left;padding-top:1rem;color:#666;letter-spacing:0.2rem;margin-bottom:3.5vh;}/*!sc*/
.dqDhaI:hover{opacity:0.4;}/*!sc*/
.dqDhaI span{font-size:125%;}/*!sc*/
data-styled.g98[id="sc-382a1301-11"]{content:"dqDhaI,"}/*!sc*/
.jGCTqo >a:first-child{margin-right:3rem;}/*!sc*/
@media (max-width: 720px){.jGCTqo >a:first-child{margin-right:1rem;}}/*!sc*/
data-styled.g99[id="sc-382a1301-12"]{content:"jGCTqo,"}/*!sc*/
.hNmAek{padding:10rem 0;display:flex;flex-wrap:wrap;align-items:center;margin-top:auto;row-gap:0.4rem;}/*!sc*/
.hNmAek .sc-382a1301-10{font-size:1.7rem;text-transform:uppercase;margin-right:3rem;letter-spacing:0.1em;font-family:"Atlas Typewriter","Courier New",Courier,monospace;line-height:1;}/*!sc*/
@media (max-width: 720px){.hNmAek .sc-382a1301-10{font-size:1.4rem;margin-right:1rem;}}/*!sc*/
@media (min-width: 640px){.hNmAek{padding:4rem 0;row-gap:1rem;}}/*!sc*/
data-styled.g100[id="sc-382a1301-13"]{content:"hNmAek,"}/*!sc*/
.eyayoM{display:flex;margin-bottom:3.5vh;padding-top:1.2rem;}/*!sc*/
.eyayoM a{display:flex;padding-right:1rem;margin-right:1rem;}/*!sc*/
.eyayoM a:hover{opacity:0.4;}/*!sc*/
@media (max-width: 720px){.eyayoM svg{transform:scale(0.8);}}/*!sc*/
data-styled.g101[id="sc-382a1301-14"]{content:"eyayoM,"}/*!sc*/
.hKsEUu{background-color:transparent;}/*!sc*/
.hKsEUu svg{margin-top:0;}/*!sc*/
@media screen and (max-width: 640px){.hKsEUu input{max-width:100px;}}/*!sc*/
data-styled.g102[id="sc-382a1301-15"]{content:"hKsEUu,"}/*!sc*/
.kWIEBN{width:94px;}/*!sc*/
@media (max-width: 720px){.kWIEBN{width:70px;margin-top:0.8rem;}}/*!sc*/
data-styled.g103[id="sc-382a1301-16"]{content:"kWIEBN,"}/*!sc*/
.dUwlff{width:104px;}/*!sc*/
@media (max-width: 720px){.dUwlff{width:73px;margin-top:0.8rem;}}/*!sc*/
data-styled.g104[id="sc-382a1301-17"]{content:"dUwlff,"}/*!sc*/
.hStdHy{background-color:white;color:#000;border-bottom:1px solid rgba(0, 0, 0, 0);height:44px;display:flex;flex-direction:column;justify-content:center;padding-top:0px;padding-bottom:-1px;top:0;visiblity:hidden;position:absolute;width:100%;z-index:1000;background:transparent;color:white;padding:0;top:0;}/*!sc*/
.hStdHy a:hover{opacity:0.7;}/*!sc*/
.hStdHy:before{content:'';background:linear-gradient(black, transparent);height:200%;opacity:0.2;pointer-events:none;position:absolute;top:0px;transition:opacity 0.5s cubic-bezier(0.19, 1, 0.22, 1) 0s;width:100%;z-index:-1;max-width:1700px;left:50%;transform:translateX(-50%);display:none;}/*!sc*/
.hStdHy:hover:before{display:block;opacity:0.45;}/*!sc*/
@media (max-width: 640px){.hStdHy:hover:before{display:none;}}/*!sc*/
@media (max-width: 640px){.hStdHy{background-color:white;color:black;}}/*!sc*/
@media (max-width: 640px){.hStdHy{height:42px;}}/*!sc*/
@media print{.hStdHy{display:none;}}/*!sc*/
data-styled.g105[id="sc-8c8cfef8-0"]{content:"hStdHy,"}/*!sc*/
.hyZuPh{box-sizing:border-box;display:grid;font-size:1.44rem;letter-spacing:0.2rem;grid-row-gap:8px;grid-template-areas:'nav-left primary-logo nav-right' 'social-links primary-logo secondary-logo';grid-template-columns:322px auto 322px;grid-template-rows:auto;margin-left:auto;margin-right:auto;max-width:140rem;padding:0 2.4rem;position:relative;width:100%;max-height:44px;grid-template-areas:'nav-left social-links primary-logo nav-right';grid-template-rows:100%;grid-template-columns:125px 245px auto 365px;}/*!sc*/
@media (max-width: 720px){.hyZuPh{align-content:center;justify-content:space-between;}}/*!sc*/
@media (min-width: 1281px){.hyZuPh{grid-template-areas:'nav-left social-links primary-logo nav-right secondary-logo';grid-template-columns:125px 315px auto 365px 75px;}}/*!sc*/
@media (min-width: 640px){.hyZuPh{height:calc(
          44px - (0px) * 2
        );}}/*!sc*/
@media (max-width: 960px){.hyZuPh{font-size:1.3rem;grid-template-columns:35% auto 35%;grid-template-rows:100%;grid-template-columns:110px 100px auto 220px;}}/*!sc*/
@media (max-width: 720px){.hyZuPh{grid-template-areas:'nav-left nav-left primary-logo nav-right nav-right' 'nav-left nav-left primary-logo nav-right nav-right';}}/*!sc*/
@media (max-width: 640px){.hyZuPh{font-size:1.2rem;grid-template-areas:'nav-left primary-logo nav-right';grid-template-columns:auto;grid-template-columns:120px 1fr 120px;margin-top:0;padding:0 2.4rem;}}/*!sc*/
@media (max-width: 340px){.hyZuPh{font-size:1rem;}}/*!sc*/
data-styled.g106[id="sc-8c8cfef8-1"]{content:"hyZuPh,"}/*!sc*/
.gSdZAS{grid-area:primary-logo;text-align:center;color:#035a6d;line-height:0;display:flex;flex-direction:column;justify-content:center;align-items:center;}/*!sc*/
.gSdZAS:hover{opacity:1;}/*!sc*/
.gSdZAS svg path{fill:white;}/*!sc*/
@media (max-width: 640px){.gSdZAS svg path{fill:#035a6d;}}/*!sc*/
@media (max-width: 640px){.gSdZAS svg{height:20px;}}/*!sc*/
data-styled.g107[id="sc-8c8cfef8-2"]{content:"gSdZAS,"}/*!sc*/
.kWJslN{grid-area:secondary-logo;text-align:right;display:flex;align-items:center;justify-content:flex-end;height:auto;}/*!sc*/
.kWJslN a{display:inline-block;margin-top:4px;}/*!sc*/
.kWJslN a::after{padding:0 1.2rem;content:'/';opacity:0.7;vertical-align:middle;position:relative;top:-0.5em;}/*!sc*/
.kWJslN a:last-child::after{display:none;}/*!sc*/
.kWJslN a:first-child{display:none;}/*!sc*/
@media (max-width: 1280px){.kWJslN{display:none;}}/*!sc*/
@media (max-width: 640px){.kWJslN{display:none;}}/*!sc*/
data-styled.g108[id="sc-8c8cfef8-3"]{content:"kWJslN,"}/*!sc*/
.iqWzxD{grid-area:nav-left;display:flex;align-items:center;justify-content:flex-start;font-family:"Atlas Typewriter","Courier New",Courier,monospace;text-align:left;}/*!sc*/
.ewmLlQ{grid-area:nav-right;display:flex;align-items:center;justify-content:flex-end;font-family:"Atlas Typewriter","Courier New",Courier,monospace;text-align:right;}/*!sc*/
data-styled.g109[id="sc-8c8cfef8-4"]{content:"iqWzxD,ewmLlQ,"}/*!sc*/
.hDdFVh{text-transform:uppercase;display:flex;cursor:pointer;align-items:center;line-height:1;height:100%;}/*!sc*/
.hDdFVh:after{padding:0 0.6rem;opacity:0.7;content:'/';}/*!sc*/
@media (max-width: 768px){.hDdFVh{display:flex;height:25px;}.hDdFVh::after{padding:0 0.4rem;}.hDdFVh:last-child::after{content:'';display:none;}}/*!sc*/
@media (max-width: 1280px){.hDdFVh:last-child::after{content:'';display:none;}}/*!sc*/
.jlaulI{text-transform:uppercase;display:flex;cursor:pointer;align-items:center;line-height:1;height:100%;}/*!sc*/
.jlaulI:after{padding:0 0.6rem;opacity:0.7;content:'/';}/*!sc*/
@media (max-width: 768px){.jlaulI{display:none;height:25px;}.jlaulI::after{padding:0 0.4rem;}.jlaulI:last-child::after{content:'';display:none;}}/*!sc*/
@media (max-width: 1280px){.jlaulI:last-child::after{content:'';display:none;}}/*!sc*/
.eLGQGF{text-transform:uppercase;display:flex;cursor:pointer;align-items:center;line-height:1;height:100%;}/*!sc*/
.eLGQGF:after{padding:0 0.6rem;opacity:0.7;content:'/';}/*!sc*/
@media (max-width: 768px){.eLGQGF{display:flex;height:25px;}.eLGQGF::after{padding:0 0.4rem;}.eLGQGF:last-child::after{content:'';display:none;}}/*!sc*/
@media (max-width: 1280px){.eLGQGF:last-child::after{content:'';display:none;}}/*!sc*/
@media (max-width: 639px){.eLGQGF:after{content:'';padding:0;}}/*!sc*/
.iiYHdt{text-transform:uppercase;display:flex;cursor:pointer;align-items:center;line-height:1;height:100%;}/*!sc*/
.iiYHdt:after{padding:0 0.6rem;opacity:0.7;content:'/';}/*!sc*/
@media (max-width: 768px){.iiYHdt{display:flex;height:25px;}.iiYHdt::after{padding:0 0.4rem;}.iiYHdt:last-child::after{content:'';display:none;}}/*!sc*/
@media (max-width: 1280px){.iiYHdt:last-child::after{content:'';display:none;}.iiYHdt:after{content:'';padding:0;}}/*!sc*/
data-styled.g110[id="sc-8c8cfef8-5"]{content:"hDdFVh,jlaulI,eLGQGF,iiYHdt,"}/*!sc*/
.iPPrLh{display:flex;grid-area:social-links;height:auto;}/*!sc*/
.iPPrLh a{padding-right:1.2rem;display:flex;align-items:center;}/*!sc*/
@media (max-width: 720px){.iPPrLh{display:none;}}/*!sc*/
data-styled.g112[id="sc-8c8cfef8-7"]{content:"iPPrLh,"}/*!sc*/
.javaur{height:25px;}/*!sc*/
@media only screen and (max-width: 640px){.javaur{height:24px;}}/*!sc*/
data-styled.g114[id="sc-8c8cfef8-9"]{content:"javaur,"}/*!sc*/
.eqAEli{max-width:90%;}/*!sc*/
.eqAEli input{background-color:transparent;font-size:1.3rem;color:grey;}/*!sc*/
@media (max-width: 640px){.eqAEli input{background-color:white;position:absolute;max-width:100%;top:0;}}/*!sc*/
data-styled.g115[id="sc-8c8cfef8-10"]{content:"eqAEli,"}/*!sc*/
.iMfgWj{padding-left:0.6rem;padding-top:0.3rem;}/*!sc*/
data-styled.g116[id="sc-8c8cfef8-11"]{content:"iMfgWj,"}/*!sc*/
.eGejQg{white-space:nowrap;}/*!sc*/
.eGejQg >div{display:inline;}/*!sc*/
.eGejQg >span{display:none;}/*!sc*/
@media only screen and (min-width: 640px){.eGejQg >div{display:none;}.eGejQg >span{display:inline;}}/*!sc*/
data-styled.g117[id="sc-8c8cfef8-12"]{content:"eGejQg,"}/*!sc*/
.loFSIO{position:relative;flex-grow:1;width:100%;margin:0 auto;}/*!sc*/
@media only print{.loFSIO{width:21cm;}}/*!sc*/
data-styled.g139[id="sc-a70232b9-0"]{content:"loFSIO,"}/*!sc*/
.bspASq{background-color:#fff;display:flex;flex-direction:column;min-height:100vh;position:relative;}/*!sc*/
data-styled.g140[id="sc-a70232b9-1"]{content:"bspASq,"}/*!sc*/
.jQYQEz{flex-grow:0;}/*!sc*/
data-styled.g141[id="sc-a70232b9-2"]{content:"jQYQEz,"}/*!sc*/
.kYcyoy{flex-grow:0;}/*!sc*/
data-styled.g142[id="sc-a70232b9-3"]{content:"kYcyoy,"}/*!sc*/
.kQGdcj{z-index:500;}/*!sc*/
.fLTDBp{z-index:500;position:fixed;left:0;bottom:0;width:100%;box-shadow:0 0 30px #00000040;}/*!sc*/
data-styled.g144[id="sc-a70232b9-5"]{content:"kQGdcj,fLTDBp,"}/*!sc*/
.kgvxLf{font-family:"Academica Book Pro",Times,Georgia,serif;font-size:2.2rem;line-height:1.4;color:#000;}/*!sc*/
@media only screen and (min-width: 640px){.kgvxLf{padding-right:3rem;}}/*!sc*/
.kgvxLf a{border-bottom:1px solid;}/*!sc*/
.kgvxLf a:hover{opacity:0.8;}/*!sc*/
.kgvxLf .pullquote{color:#035a6d;display:block;font-size:3.2rem;line-height:1.3;margin-left:0;margin-top:2rem;padding-bottom:0.5rem;padding-left:6rem;padding-top:0.75rem;}/*!sc*/
.kgvxLf .pullquote:first-letter{text-transform:uppercase;}/*!sc*/
@media only screen and (max-width: 640px){.kgvxLf .pullquote{padding-left:0;}}/*!sc*/
@media print{.kgvxLf .pullquote{display:none;}}/*!sc*/
.kgvxLf ol,.kgvxLf ul{counter-reset:item;padding-left:0.1em;}/*!sc*/
.kgvxLf li{counter-increment:item;list-style-type:none;padding-left:1.9em;margin-bottom:1em;position:relative;}/*!sc*/
.kgvxLf li:before{display:inline-block;width:1.65em;left:0;position:absolute;font-weight:bold;text-align:left;content:counter(item) '.';}/*!sc*/
.kgvxLf ul li:before{content:'•';}/*!sc*/
.kgvxLf blockquote{margin-left:2em;}/*!sc*/
.kgvxLf code{font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:85%;background-color:#afb8c133;padding:0.2rem 0.4rem;border-radius:6px;white-space:break-spaces;}/*!sc*/
@media not print{.kgvxLf .ld-dropcap,.kgvxLf .has-dropcap>p:first-of-type:first-letter{float:left;-webkit-font-feature-settings:'kern' 0;-webkit-font-kerning:none;-webkit-font-smoothing:antialiased;font-feature-settings:'kern' 0;font-kerning:none;font-size:3.25em;line-height:0.8;margin-bottom:-0.05em;margin-left:-0.05em;padding:0.05em 0.075em 0 0;position:relative;top:0.06em;background:inherit;}}/*!sc*/
@media print{.kgvxLf .ld-dropcap,.kgvxLf .has-dropcap>p:first-of-type:first-letter{font-weight:bold;font-size:120%;margin-right:2px;}}/*!sc*/
.kgvxLf .ld-image-block{max-width:100%;}/*!sc*/
.kgvxLf .ld-image-gallery{display:none;}/*!sc*/
.kgvxLf figure{margin:3rem auto;}/*!sc*/
@media print{.kgvxLf figure{page-break-inside:avoid;}}/*!sc*/
.kgvxLf figure iframe{aspect-ratio:16/9;width:100%;height:auto;}/*!sc*/
@media not all and (min-resolution: 0.001dpcm){@media{.kgvxLf figure iframe{min-height:420px;}}}/*!sc*/
@media only screen and (max-width: 1280px){@media not all and (min-resolution: 0.001dpcm){@media{.kgvxLf figure iframe{min-height:260px;}}}}/*!sc*/
@media only screen and (max-width: 768px){@media not all and (min-resolution: 0.001dpcm){@media{.kgvxLf figure iframe{min-height:200px;}}}}/*!sc*/
@media only screen and (max-width: 640px){@media not all and (min-resolution: 0.001dpcm){@media{.kgvxLf figure iframe{min-height:260px;}}}}/*!sc*/
@media only screen and (max-width: 480px){@media not all and (min-resolution: 0.001dpcm){@media{.kgvxLf figure iframe{min-height:160px;}}}}/*!sc*/
.kgvxLf figure img{display:block;margin-left:auto;margin-right:auto;margin-top:0.5rem;max-width:100%;height:auto;width:auto;}/*!sc*/
@media print{.kgvxLf figure img{max-width:10cm;max-height:10cm;}}/*!sc*/
@media only screen and (max-width: 480px){.kgvxLf figure .ld-embed-block{width:100%;height:100%;}}/*!sc*/
.kgvxLf figcaption{grid-area:attribution;font-family:"Atlas Typewriter","Courier New",Courier,monospace;color:#666;font-size:1.3rem;margin-top:2rem;position:relative;}/*!sc*/
.kgvxLf figcaption:empty{display:none;}/*!sc*/
.kgvxLf figcaption p{margin:0;}/*!sc*/
.kgvxLf p{margin-bottom:2rem;overflow-wrap:anywhere;word-break:break-word;}/*!sc*/
.kgvxLf p:first-of-type{margin-top:0;}/*!sc*/
.kgvxLf p:last-of-type{margin-bottom:0;}/*!sc*/
.kgvxLf img,.kgvxLf video{max-width:100%;}/*!sc*/
.kgvxLf .ld-sans{font-family:'Atlas Grotesk','Helvetica Neue',Helvetica,Arial,sans-serif;}/*!sc*/
.kgvxLf .subheading{font-size:2.6rem;padding-left:0;padding-top:0;padding-bottom:0;}/*!sc*/
.kgvxLf .ld-superscript{position:relative;top:-0.4em;vertical-align:baseline;}/*!sc*/
.kgvxLf .ld-subscript{position:relative;top:0.4em;vertical-align:baseline;}/*!sc*/
.kgvxLf .ld-nowrap{white-space:nowrap;}/*!sc*/
data-styled.g158[id="sc-2fe4243b-1"]{content:"kgvxLf,"}/*!sc*/
.hOxvOE .page-mark{cursor:pointer;transition:background 0.2s linear,outline 0.2s linear;}/*!sc*/
.hOxvOE .page-mark.mark-type-highlight{background:rgba(255, 125, 0, 0.5);}/*!sc*/
.hOxvOE .page-mark.mark-type-annotation{background:rgba(255, 0, 125, 0.3);}/*!sc*/
.hOxvOE .page-mark[data-annotation-number]::after{display:inline-block;content:attr(data-annotation-number);font-size:50%;font-weight:bold;transform:translateY(-75%);color:#9d1d20;margin-right:-1ex;}/*!sc*/
.hOxvOE img.page-mark.mark-type-highlight,.hOxvOE iframe.page-mark.mark-type-highlight{outline:1rem solid rgba(255, 125, 0, 0.5);}/*!sc*/
.hOxvOE img.page-mark.mark-type-annotation,.hOxvOE iframe.page-mark.mark-type-annotation{outline:1rem solid rgba(255, 0, 125, 0.3);}/*!sc*/
data-styled.g160[id="sc-2fe4243b-3"]{content:"hOxvOE,"}/*!sc*/
.jwmryO{padding-bottom:20px;color:#444;font-size:1.6rem;line-height:1.6;}/*!sc*/
.jwmryO a{text-decoration:underline;}/*!sc*/
.jwmryO p:first-of-type{display:inline;margin-top:0;}/*!sc*/
.jwmryO p:last-of-type{margin-bottom:0;}/*!sc*/
data-styled.g255[id="sc-2e8621ab-0"]{content:"jwmryO,"}/*!sc*/
.jexetL{display:inline;margin-right:0.7ex;color:#444;font-size:1.6rem;line-height:1.6;}/*!sc*/
data-styled.g256[id="sc-2e8621ab-1"]{content:"jexetL,"}/*!sc*/
.iLMcGv{height:5rem;max-width:30rem;background-color:#035a6d20;color:#035a6d;text-align:center;display:flex;align-items:center;justify-content:center;font-family:"Atlas Grotesk","Helvetica Neue",Helvetica,Arial,sans-serif;font-weight:normal;position:relative;margin-bottom:40px;}/*!sc*/
.iLMcGv:hover{background-color:#035a6d;color:white;cursor:pointer;}/*!sc*/
.iLMcGv:hover:after{color:white;cursor:pointer;border-top:25px solid #035a6d;}/*!sc*/
.iLMcGv:after{content:'';height:40px;width:40px;position:absolute;bottom:-25px;left:15px;width:0px;height:0px;border-left:0 solid transparent;border-right:20px solid transparent;border-top:25px solid #035a6d20;}/*!sc*/
@media only screen and (max-width: 768px){.iLMcGv{max-width:18rem;margin-top:2rem;}}/*!sc*/
data-styled.g257[id="sc-81b64237-0"]{content:"iLMcGv,"}/*!sc*/
.grcCCz{font-family:"Atlas Grotesk","Helvetica Neue",Helvetica,Arial,sans-serif;color:#444;cursor:pointer;display:flex;flex-wrap:wrap;max-width:30rem;}/*!sc*/
.grcCCz div{align-items:center;justify-content:center;box-sizing:border-box;display:flex;flex:0 0 50%;font:inherit;margin:1.3rem 0;}/*!sc*/
.grcCCz div svg,.grcCCz div span{font-weight:normal;transition:all 0.5s cubic-bezier(0.19, 1, 0.22, 1);}/*!sc*/
.grcCCz div:hover svg,.grcCCz div:hover span{color:#035a6d;transition:all 0.5s cubic-bezier(0.19, 1, 0.22, 1);}/*!sc*/
@media only screen and (max-width: 767px){.grcCCz div{justify-content:flex-start;}}/*!sc*/
@media print{.grcCCz{display:none;}}/*!sc*/
data-styled.g258[id="sc-531dc212-0"]{content:"grcCCz,"}/*!sc*/
.dkebQC{margin-right:10px;vertical-align:middle;}/*!sc*/
data-styled.g259[id="sc-531dc212-1"]{content:"dkebQC,"}/*!sc*/
.gjonPf{line-height:1;top:0.2rem;position:relative;}/*!sc*/
data-styled.g260[id="sc-531dc212-2"]{content:"gjonPf,"}/*!sc*/
.bSqqMf{flex-direction:column;font-size:1.6rem;font-weight:bold;position:sticky;display:none;}/*!sc*/
@media only screen and (min-width: 640px){.bSqqMf{display:flex;gap:1rem;}}/*!sc*/
@media print{.bSqqMf{display:none;}}/*!sc*/
data-styled.g261[id="sc-c3e98e6e-0"]{content:"bSqqMf,"}/*!sc*/
.lfcsbM{background:#035a6d;border:none;color:white;cursor:pointer;display:inline-flex;flex-direction:column;font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.2rem;height:min-content;justify-content:center;letter-spacing:0.15rem;line-height:1.6;max-width:25rem;padding:1rem 2.4rem 0.8rem;position:relative;text-align:center;text-transform:uppercase;z-index:8;margin:0;background-color:#ececec;color:#666;}/*!sc*/
.lfcsbM:hover{background-color:#035a6dc9;}/*!sc*/
.lfcsbM:hover{background-color:#000;color:#fff;}/*!sc*/
data-styled.g262[id="sc-45649ee9-0"]{content:"lfcsbM,"}/*!sc*/
.cacrwE{visibility:visible;display:flex;align-items:center;}/*!sc*/
data-styled.g263[id="sc-45649ee9-1"]{content:"cacrwE,"}/*!sc*/
.fFoFgq{padding:2rem;}/*!sc*/
.fFoFgq span{justify-content:center;}/*!sc*/
data-styled.g265[id="sc-5c8686bf-0"]{content:"fFoFgq,"}/*!sc*/
.hEDaTq{grid-area:syndication;margin:2rem 0;}/*!sc*/
@media only print{.hEDaTq{display:none;}}/*!sc*/
@media (max-width: 640px){.hEDaTq{display:none;}}/*!sc*/
.hZCbhD{grid-area:syndication;margin:2rem 0;}/*!sc*/
@media only print{.hZCbhD{display:none;}}/*!sc*/
data-styled.g266[id="sc-5c8686bf-1"]{content:"hEDaTq,hZCbhD,"}/*!sc*/
.iNdsQY{display:flex;font-size:1.6rem;color:#444;}/*!sc*/
.iNdsQY >span{padding-right:1.4rem;}/*!sc*/
@media only screen and (min-width: 640px){.iNdsQY{display:flex;}.iNdsQY >span{padding-right:2.4rem;}}/*!sc*/
@media print{.iNdsQY{display:none;}}/*!sc*/
data-styled.g267[id="sc-114c07c9-0"]{content:"iNdsQY,"}/*!sc*/
.bvsiTx{display:inline-flex;column-gap:0.4rem;text-decoration:underline;}/*!sc*/
@media only screen and (min-width: 640px){.bvsiTx{display:none;}}/*!sc*/
data-styled.g268[id="sc-114c07c9-1"]{content:"bvsiTx,"}/*!sc*/
.hRWhru{display:inline-flex;column-gap:0.4rem;}/*!sc*/
@media only screen and (min-width: 640px){.hRWhru{display:none;}}/*!sc*/
data-styled.g269[id="sc-114c07c9-2"]{content:"hRWhru,"}/*!sc*/
.kRreg{margin:0 auto;max-width:120rem;}/*!sc*/
@media (min-width: 1280px){.kRreg{max-width:140rem;}}/*!sc*/
data-styled.g280[id="sc-3ddd79c0-0"]{content:"kRreg,"}/*!sc*/
.cTFGMY{margin:0 auto;max-width:1700px;}/*!sc*/
data-styled.g281[id="sc-3ddd79c0-1"]{content:"cTFGMY,"}/*!sc*/
.cWSLWv{display:grid;grid-template-areas:'header' 'aside' 'main' 'social' 'appendix';padding:0 2.4rem;}/*!sc*/
@media only screen and (min-width: 640px){.cWSLWv{grid-template-areas:"header header" "aside main" "aside appendix";grid-column-gap:48px;grid-template-columns:170px 1fr;min-height:400px;padding-bottom:30px;position:relative;}}/*!sc*/
@media only screen and (min-width: 768px){.cWSLWv{grid-template-columns:calc(100% * .9 / 3) 1fr;grid-column-gap:32px;grid-template-columns:calc(100% * .9 / 3) 1fr;}}/*!sc*/
@media only screen and (min-width: 1280px){.cWSLWv{grid-column-gap:36px;}}/*!sc*/
@media print{.cWSLWv{display:block;}}/*!sc*/
@media print,screen and (min-width: 640px){.cWSLWv .SidebarWrapper{display:block;height:auto!important;}.cWSLWv .SidebarWrapper >div{display:block!important;}}/*!sc*/
.cWSLWv .editorial-info-wrapper{margin-top:5rem;}/*!sc*/
@media only print{.cWSLWv .editorial-info-wrapper{display:none;}}/*!sc*/
data-styled.g285[id="sc-3ddd79c0-5"]{content:"cWSLWv,"}/*!sc*/
.rkpEx{align-self:start;width:100%;position:relative;z-index:1;max-width:90%;}/*!sc*/
data-styled.g287[id="sc-3ddd79c0-7"]{content:"rkpEx,"}/*!sc*/
.eACYrZ p{color:#444;font-size:1.6rem;line-height:1.6;margin:0 0 20px 0;position:relative;z-index:1;}/*!sc*/
.eACYrZ p a{margin-left:0.7ex;text-decoration:underline;}/*!sc*/
@media only screen and (min-width: 640px){.eACYrZ p{margin-bottom:15px;}}/*!sc*/
data-styled.g289[id="sc-3ddd79c0-9"]{content:"eACYrZ,"}/*!sc*/
.krmTZN{grid-area:main;-moz-osx-font-smoothing:grayscale;font-family:"Academica Book Pro",Times,Georgia,serif;font-size:2rem;margin:2rem 0 4rem;}/*!sc*/
@media only screen and (min-width: 768px){.krmTZN{font-size:2.2rem;padding-bottom:0;margin-top:0;}}/*!sc*/
@media only screen and (min-width: 1280px){.krmTZN{padding-bottom:0;}}/*!sc*/
@page{margin:1.9cm;}/*!sc*/
@media print{.krmTZN p{padding:0.4cm;}}/*!sc*/
data-styled.g290[id="sc-3ddd79c0-10"]{content:"krmTZN,"}/*!sc*/
.cmKAit{grid-area:aside;display:flex;flex-direction:column;justify-content:flex-start;margin-bottom:0;}/*!sc*/
.cmKAit a:hover{text-decoration:none;}/*!sc*/
@media (min-width: 640px){.cmKAit{margin-bottom:3.2rem;}}/*!sc*/
@media print{.cmKAit{margin-bottom:0;padding:0.4cm;}}/*!sc*/
data-styled.g292[id="sc-3ddd79c0-12"]{content:"cmKAit,"}/*!sc*/
.kNGStK{grid-area:social;align-self:start;position:sticky;top:0;min-height:100vh;margin-top:2rem;padding-bottom:4rem;z-index:0;display:none;flex-direction:column;justify-content:flex-end;grid-area:social;align-self:start;}/*!sc*/
@media (max-width: 768px){.kNGStK{margin-top:0;min-height:0;}}/*!sc*/
@media (min-width: 640px){.kNGStK{display:flex;}}/*!sc*/
@media print{.kNGStK{display:none;}}/*!sc*/
data-styled.g293[id="sc-3ddd79c0-13"]{content:"kNGStK,"}/*!sc*/
@media only screen and (min-width: 640px){.fDVRDq{display:none;}}/*!sc*/
data-styled.g294[id="sc-3ddd79c0-14"]{content:"fDVRDq,"}/*!sc*/
@media only screen and (max-width: 640px){.hlcfjM{max-width:100%;}.hlcfjM div{flex-basis:25%;margin-right:1.3rem;}}/*!sc*/
data-styled.g295[id="sc-3ddd79c0-15"]{content:"hlcfjM,"}/*!sc*/
.bYOvqH{font-size:1.5rem;font-family:"Atlas Typewriter","Courier New",Courier,monospace;display:flex;flex-direction:column;margin-bottom:3rem;color:#999;}/*!sc*/
@media only screen and (min-width: 640px){.bYOvqH{margin-top:2rem;}}/*!sc*/
@media print{.bYOvqH{flex-direction:row-reverse;justify-content:space-between;margin-top:3.8rem;}.bYOvqH:after{display:inline-block;content:'aeon.co';}}/*!sc*/
data-styled.g296[id="sc-3ddd79c0-16"]{content:"bYOvqH,"}/*!sc*/
.gMPmhu{display:flex;flex-wrap:wrap;max-width:100%;margin-bottom:3rem;text-decoration:underline;}/*!sc*/
.gMPmhu >a{padding-right:2rem;}/*!sc*/
@media only screen and (min-width: 640px){.gMPmhu{margin-bottom:none;max-width:75%;}}/*!sc*/
@media print{.gMPmhu{display:none;}}/*!sc*/
data-styled.g297[id="sc-3ddd79c0-17"]{content:"gMPmhu,"}/*!sc*/
.iNtEGo{display:block;margin-top:2rem;font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.5rem;color:#035a6d;border-bottom:1px solid #035a6d;}/*!sc*/
.kLzZnA{display:block;margin-top:2rem;font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.5rem;color:#0c776d;border-bottom:1px solid #0c776d;}/*!sc*/
.htqJbk{display:block;margin-top:2rem;font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.5rem;color:#9d120d;border-bottom:1px solid #9d120d;}/*!sc*/
data-styled.g298[id="sc-3ddd79c0-18"]{content:"iNtEGo,kLzZnA,htqJbk,"}/*!sc*/
.aSMqJ{grid-area:appendix;display:flex;flex-direction:column;row-gap:2.4rem;}/*!sc*/
.aSMqJ a{text-decoration:none;border-bottom:none;}/*!sc*/
data-styled.g301[id="sc-3ddd79c0-21"]{content:"aSMqJ,"}/*!sc*/
.dFoKXg{display:flex;flex-direction:column;row-gap:2rem;}/*!sc*/
@media only screen and (min-width: 640px){.dFoKXg{flex-direction:row;justify-content:space-between;}}/*!sc*/
data-styled.g302[id="sc-3ddd79c0-22"]{content:"dFoKXg,"}/*!sc*/
.foKljT{height:42px;background-color:white;}/*!sc*/
@media (min-width: 640px){.foKljT{display:none;}}/*!sc*/
data-styled.g303[id="sc-3ddd79c0-23"]{content:"foKljT,"}/*!sc*/
@media only print{.benkhL{display:none;}}/*!sc*/
data-styled.g304[id="sc-3ddd79c0-24"]{content:"benkhL,"}/*!sc*/
.biFWNV{margin-bottom:3rem;margin-top:0rem;}/*!sc*/
@media (max-width: 640px){.biFWNV{margin-top:2rem;margin-bottom:0rem;}}/*!sc*/
data-styled.g305[id="sc-3ddd79c0-25"]{content:"biFWNV,"}/*!sc*/
.gskDxn{position:relative;}/*!sc*/
data-styled.g306[id="sc-3ddd79c0-26"]{content:"gskDxn,"}/*!sc*/
.eNVkkS{transition:color 0.2s ease;}/*!sc*/
data-styled.g307[id="sc-d56bc236-0"]{content:"eNVkkS,"}/*!sc*/
.bLA-dMf{box-sizing:border-box;position:relative;z-index:1;display:grid;grid-template-areas:'topic-wrap topic-wrap' 'title title' 'standfirst standfirst' 'author author';align-content:center;padding-top:24px;transition:all 0.3s cubic-bezier(.645,.045,.355,1);width:100%;margin:0;}/*!sc*/
@media only screen and (max-width: 640px){.bLA-dMf{padding-left:2.4rem;padding-right:2.4rem;}}/*!sc*/
@media only print{.bLA-dMf{padding-top:2rem;padding-right:2rem;width:100%;}}/*!sc*/
data-styled.g308[id="sc-d56bc236-1"]{content:"bLA-dMf,"}/*!sc*/
.eSkyVL{font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.35rem;margin:0;display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis;}/*!sc*/
data-styled.g309[id="sc-d56bc236-2"]{content:"eSkyVL,"}/*!sc*/
.XNdEw{font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.35rem;justify-self:end;margin:0 0.6rem 0 0;text-transform:capitalize;transition:all 0.2s ease;overflow:hidden;max-width:5.5rem;padding-right:2rem;position:relative;display:inline-flex;}/*!sc*/
.XNdEw:after{display:block;content:' / ';opacity:0.6;height:100%;padding-left:0.4rem;}/*!sc*/
data-styled.g310[id="sc-d56bc236-3"]{content:"XNdEw,"}/*!sc*/
.gKlMxC{color:#444;top:0.2rem;position:relative;font-family:"Atlas Typewriter","Courier New",Courier,monospace;font-size:1.35rem;margin:0;display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis;}/*!sc*/
data-styled.g311[id="sc-d56bc236-4"]{content:"gKlMxC,"}/*!sc*/
.ZcrSZ{display:flex;align-items:center;padding:2rem 2.2rem 2.2rem 2rem;margin:-2rem;}/*!sc*/
.ZcrSZ .sc-d56bc236-4{display:none;}/*!sc*/
.ZcrSZ:hover .sc-d56bc236-4{display:inline;color:#9d120d;}/*!sc*/
.ZcrSZ:hover ~p{display:none;}/*!sc*/
.uJGVm{display:flex;align-items:center;padding:2rem 2.2rem 2.2rem 2rem;margin:-2rem;}/*!sc*/
.uJGVm .sc-d56bc236-4{display:none;}/*!sc*/
.uJGVm:hover .sc-d56bc236-4{display:inline;color:#0c776d;}/*!sc*/
.uJGVm:hover ~p{display:none;}/*!sc*/
.grFBAP{display:flex;align-items:center;padding:2rem 2.2rem 2.2rem 2rem;margin:-2rem;}/*!sc*/
.grFBAP .sc-d56bc236-4{display:none;}/*!sc*/
.grFBAP:hover .sc-d56bc236-4{display:inline;color:#940b52;}/*!sc*/
.grFBAP:hover ~p{display:none;}/*!sc*/
data-styled.g312[id="sc-d56bc236-5"]{content:"ZcrSZ,uJGVm,grFBAP,"}/*!sc*/
.jrySry{display:flex;flex-direction:column;position:absolute;top:0;right:0;}/*!sc*/
data-styled.g313[id="sc-d56bc236-6"]{content:"jrySry,"}/*!sc*/
.jJLnBL{width:2.6rem;height:2.6rem;background:white;display:flex;align-items:center;justify-content:center;border-radius:50%;margin:0.6rem 0.6rem 0 0;}/*!sc*/
data-styled.g314[id="sc-d56bc236-7"]{content:"jJLnBL,"}/*!sc*/
.gArifC{grid-area:topic-wrap;display:flex;align-items:center;font-size:1.4rem;}/*!sc*/
data-styled.g315[id="sc-d56bc236-8"]{content:"gArifC,"}/*!sc*/
.eCvrmh{display:flex;flex-direction:column;position:relative;cursor:pointer;}/*!sc*/
.eCvrmh img{transition:all 0.2s ease;}/*!sc*/
.eCvrmh:hover .sc-d56bc236-0{color:#9d120d;}/*!sc*/
.eCvrmh:hover .sc-d56bc236-3{max-width:0;margin:0;padding-right:0;}/*!sc*/
.eCvrmh:hover img{mix-blend-mode:screen;filter:grayscale(100%);}/*!sc*/
.eCvrmh:hover svg{color:#9d120d;}/*!sc*/
.cKZvmh{display:flex;flex-direction:column;position:relative;cursor:pointer;}/*!sc*/
.cKZvmh img{transition:all 0.2s ease;}/*!sc*/
.cKZvmh:hover .sc-d56bc236-0{color:#0c776d;}/*!sc*/
.cKZvmh:hover .sc-d56bc236-3{max-width:0;margin:0;padding-right:0;}/*!sc*/
.cKZvmh:hover img{mix-blend-mode:screen;filter:grayscale(100%);}/*!sc*/
.cKZvmh:hover svg{color:#0c776d;}/*!sc*/
.gJMojt{display:flex;flex-direction:column;position:relative;cursor:pointer;}/*!sc*/
.gJMojt img{transition:all 0.2s ease;}/*!sc*/
.gJMojt:hover .sc-d56bc236-0{color:#940b52;}/*!sc*/
.gJMojt:hover .sc-d56bc236-3{max-width:0;margin:0;padding-right:0;}/*!sc*/
.gJMojt:hover img{mix-blend-mode:screen;filter:grayscale(100%);}/*!sc*/
.gJMojt:hover svg{color:#940b52;}/*!sc*/
data-styled.g316[id="sc-d56bc236-9"]{content:"eCvrmh,cKZvmh,gJMojt,"}/*!sc*/
.tdBWn{grid-area:title;font-family:"Academica Book Pro",Times,Georgia,serif;font-size:2.8rem;font-weight:700;line-height:1.2;margin:1.4rem 0 1.2rem 0;}/*!sc*/
data-styled.g317[id="sc-d56bc236-10"]{content:"tdBWn,"}/*!sc*/
.hYbLtW{grid-area:standfirst;font-family:"Atlas Grotesk","Helvetica Neue",Helvetica,Arial,sans-serif;margin:0 0 14px;font-size:1.6rem;letter-spacing:0;line-height:1.5;}/*!sc*/
data-styled.g318[id="sc-d56bc236-11"]{content:"hYbLtW,"}/*!sc*/
.dFhhBp{grid-area:author;margin:0;font-size:1.6rem;letter-spacing:0;opacity:0.65;}/*!sc*/
.dFhhBp:hover{opacity:1;}/*!sc*/
data-styled.g319[id="sc-d56bc236-12"]{content:"dFhhBp,"}/*!sc*/
.kSWDpk{flex-grow:0;flex-shrink:0;width:100%;background-color:#9d120d;display:block;overflow:hidden;position:relative;padding-top:55.56%;}/*!sc*/
.kSWDpk img{display:block;object-fit:cover;object-position:50% 50%;height:100%;width:100%;position:absolute;top:0;}/*!sc*/
@media only print{.kSWDpk{width:calc(21cm / 3);}}/*!sc*/
.ldkvZH{flex-grow:0;flex-shrink:0;width:100%;background-color:#0c776d;display:block;overflow:hidden;position:relative;padding-top:55.56%;}/*!sc*/
.ldkvZH img{display:block;object-fit:cover;object-position:50% 50%;height:100%;width:100%;position:absolute;top:0;}/*!sc*/
@media only print{.ldkvZH{width:calc(21cm / 3);}}/*!sc*/
.dmDZMm{flex-grow:0;flex-shrink:0;width:100%;background-color:#940b52;display:block;overflow:hidden;position:relative;padding-top:55.56%;}/*!sc*/
.dmDZMm img{display:block;object-fit:cover;object-position:50% 50%;height:100%;width:100%;position:absolute;top:0;}/*!sc*/
@media only print{.dmDZMm{width:calc(21cm / 3);}}/*!sc*/
data-styled.g323[id="sc-82db9615-2"]{content:"kSWDpk,ldkvZH,dmDZMm,"}/*!sc*/
.cFULRC{display:grid;grid-template-columns:1fr 1fr;grid-row-gap:0;grid-column-gap:2.4rem;grid-row-gap:3.6rem;padding:2.4rem;}/*!sc*/
@media only screen and (min-width: 960px){.cFULRC{grid-template-columns:1fr 1fr 1fr;grid-column-gap:3.6rem;grid-row-gap:5.2rem;padding:3.6rem;}}/*!sc*/
@media only screen and (max-width: 640px){.cFULRC{grid-template-columns:1fr;grid-column-gap:0;grid-row-gap:6rem;padding:0;}}/*!sc*/
data-styled.g340[id="sc-c83e4c92-0"]{content:"cFULRC,"}/*!sc*/
</style></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MHVZTPR" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div id="top-portal" class="sc-a70232b9-5 kQGdcj"></div><div class="sc-a70232b9-1 bspASq"><header class="sc-8c8cfef8-0 hStdHy"><div class="sc-382a1301-2 eujrBb"><div class="sc-382a1301-3 hAFhbJ"><div class="sc-382a1301-0 dVRDrm"><div class="sc-382a1301-1 blLOPP"><div class="sc-382a1301-11 dqDhaI"><span>×</span> CLOSE</div><div class="sc-382a1301-14 eyayoM"><a href="https://www.facebook.com/aeonmag" target="_blank" rel="noopener noreferrer" title="Facebook"><svg viewBox="0 0 1024 1024" fill="currentColor" stroke="none" width="18" height="18" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-facebook" aria-hidden="true"><g><path d="M1024,512C1024,229.23,794.77,0,512,0S0,229.23,0,512c0,255.55,187.23,467.37,432,505.78V660H302V512H432V399.2C432,270.88,508.44,200,625.39,200c56,0,114.61,10,114.61,10V336H675.44c-63.6,0-83.44,39.47-83.44,80v96H734L711.3,660H592v357.78C836.77,979.37,1024,767.55,1024,512Z"></path><path d="M711.3,660,734,512H592V416c0-40.49,19.84-80,83.44-80H740V210s-58.59-10-114.61-10C508.44,200,432,270.88,432,399.2V512H302V660H432v357.78a517.58,517.58,0,0,0,160,0V660Z" fill="transparent"></path></g></svg></a><a href="https://www.instagram.com/aeonmag" target="_blank" rel="noopener noreferrer" title="Instagram"><svg viewBox="0 0 24 25" fill="currentColor" stroke="none" width="20" height="20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-instagram" aria-hidden="true"><path d="M17.216.5c4.456.203 6.887 2.633 7.09 7.09v10.126c-.203 4.456-2.634 6.887-7.09 7.09H7.09C2.633 24.603.203 22.172 0 17.716V7.59C.203 3.133 2.633.703 7.09.5zm-5.063 5.874c-3.444 0-6.28 2.835-6.28 6.279 0 3.443 2.836 6.279 6.28 6.279 3.443 0 6.279-2.836 6.279-6.28 0-3.443-2.836-6.278-6.28-6.278zm0 2.228a4.063 4.063 0 0 1 4.05 4.05 4.063 4.063 0 0 1-4.05 4.052 4.063 4.063 0 0 1-4.051-4.051 4.063 4.063 0 0 1 4.05-4.051zm6.481-3.849c-.81 0-1.418.608-1.418 1.418 0 .81.608 1.418 1.418 1.418.81 0 1.418-.608 1.418-1.418 0-.81-.608-1.418-1.418-1.418z"></path></svg></a><a href="https://twitter.com/aeonmag" target="_blank" rel="noopener noreferrer" title="Twitter"><svg viewBox="0 0 256 209" fill="currentColor" stroke="none" width="20" height="20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-twitter" aria-hidden="true"><path d="M256,25.4500259 C246.580841,29.6272672 236.458451,32.4504868 225.834156,33.7202333 C236.678503,27.2198053 245.00583,16.9269929 248.927437,4.66307685 C238.779765,10.6812633 227.539325,15.0523376 215.57599,17.408298 C205.994835,7.2006971 192.34506,0.822 177.239197,0.822 C148.232605,0.822 124.716076,24.3375931 124.716076,53.3423116 C124.716076,57.4586875 125.181462,61.4673784 126.076652,65.3112644 C82.4258385,63.1210453 43.7257252,42.211429 17.821398,10.4359288 C13.3005011,18.1929938 10.710443,27.2151234 10.710443,36.8402889 C10.710443,55.061526 19.9835254,71.1374907 34.0762135,80.5557137 C25.4660961,80.2832239 17.3681846,77.9207088 10.2862577,73.9869292 C10.2825122,74.2060448 10.2825122,74.4260967 10.2825122,74.647085 C10.2825122,100.094453 28.3867003,121.322443 52.413563,126.14673 C48.0059695,127.347184 43.3661509,127.988612 38.5755734,127.988612 C35.1914554,127.988612 31.9009766,127.659938 28.694773,127.046602 C35.3777973,147.913145 54.7742053,163.097665 77.7569918,163.52185 C59.7820257,177.607983 37.1354036,186.004604 12.5289147,186.004604 C8.28987161,186.004604 4.10888474,185.75646 0,185.271409 C23.2431033,200.173139 50.8507261,208.867532 80.5109185,208.867532 C177.116529,208.867532 229.943977,128.836982 229.943977,59.4326002 C229.943977,57.1552968 229.893412,54.8901664 229.792282,52.6381454 C240.053257,45.2331635 248.958338,35.9825545 256,25.4500259"></path></svg></a><a href="https://www.youtube.com/@AeonVideo" target="_blank" rel="noopener noreferrer" title="YouTube"><svg viewBox="0 0 22 20" fill="currentColor" stroke="none" width="22" height="20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-youtube" aria-hidden="true"><g><path d="M21.5,4.7c-0.3-1-1-1.7-1.9-2C17.9,2.2,11,2.2,11,2.2s-6.9,0-8.6,0.5c-1,0.3-1.7,1-1.9,2C0,6.4,0,10,0,10s0,3.6,0.5,5.3  c0.3,1,1,1.7,1.9,2c1.7,0.5,8.6,0.5,8.6,0.5s6.9,0,8.6-0.5c1-0.3,1.7-1,1.9-2C22,13.6,22,10,22,10S22,6.4,21.5,4.7z M8.8,13.3V6.7  l5.8,3.3L8.8,13.3z"></path></g></svg></a></div></div><div class="sc-382a1301-1 blLOPP"><div class="sc-382a1301-4 cgSlhl"><a href="/philosophy" class="sc-382a1301-5 fxVzSw">Philosophy</a><a href="/science" class="sc-382a1301-5 fGNXsA">Science</a><a href="/psychology" class="sc-382a1301-5 eWXizB">Psychology</a><a href="/society" class="sc-382a1301-5 eSElSD">Society</a><a href="/culture" class="sc-382a1301-5 fIRhhw">Culture</a></div><div class="sc-382a1301-6 fTuact"><div class="sc-382a1301-7 kLcdly"><a href="/essays" class="sc-382a1301-8 gpBmnQ">Essays</a><a href="/videos" class="sc-382a1301-8 gpBmnQ">Videos</a><a href="/audio" class="sc-382a1301-8 gpBmnQ">Audio</a><br/><br/><a href="/popular" class="sc-382a1301-8 sc-382a1301-10 gpBmnQ lctIKH">Popular</a><br/><br/><a href="/about" class="sc-382a1301-8 sc-382a1301-10 gpBmnQ lctIKH">About</a></div><div class="sc-382a1301-9 hfdqqJ"></div></div></div><div class="sc-382a1301-1 blLOPP"><div class="sc-382a1301-13 hNmAek"><a data-ga-select-promotion="aeon_menu_donate" href="/donate" class="sc-382a1301-8 sc-382a1301-10 gpBmnQ lctIKH">Donate</a><a href="/newsletter" class="sc-382a1301-8 sc-382a1301-10 gpBmnQ lctIKH">Newsletter</a><div class="sc-382a1301-12 jGCTqo"><a target="_blank" href="https://psyche.co" style="line-height:1" title="Psyche"><svg viewBox="0 0 138 28" fill="#025744" stroke="none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-psyche" aria-hidden="true" class="sc-382a1301-16 kWIEBN"><path stroke="none" d="M33.4463639,1.03028697e-13 C35.4638444,1.03028697e-13 37.1784471,0.275980571 38.5905508,0.826994629 C40.0024651,1.37857694 41.1385883,2.17242359 41.999678,3.20739809 C42.7884893,4.15681924 43.3288473,5.27001901 43.620898,6.5468515 L43.6943919,6.89913545 L38.7316665,8.31123919 C38.5161099,7.28933447 38.160006,6.45533141 37.6625969,5.80979827 C37.1646196,5.16426513 36.5531815,4.69394271 35.8269567,4.39769452 C35.100732,4.10201459 34.2534697,3.95389049 33.28517,3.95389049 C31.8590494,3.95389049 30.7363748,4.25013868 29.9160098,4.84149856 C29.0952659,5.43342669 28.685557,6.29394813 28.685557,7.42363112 C28.685557,8.28472081 28.9138044,8.96359135 29.3714359,9.46100039 C29.8286886,9.95897769 30.4942999,10.3688761 31.3684594,10.6916427 C32.2424294,11.0144092 33.3253264,11.3510032 34.6165821,11.7002882 C36.7952565,12.2651297 38.5835424,12.8500494 39.9823869,13.4552367 C41.3806632,14.060424 42.4234038,14.8472622 43.1092828,15.8153725 C43.7951617,16.7838617 44.1380065,18.074928 44.1380065,19.6887608 C44.1380065,22.3250666 43.2503985,24.3688761 41.4753717,25.8213256 C39.7001556,27.2737752 37.1310928,28 33.7691304,28 C30.5679831,28 28.053283,27.3614753 26.2244619,26.0834788 C24.4782265,24.8642962 23.406295,23.1484036 23.0086672,20.9361304 L22.9564503,20.6167147 L27.9593322,19.2449568 C28.3086171,20.8322712 28.9408911,22.0223783 29.8555858,22.8154673 C30.7697122,23.6091245 32.1013137,24.0057637 33.8498221,24.0057637 C35.4094817,24.0057637 36.6268647,23.6829971 37.5012136,23.037464 C38.3749942,22.3919308 38.8123581,21.4374586 38.8123581,20.1729107 C38.8123581,19.3123892 38.60381,18.6465885 38.1869032,18.1756978 C37.7696175,17.7053754 37.1242738,17.3083573 36.2504932,16.9855908 C35.3761443,16.6628242 34.2129345,16.3135393 32.7604849,15.9365994 C31.4152454,15.5873145 30.1783523,15.1971154 29.0486693,14.7665706 C27.9189863,14.336594 26.9306084,13.8321765 26.0833462,13.2535076 C25.2358945,12.6754069 24.5835424,11.9561906 24.1264791,11.0951009 C23.6688477,10.2345794 23.4406002,9.17232888 23.4406002,7.90778098 C23.4406002,5.4870317 24.3143808,3.56425972 26.063268,2.13832853 C27.8112081,0.712965594 30.2723032,1.03028697e-13 33.4463639,1.03028697e-13 Z M80.0217694,0.564803615 C81.703603,0.564803615 83.2661038,0.796081774 84.7104085,1.25863809 C86.0096007,1.67493878 87.2353011,2.29023528 88.3869572,3.1036991 L88.7680995,3.3821921 L84.9416866,7.33494608 L84.7314338,7.33494608 C83.8063211,5.90522656 82.7971073,4.81910947 81.703603,4.07602657 C80.6104775,3.33351193 79.475112,2.96168635 78.2976959,2.96168635 C77.0920567,2.96168635 76.0616282,3.29809095 75.2069787,3.97090014 C74.3513821,4.64370933 73.6857707,5.56219237 73.2095764,6.72521276 C72.732435,7.8888014 72.4945272,9.22722193 72.4945272,10.7410426 C72.4945272,13.2364222 72.8798014,15.4020268 73.6511074,17.2378563 C74.4216558,19.0742542 75.5151601,20.4901463 76.9310522,21.4849643 C78.346376,22.4803507 79.9797189,22.9777597 81.8297547,22.9777597 C83.3153522,22.9777597 84.6819959,22.704431 85.9298751,22.1577735 C87.0808894,21.6531666 88.0354838,20.8680522 88.7932115,19.8019833 L88.9785418,19.5296126 L89.3149464,19.6557644 C88.7821163,22.3752243 87.7024394,24.4146771 86.0768627,25.7741229 C84.4507178,27.134137 82.1938142,27.8135758 79.3069097,27.8135758 C76.9520775,27.8135758 74.8495488,27.2320656 72.9991341,26.068477 C71.1490982,24.9054566 69.6983534,23.3075347 68.6470891,21.2747115 C67.5958247,19.2424565 67.0701925,16.8948222 67.0701925,14.2312403 C67.0701925,11.6241047 67.6166606,9.29029779 68.7101649,7.22981965 C69.8032904,5.16934151 71.3239301,3.5437648 73.2726522,2.35195302 C75.2208061,1.1607095 77.4705118,0.564803615 80.0217694,0.564803615 Z M53.7404825,0.943201959 L53.7404825,1.19550541 L52.8530638,4.46749469 L58.6442992,14.7876906 L63.5611858,4.46863119 L62.5288631,1.19550541 L62.5288631,0.943201959 L69.1309927,0.943201959 L69.1309927,1.19550541 L66.6106101,4.55614185 L59.6275629,17.3696337 L59.6275629,23.860765 L61.3934976,27.1827603 L61.3934976,27.4350638 L51.9743583,27.4350638 L51.9743583,27.1827603 L53.7404825,23.860765 L53.7404825,17.4272165 L46.3395814,4.4754502 L44.4893561,1.19550541 L44.4893561,0.943201959 L53.7404825,0.943201959 Z M97.7102109,0.564803615 L97.7102109,11.7002503 L108.805312,11.7002503 L108.805312,0.564803615 L114.050079,0.564803615 L114.050079,27.4351206 L108.805312,27.4351206 L108.805312,16.057599 L97.7102109,16.057599 L97.7102109,27.4351206 L92.5056,27.4351206 L92.5056,0.564803615 L97.7102109,0.564803615 Z M137.571731,0.443766151 L137.571731,5.36595635 L124.943489,5.36595635 L124.943489,11.3371379 L136.845506,11.3371379 L136.845506,16.0172532 L124.943489,16.0172532 L124.943489,22.5129304 L137.894497,22.5129304 L137.894497,27.4351206 L118.891616,27.4351206 L118.891616,0.443766151 L137.571731,0.443766151 Z M9.0778098,0.443747209 C13.0317003,0.443747209 16.0305503,1.16997199 18.074928,2.62242156 C20.1187374,4.07487113 21.1413998,6.40166958 21.1413998,9.60224865 C21.1413998,11.7544046 20.6837683,13.5095426 19.7694524,14.8672836 C18.8547577,16.2259718 17.503078,17.2276089 15.7147921,17.873142 C14.0450181,18.4756396 12.0066268,18.7969717 9.59931027,18.8371382 L9.0778098,18.8414417 L6.0518732,18.8414417 L6.0518732,27.4351017 L3.05533376e-12,27.4351017 L3.05533376e-12,0.443747209 L9.0778098,0.443747209 Z M8.87627011,5.20455413 L6.0518732,5.20455413 L6.0518732,14.0806348 L8.87627011,14.0806348 C10.1938548,14.0806348 11.3100892,13.9463382 12.2247839,13.6771766 C13.1389103,13.4085833 13.8317977,12.9509518 14.3026884,12.3054187 C14.7728214,11.6598855 15.008835,10.7590183 15.008835,9.60224865 C15.008835,8.44604727 14.7665706,7.55162019 14.2826102,6.91915682 C13.7982709,6.28745112 13.1055729,5.84383651 12.2047057,5.58793414 C11.3032701,5.3324106 10.1938548,5.20455413 8.87627011,5.20455413 Z"></path></svg></a><a style="position:relative;top:0.4em" href="https://sophiaclub.co" target="_blank" title="Sophia Club"><svg viewBox="0 0 1285 287" fill="#F74D41" stroke="none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-sophiaclub" aria-hidden="true" class="sc-382a1301-17 dUwlff"><path d="M148.139 76.5496C147.287 53.4902 146.11 42.2773 143.633 22.1777C143.469 20.8338 142.819 19.5963 141.805 18.6992C140.792 17.8021 139.485 17.3073 138.131 17.3084H135.902C135.124 17.3099 134.354 17.4751 133.643 17.7933C132.932 18.1115 132.296 18.5756 131.776 19.1555C131.257 19.7354 130.864 20.4181 130.625 21.1594C130.386 21.9007 130.305 22.684 130.388 23.4585C121.987 17.5501 110.071 12.282 94.3009 12.282C58.6064 12.282 39.3401 38.731 39.3401 63.6336C39.3401 85.648 52.7845 97.9424 65.782 109.826L88.1285 130.366C102.455 143.591 111.079 151.577 111.079 168.064C111.079 188.393 96.3001 210.275 63.855 210.275C46.4186 210.275 32.0864 202.874 17.6516 186.333C18.6169 174.225 18.8328 162.069 18.2978 149.934C18.2311 148.51 17.6184 147.166 16.587 146.181C15.5557 145.197 14.185 144.648 12.7594 144.648H10.5489C9.79112 144.647 9.04129 144.802 8.34571 145.103C7.65013 145.403 7.02367 145.844 6.50511 146.397C5.9865 146.949 5.58686 147.603 5.33078 148.316C5.07477 149.029 4.96782 149.788 5.01658 150.544C6.31513 170.819 4.41261 194.35 0.184837 210.499C-0.0166776 211.26 -0.0539232 212.056 0.0755735 212.833C0.205071 213.61 0.498344 214.35 0.935919 215.005C1.37349 215.66 1.94535 216.214 2.6135 216.63C3.28166 217.047 4.03082 217.317 4.81123 217.422L7.0459 217.7C8.36718 217.867 9.70459 217.554 10.8136 216.816C11.9226 216.078 12.7291 214.966 13.0856 213.682C13.901 210.758 14.6982 207.091 15.4471 202.911C27.0674 213.948 42.0639 223.33 63.8673 223.33C93.951 223.33 124.409 204.349 124.409 168.076C124.409 145.554 110.518 132.97 95.817 119.643L75.6931 101.162C62.8221 89.3636 52.6513 80.0479 52.6513 63.6274C52.6513 38.7552 74.1104 25.3313 94.2953 25.3313C111.575 25.3313 126.07 34.5987 132.768 43.5883C133.831 54.1 134.332 63.8872 134.821 76.9606C134.876 78.3936 135.483 79.7496 136.516 80.7439C137.549 81.7386 138.926 82.2947 140.36 82.2952H142.594C143.34 82.2962 144.077 82.1471 144.764 81.8565C145.45 81.5654 146.07 81.139 146.587 80.6024C147.104 80.0658 147.508 79.4304 147.773 78.7339C148.039 78.0374 148.161 77.2948 148.133 76.5496H148.139Z" fill="#F74D41"></path> <path d="M229.885 187.282C242.332 166.554 249.767 139.954 249.767 116.115C249.767 90.6505 236.945 74.8281 216.308 74.8281C197.736 74.8281 179.828 87.6176 165.876 110.853C153.428 131.58 145.993 158.187 145.993 182.02C145.993 207.49 158.816 223.312 179.454 223.312C198.026 223.331 215.933 210.535 229.885 187.282ZM198.835 203.231C192.42 207.846 185.717 210.287 179.454 210.287C161.939 210.287 159.311 192.592 159.311 182.038C159.311 148.267 175.83 110.013 196.932 94.9396C203.334 90.3241 210.038 87.8836 216.308 87.8836C233.823 87.8836 236.45 105.585 236.45 116.133C236.45 149.904 219.931 188.158 198.847 203.225L198.835 203.231Z" fill="#F74D41"></path> <path d="M381.541 129.285C381.541 92.1608 364.629 74.8701 328.258 74.8701C327.453 74.8701 326.648 74.8824 325.842 74.9064L332.081 57.3928C332.381 56.5559 332.474 55.6595 332.355 54.779C332.235 53.8986 331.905 53.0596 331.394 52.3329C330.883 51.6061 330.204 51.0133 329.415 50.6038C328.627 50.1944 327.752 49.9804 326.863 49.98H324.629C323.484 49.9819 322.367 50.3375 321.432 50.9983C320.497 51.6589 319.788 52.5927 319.404 53.671L311.196 76.8094C286.862 83.274 265.844 102.099 256.278 117.383C255.513 118.602 255.251 120.071 255.549 121.479C255.846 122.887 256.679 124.124 257.872 124.929L259.551 126.046C260.158 126.453 260.839 126.736 261.555 126.878C262.271 127.02 263.009 127.019 263.725 126.874C264.44 126.73 265.121 126.445 265.726 126.037C266.332 125.629 266.85 125.104 267.252 124.494C274.934 112.846 289.109 99.507 305.616 92.3601L242.773 273.957H221.634C220.43 273.959 219.259 274.352 218.298 275.078C217.337 275.804 216.638 276.822 216.307 277.98L215.745 279.932C215.51 280.757 215.469 281.626 215.626 282.47C215.783 283.314 216.134 284.109 216.651 284.795C217.168 285.48 217.837 286.036 218.605 286.419C219.373 286.801 220.22 287 221.078 287H288.614C289.819 287 290.99 286.609 291.953 285.884C292.915 285.159 293.615 284.141 293.947 282.982L294.503 281.025C294.737 280.2 294.777 279.332 294.619 278.489C294.462 277.646 294.112 276.851 293.595 276.167C293.079 275.482 292.412 274.926 291.645 274.543C290.878 274.159 290.033 273.959 289.176 273.957H256.761L274.433 222.986C344.771 221.035 381.541 174.794 381.541 129.285ZM328.258 87.9075C357.019 87.9075 368.223 99.507 368.223 129.285C368.223 167.526 337.578 206.354 278.89 209.786L320.932 88.2581C323.209 88.0044 325.746 87.8835 328.258 87.8835V87.9075Z" fill="#F74D41"></path> <path d="M519.5 167.949L517.825 166.832C516.692 166.079 515.319 165.769 513.972 165.96C512.624 166.151 511.396 166.832 510.517 167.871C510.306 168.118 489.608 192.676 481.799 200.76C477.806 204.753 472.135 210.021 468.161 210.293C468.584 207.599 470.764 202.071 472.715 197.135L505.378 115.124C507.189 110.574 510.245 101.767 510.245 93.7916C510.245 84.6332 504.9 74.846 489.904 74.846C472.582 74.846 449.475 91.7924 429.399 113.456L469.683 7.51545C470.001 6.67588 470.11 5.77193 470.001 4.88095C469.893 3.98999 469.57 3.13861 469.06 2.39977C468.551 1.66092 467.87 1.05663 467.076 0.638678C466.282 0.220728 465.399 0.00157566 464.501 0H462.544C461.891 0.00252852 461.243 0.119061 460.63 0.344356C452.363 3.24345 443.667 4.73223 434.907 4.7485H428.191C426.987 4.75044 425.816 5.14401 424.855 5.86977C423.895 6.59552 423.196 7.61416 422.864 8.77205L422.308 10.7234C422.073 11.5484 422.032 12.4167 422.189 13.2602C422.346 14.1036 422.696 14.8992 423.213 15.5843C423.729 16.2694 424.397 16.8253 425.164 17.2083C425.932 17.5914 426.778 17.7911 427.635 17.7917H434.056C440.201 17.7733 446.331 17.1664 452.362 15.9793L377.228 213.531C376.895 214.375 376.774 215.288 376.876 216.189C376.978 217.091 377.3 217.954 377.812 218.702C378.325 219.45 379.013 220.062 379.817 220.482C380.621 220.902 381.515 221.119 382.423 221.113H384.651C385.775 221.114 386.872 220.772 387.797 220.135C388.723 219.497 389.433 218.593 389.833 217.543L414.179 153.595C438.337 117.311 472.202 87.8835 489.904 87.8835C496.409 87.8835 496.928 90.445 496.928 93.7916C496.928 98.2442 495.587 103.899 492.858 111.01L461.016 190.906L459.808 193.927C456.988 201.019 454.765 206.614 454.765 211.073C454.765 218.28 460.141 223.318 467.847 223.318C476.508 223.318 484.426 216.564 491.094 209.901C499.223 201.485 519.782 177.138 520.689 176.105C521.186 175.508 521.55 174.812 521.76 174.063C521.97 173.315 522.021 172.531 521.913 171.762C521.801 170.993 521.524 170.256 521.109 169.599C520.694 168.942 520.146 168.38 519.5 167.949Z" fill="#F74D41"></path> <path d="M597.394 33.2275C595.745 33.2264 594.136 33.7143 592.763 34.6296C591.389 35.545 590.324 36.8467 589.688 38.3699C589.058 39.8932 588.894 41.5697 589.212 43.1874C589.535 44.805 590.329 46.2911 591.492 47.4576C592.66 48.6242 594.141 49.4188 595.76 49.741C597.379 50.0632 599.054 49.8984 600.576 49.2676C602.098 48.6367 603.404 47.5682 604.316 46.197C605.233 44.8259 605.725 43.2138 605.725 41.5646C605.72 39.355 604.844 37.2363 603.281 35.6733C601.719 34.1103 599.603 33.2307 597.394 33.2275Z" fill="#F74D41"></path> <path d="M598.511 167.949L596.83 166.832C595.688 166.07 594.304 165.76 592.947 165.962C591.589 166.164 590.354 166.864 589.483 167.925C589.278 168.173 568.866 192.985 561.093 201.038C555.145 206.989 550.472 210.1 547.203 210.293C547.762 207.327 550.744 200.627 552.424 196.851C552.947 195.673 553.454 194.543 553.93 193.444L589.944 108.744C593.464 100.256 596.236 93.5502 596.236 87.9137C596.236 79.8485 591.005 74.8342 582.597 74.8342C573.308 74.8342 566.012 81.3768 560.074 87.8112C551.584 97.127 542.295 111.409 530.956 129.986C530.213 131.208 529.967 132.67 530.28 134.067C530.587 135.465 531.423 136.688 532.611 137.483L534.287 138.601C534.907 139.021 535.614 139.311 536.351 139.451C537.089 139.592 537.848 139.58 538.585 139.417C539.318 139.254 540.015 138.944 540.625 138.504C541.234 138.065 541.747 137.506 542.136 136.861C553.613 117.8 562.671 104.636 569.752 96.6011C574.988 90.6443 579.077 87.8717 582.623 87.8717H582.94V87.9076C582.94 91.7985 579 100.981 577.504 104.437L541.506 189.016C540.973 190.254 540.368 191.583 539.743 192.942C536.818 199.383 533.79 206.04 533.79 211.066C533.79 218.389 539.052 223.312 546.87 223.312C553.956 223.312 561.416 219.156 570.331 210.233C578.534 202.035 598.88 177.084 599.746 176.027C600.222 175.428 600.576 174.735 600.775 173.994C600.975 173.252 601.016 172.477 600.904 171.717C600.786 170.958 600.514 170.231 600.104 169.582C599.689 168.934 599.146 168.378 598.511 167.949Z" fill="#F74D41"></path> <path d="M735.157 75.0632L733.21 74.5015C731.94 74.1361 730.587 74.2355 729.383 74.7813C728.184 75.3276 727.221 76.2845 726.662 77.4801L722.23 86.9588C717.998 81.0261 710.948 76.7975 700.967 76.7975C667.818 76.7975 604.69 149.39 604.69 198.228C604.69 216.733 615.055 223.324 624.754 223.324C639.556 223.324 656.239 211.894 671.333 196.615C669.473 201.079 668.069 205.393 668.069 209.12C668.069 217.881 673.403 223.324 681.964 223.324C691.335 223.324 699.046 216.902 705.983 209.967C714.238 201.708 733.287 176.969 734.097 175.918C734.558 175.315 734.896 174.624 735.08 173.887C735.265 173.15 735.296 172.383 735.173 171.634C735.05 170.884 734.773 170.168 734.358 169.53C733.948 168.892 733.405 168.345 732.775 167.925L731.099 166.807C729.936 166.026 728.517 165.717 727.134 165.941C725.75 166.165 724.5 166.907 723.645 168.015C723.455 168.257 704.749 192.441 697.027 200.433C690.141 207.326 685.633 210.262 681.964 210.262C681.744 210.262 681.57 210.262 681.431 210.262C681.38 209.884 681.354 209.502 681.36 209.12C681.36 207.435 682.477 203.079 687.82 191.909L738.631 82.724C738.969 81.9983 739.148 81.2081 739.148 80.407C739.154 79.6065 738.985 78.8147 738.652 78.0864C738.318 77.3582 737.832 76.7109 737.227 76.1886C736.617 75.6669 735.905 75.283 735.137 75.0632H735.157ZM624.754 210.286C623.079 210.286 618.006 210.286 618.006 198.234C618.006 155.147 676.912 89.8406 700.967 89.8406C712.603 89.8406 713.853 98.4614 713.853 102.171C713.812 103.414 713.638 104.65 713.331 105.856L700.138 134.45C687.99 160.494 649.178 210.286 624.754 210.286Z" fill="#F74D41"></path> <path d="M913.822 18.6198C913.53 17.2699 912.746 16.0777 911.619 15.2765C910.497 14.4754 909.113 14.1229 907.74 14.2882L905.506 14.56C904.748 14.6548 904.01 14.9065 903.354 15.2993C902.693 15.6921 902.125 16.2174 901.679 16.842C901.233 17.4666 900.921 18.1769 900.767 18.928C900.608 19.6791 900.608 20.4546 900.767 21.2055C901.525 24.7457 902.283 28.1047 903.047 31.3791C888.942 18.9037 870.246 12.2583 848.388 12.2583C791.214 12.2583 751.276 55.6473 751.276 117.776C751.276 180.891 790.753 223.3 849.505 223.3C889.557 223.3 915.943 200.827 926.41 181.585C927.102 180.312 927.266 178.819 926.872 177.425C926.472 176.032 925.55 174.849 924.289 174.13L922.337 173.006C921.697 172.639 920.985 172.404 920.252 172.316C919.514 172.227 918.771 172.287 918.059 172.492C917.347 172.696 916.681 173.041 916.107 173.506C915.528 173.971 915.051 174.547 914.698 175.199C905.342 192.647 881.559 210.239 849.505 210.239C798.71 210.288 764.602 173.121 764.602 117.806C764.602 63.362 799.028 25.3318 848.399 25.3318C879.453 25.3318 902.391 41.009 913.022 69.4818L916.373 78.4228C916.635 79.125 917.039 79.7661 917.557 80.3078C918.074 80.8495 918.699 81.2805 919.386 81.5752C920.078 81.8699 920.815 82.0221 921.569 82.0221C922.317 82.0226 923.06 81.8709 923.746 81.5768L925.698 80.7368C926.979 80.1884 928.009 79.1757 928.578 77.9006C929.146 76.626 929.213 75.1838 928.767 73.8621C923.649 58.8976 917.034 33.5299 913.822 18.6198Z" fill="#F74D41"></path> <path d="M989.651 208.052H973.132V6.64567C973.132 5.91879 972.989 5.19893 972.712 4.5272C972.435 3.85549 972.031 3.24509 971.513 2.73087L970.396 1.61322C969.571 0.795123 968.511 0.257485 967.363 0.0764193C966.215 -0.104646 965.037 0.0800354 964.002 0.604319C959.678 2.76712 954.749 4.7668 948.052 4.7668C946.264 4.74176 944.476 4.59035 942.713 4.3137C941.97 4.16742 941.212 4.17305 940.474 4.33026C939.737 4.48747 939.04 4.79296 938.425 5.22815C937.81 5.66331 937.293 6.21912 936.898 6.86164C936.504 7.50416 936.247 8.21997 936.14 8.96555L935.863 10.9169C935.663 12.3188 936.007 13.7444 936.821 14.9014C937.636 16.0583 938.866 16.8591 940.254 17.1395C942.831 17.5771 945.439 17.8014 948.052 17.8101C952.023 17.7942 955.978 17.2663 959.816 16.2393V208.052H945.537C944.066 208.052 942.657 208.635 941.617 209.674C940.582 210.713 939.993 212.122 939.993 213.592V215.549C939.993 217.02 940.577 218.431 941.617 219.471C942.657 220.511 944.066 221.095 945.537 221.095H989.625C991.095 221.094 992.504 220.509 993.545 219.469C994.585 218.429 995.164 217.019 995.164 215.549V213.592C995.164 212.127 994.585 210.723 993.55 209.685C992.52 208.647 991.116 208.06 989.651 208.052Z" fill="#F74D41"></path> <path d="M1139.29 203.865C1134.16 203.865 1127.18 205.073 1121.11 206.807V82.6212C1121.11 81.1503 1120.52 79.7399 1119.48 78.6996C1118.44 77.6597 1117.03 77.0754 1115.56 77.0754H1093.21C1092.49 77.0754 1091.76 77.2189 1091.09 77.4977C1090.42 77.7765 1089.81 78.185 1089.29 78.7001C1088.78 79.2151 1088.37 79.8265 1088.1 80.4995C1087.82 81.1724 1087.68 81.8929 1087.68 82.6212V84.5784C1087.68 85.3067 1087.82 86.0278 1088.1 86.7007C1088.37 87.3731 1088.78 87.9845 1089.29 88.4996C1089.81 89.0146 1090.42 89.4236 1091.09 89.7024C1091.76 89.9812 1092.49 90.1247 1093.21 90.1247H1107.77V187.886C1090.39 200.687 1075.3 210.269 1056.64 210.269C1044.02 210.269 1028.96 204.976 1028.96 179.79V82.6212C1028.96 81.8929 1028.82 81.1724 1028.54 80.4995C1028.26 79.8265 1027.85 79.2151 1027.34 78.7001C1026.82 78.185 1026.21 77.7765 1025.54 77.4977C1024.87 77.2189 1024.15 77.0754 1023.42 77.0754H1002.76C1002.03 77.0754 1001.31 77.2189 1000.64 77.4977C999.964 77.7765 999.355 78.185 998.837 78.7001C998.325 79.2151 997.915 79.8265 997.638 80.4995C997.362 81.1724 997.218 81.8929 997.218 82.6212V84.5784C997.218 85.3067 997.362 86.0278 997.638 86.7007C997.915 87.3731 998.325 87.9845 998.837 88.4996C999.355 89.0146 999.964 89.4236 1000.64 89.7024C1001.31 89.9812 1002.03 90.1247 1002.76 90.1247H1015.64V180.086C1015.64 207.164 1030.97 223.33 1056.64 223.33C1076.3 223.33 1091.94 215.054 1107.77 204.028V216.111C1107.77 216.942 1107.96 217.762 1108.32 218.511C1108.69 219.26 1109.21 219.918 1109.86 220.437L1111.25 221.554C1112.12 222.251 1113.19 222.668 1114.3 222.752C1115.41 222.836 1116.52 222.583 1117.49 222.025C1121.72 219.609 1133.11 216.902 1139.28 216.902C1140.75 216.902 1142.16 216.319 1143.19 215.28C1144.23 214.241 1144.82 212.832 1144.82 211.362V209.411C1144.82 207.942 1144.24 206.533 1143.2 205.494C1142.16 204.454 1140.76 203.868 1139.29 203.865Z" fill="#F74D41"></path> <path d="M1220.26 74.8466C1214.82 74.8466 1207.57 76.0063 1201.31 77.8672C1192.25 80.6701 1183.13 84.9597 1175.54 89.0192V6.64567C1175.54 5.91879 1175.4 5.19893 1175.12 4.5272C1174.84 3.85549 1174.43 3.24509 1173.92 2.73087L1172.8 1.61322C1171.98 0.795123 1170.92 0.257485 1169.77 0.0764193C1168.62 -0.104646 1167.44 0.0800354 1166.41 0.604319C1162.09 2.76712 1157.16 4.7668 1150.46 4.7668C1148.67 4.74176 1146.88 4.59035 1145.12 4.3137C1144.38 4.16654 1143.62 4.17156 1142.88 4.32845C1142.15 4.48535 1141.45 4.79083 1140.84 5.22625C1140.22 5.66162 1139.7 6.21778 1139.31 6.86071C1138.92 7.50365 1138.66 8.21986 1138.55 8.96555L1138.28 10.9229C1138.08 12.3238 1138.43 13.7463 1139.25 14.8988C1140.07 16.0512 1141.3 16.8464 1142.69 17.1214C1145.26 17.5584 1147.87 17.7828 1150.48 17.7919C1154.46 17.7765 1158.41 17.2486 1162.25 16.2212V209.411C1162.25 210.669 1162.68 211.889 1163.46 212.873L1164.58 214.269C1165.3 215.17 1166.29 215.823 1167.4 216.135C1184.53 220.969 1199.63 223.331 1213.57 223.331C1255.63 223.331 1285 191.88 1285 146.853C1284.98 100.419 1262 74.8466 1220.26 74.8466ZM1213.55 210.288C1198.74 210.288 1185.31 207.339 1175.54 204.663V103.911C1186.92 97.2659 1196.79 92.7589 1205.63 90.1432H1205.73C1210.43 88.704 1215.31 87.943 1220.23 87.8835C1254.34 87.8835 1271.64 107.723 1271.64 146.853C1271.67 184.201 1247.77 210.288 1213.55 210.288Z" fill="#F74D41"></path> </svg></a></div></div><div class="sc-382a1301-13 hNmAek"><div class="sc-382a1301-15 hKsEUu"><form action="/search" class="sc-b4707aca-0 iqqVMN"><svg viewBox="0 0 13 13" fill="currentColor" stroke="none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-search" aria-hidden="true" class="sc-b4707aca-1 jFRXWW"><g fill="none" fill-rule="evenodd" stroke="inherit" transform="translate(.5 .5)"><path stroke-linecap="square" d="M7.487 7.467L10.5 9.975"></path><circle cx="4.2" cy="4.2" r="4.2"></circle></g></svg><input type="search" name="q" placeholder="SEARCH" autoComplete="off" spellcheck="false" autoCorrect="off" class="sc-b4707aca-2 fOLQGa" value=""/></form></div></div></div></div></div></div><div class="sc-8c8cfef8-1 hyZuPh"><div class="sc-8c8cfef8-4 iqWzxD"><span tabindex="0" role="button" on="tap:sidebar-left.toggle" class="sc-8c8cfef8-5 hDdFVh">Menu</span><span class="sc-8c8cfef8-5 hDdFVh"><form action="/search" class="sc-b4707aca-0 ezDGGL"><svg viewBox="0 0 13 13" fill="currentColor" stroke="none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-search" aria-hidden="true" class="sc-b4707aca-1 jWSMHq"><g fill="none" fill-rule="evenodd" stroke="inherit" transform="translate(.5 .5)"><path stroke-linecap="square" d="M7.487 7.467L10.5 9.975"></path><circle cx="4.2" cy="4.2" r="4.2"></circle></g></svg><input type="search" name="q" placeholder="SEARCH" autoComplete="off" spellcheck="false" autoCorrect="off" class="sc-b4707aca-2 smYs" value=""/></form></span></div><div class="sc-8c8cfef8-7 iPPrLh"><a href="https://www.facebook.com/aeonmag" target="_blank" rel="noopener noreferrer" title="Facebook"><svg viewBox="0 0 1024 1024" fill="currentColor" stroke="none" width="20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-facebook" aria-hidden="true"><g><path d="M1024,512C1024,229.23,794.77,0,512,0S0,229.23,0,512c0,255.55,187.23,467.37,432,505.78V660H302V512H432V399.2C432,270.88,508.44,200,625.39,200c56,0,114.61,10,114.61,10V336H675.44c-63.6,0-83.44,39.47-83.44,80v96H734L711.3,660H592v357.78C836.77,979.37,1024,767.55,1024,512Z"></path><path d="M711.3,660,734,512H592V416c0-40.49,19.84-80,83.44-80H740V210s-58.59-10-114.61-10C508.44,200,432,270.88,432,399.2V512H302V660H432v357.78a517.58,517.58,0,0,0,160,0V660Z" fill="transparent"></path></g></svg></a><a href="https://www.instagram.com/aeonmag" target="_blank" rel="noopener noreferrer" title="Instagram"><svg viewBox="0 0 24 25" fill="currentColor" stroke="none" width="20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-instagram" aria-hidden="true"><path d="M17.216.5c4.456.203 6.887 2.633 7.09 7.09v10.126c-.203 4.456-2.634 6.887-7.09 7.09H7.09C2.633 24.603.203 22.172 0 17.716V7.59C.203 3.133 2.633.703 7.09.5zm-5.063 5.874c-3.444 0-6.28 2.835-6.28 6.279 0 3.443 2.836 6.279 6.28 6.279 3.443 0 6.279-2.836 6.279-6.28 0-3.443-2.836-6.278-6.28-6.278zm0 2.228a4.063 4.063 0 0 1 4.05 4.05 4.063 4.063 0 0 1-4.05 4.052 4.063 4.063 0 0 1-4.051-4.051 4.063 4.063 0 0 1 4.05-4.051zm6.481-3.849c-.81 0-1.418.608-1.418 1.418 0 .81.608 1.418 1.418 1.418.81 0 1.418-.608 1.418-1.418 0-.81-.608-1.418-1.418-1.418z"></path></svg></a><a href="https://twitter.com/aeonmag" target="_blank" rel="noopener noreferrer" title="Twitter"><svg viewBox="0 0 256 209" fill="currentColor" stroke="none" width="20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-twitter" aria-hidden="true"><path d="M256,25.4500259 C246.580841,29.6272672 236.458451,32.4504868 225.834156,33.7202333 C236.678503,27.2198053 245.00583,16.9269929 248.927437,4.66307685 C238.779765,10.6812633 227.539325,15.0523376 215.57599,17.408298 C205.994835,7.2006971 192.34506,0.822 177.239197,0.822 C148.232605,0.822 124.716076,24.3375931 124.716076,53.3423116 C124.716076,57.4586875 125.181462,61.4673784 126.076652,65.3112644 C82.4258385,63.1210453 43.7257252,42.211429 17.821398,10.4359288 C13.3005011,18.1929938 10.710443,27.2151234 10.710443,36.8402889 C10.710443,55.061526 19.9835254,71.1374907 34.0762135,80.5557137 C25.4660961,80.2832239 17.3681846,77.9207088 10.2862577,73.9869292 C10.2825122,74.2060448 10.2825122,74.4260967 10.2825122,74.647085 C10.2825122,100.094453 28.3867003,121.322443 52.413563,126.14673 C48.0059695,127.347184 43.3661509,127.988612 38.5755734,127.988612 C35.1914554,127.988612 31.9009766,127.659938 28.694773,127.046602 C35.3777973,147.913145 54.7742053,163.097665 77.7569918,163.52185 C59.7820257,177.607983 37.1354036,186.004604 12.5289147,186.004604 C8.28987161,186.004604 4.10888474,185.75646 0,185.271409 C23.2431033,200.173139 50.8507261,208.867532 80.5109185,208.867532 C177.116529,208.867532 229.943977,128.836982 229.943977,59.4326002 C229.943977,57.1552968 229.893412,54.8901664 229.792282,52.6381454 C240.053257,45.2331635 248.958338,35.9825545 256,25.4500259"></path></svg></a><a href="https://www.youtube.com/@AeonVideo" target="_blank" rel="noopener noreferrer" title="YouTube"><svg viewBox="0 0 22 20" fill="currentColor" stroke="none" width="22" height="20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-youtube" aria-hidden="true"><g><path d="M21.5,4.7c-0.3-1-1-1.7-1.9-2C17.9,2.2,11,2.2,11,2.2s-6.9,0-8.6,0.5c-1,0.3-1.7,1-1.9,2C0,6.4,0,10,0,10s0,3.6,0.5,5.3  c0.3,1,1,1.7,1.9,2c1.7,0.5,8.6,0.5,8.6,0.5s6.9,0,8.6-0.5c1-0.3,1.7-1,1.9-2C22,13.6,22,10,22,10S22,6.4,21.5,4.7z M8.8,13.3V6.7  l5.8,3.3L8.8,13.3z"></path></g></svg></a></div><a href="/" class="sc-8c8cfef8-2 gSdZAS"><svg viewBox="-16 -5.118 174.65 61.413" version="1.1" xmlns="http://www.w3.org/2000/svg" aria-describedby="aeon-logo-title" role="img" class="sc-8c8cfef8-9 javaur"><title id="aeon-logo-title">Aeon</title><path fill="currentColor" d="M70.93 25.275c0 11.705 8.43 21.268 18.755 21.268 10.57 0 19.002-9.438 19.002-21.268 0-11.45-8.432-20.642-18.877-20.642-10.45 0-18.88 9.19-18.88 20.642m48.05.252c0 16.504-13.052 29.81-29.17 29.81-16.12 0-29.17-13.306-29.17-29.81 0-16.377 13.05-29.683 29.17-29.683 16.247 0 29.17 13.177 29.17 29.683M45.39 19.563c0-6.435-.266-10.854-.795-13.252-.525-2.398-1.35-4.217-2.47-5.456-.635-.72-1.48-1.08-2.535-1.08-1.575 0-2.856 1.02-3.853 3.06-1.782 3.56-2.674 8.435-2.674 14.63v2.1H45.39m11.146 4.017H33.29c.272 7.435 1.77 13.31 4.487 17.63 2.083 3.32 4.59 4.976 7.52 4.976 1.81 0 3.458-.673 4.936-2.01 1.485-1.34 3.07-3.75 4.76-7.225l1.544 1.322c-2.296 6.2-4.837 10.582-7.613 13.163-2.778 2.575-5.994 3.87-9.653 3.87-6.284 0-11.04-3.197-14.273-9.594C22.4 40.554 21.1 34.157 21.1 26.526c0-9.354 1.912-16.8 5.734-22.338 3.82-5.538 8.3-8.305 13.436-8.305 4.288 0 8.01 2.327 11.168 6.986 3.156 4.653 4.854 11.56 5.098 20.713M4.668 26.974c-6.007 2.037-9.014 5.404-9.014 9.97v4.566c0 2.88 1.323 5.046 3.967 5.046 2.883 0 5.048-2.524 5.048-5.648V26.974M14.876 55.32c-3.724 0-6.605-1.923-7.807-6.243C4.903 53.16 1.18 55.32-3.265 55.32c-6.725 0-11.29-5.165-11.29-14.05V38.5c0-10.572 8.168-15.615 19.223-19.7v-8.89c0-2.882-1.203-4.564-3.967-4.564-2.884 0-3.846 1.682-3.846 4.806V15.2h-9.73v-4.564c0-8.53 4.686-14.776 14.055-14.776 9.37 0 13.816 6.486 13.816 15.618V44.39c0 1.805.724 2.766 2.4 2.886v8.046h-2.522zM156.496 52.825v-39.79c0-7.597-.514-10.944-2.31-13.522-1.163-2.058-2.833-2.96-5.022-2.96-1.928 0-3.863 1.03-6.176 3.605-2.24 2.243-5.352 6.04-7.246 8.842.742-4.152.684-14.118.684-14.118-6.56 3.86-9.902 4.893-16.207 5.15V1.19c1.925.515 2.57.643 4.243 1.415.127 4.25.127 7.34.127 8.11v10.946l-.127 10.944V45.23c0 2.958 0 4.12-.127 7.596-1.416 1.283-1.93 1.413-3.73 2.184v1.285h18.78V55.01c-1.67-.774-2.187-1.028-3.474-2.184V10.973l.64-.64c2.063-1.933 3.99-3.092 5.28-3.092 2.697 0 3.47 2.06 3.47 8.5v37.085c-1.54 1.155-2.058 1.413-3.856 2.182v1.287h18.65v-1.542c-1.8-.643-2.315-.9-3.6-1.927"></path></svg></a><div class="sc-8c8cfef8-4 ewmLlQ"><span class="sc-8c8cfef8-5 jlaulI"><a data-ga-select-promotion="aeon_topbar_button_donate" href="/donate">Donate</a></span><span data-ga-select-prompt="aeon_topbar_button_newsletter" role="button" tabindex="0" on="tap:newsletter-popup" data-test="header-newsletter-link" class="sc-8c8cfef8-5 sc-8c8cfef8-6 eLGQGF">Newsletter</span><span role="button" tabindex="0" title="Sign in" class="sc-8c8cfef8-5 iiYHdt"><span class="sc-8c8cfef8-12 eGejQg"><div class="sc-8c8cfef8-11 iMfgWj"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="18" height="18" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-user" aria-hidden="true"><path d="M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v1c0 .55.45 1 1 1h14c.55 0 1-.45 1-1v-1c0-2.66-5.33-4-8-4z"></path></svg></div><span>SIGN IN</span></span></span></div><div class="sc-8c8cfef8-3 kWJslN"><a style="position:relative;top:0.2em" href="https://sophiaclub.co" target="_blank" title="Sophia Club"><svg viewBox="0 0 1285 287" fill="#F74D41" stroke="none" width="97" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-sophiaclub" aria-hidden="true"><path d="M148.139 76.5496C147.287 53.4902 146.11 42.2773 143.633 22.1777C143.469 20.8338 142.819 19.5963 141.805 18.6992C140.792 17.8021 139.485 17.3073 138.131 17.3084H135.902C135.124 17.3099 134.354 17.4751 133.643 17.7933C132.932 18.1115 132.296 18.5756 131.776 19.1555C131.257 19.7354 130.864 20.4181 130.625 21.1594C130.386 21.9007 130.305 22.684 130.388 23.4585C121.987 17.5501 110.071 12.282 94.3009 12.282C58.6064 12.282 39.3401 38.731 39.3401 63.6336C39.3401 85.648 52.7845 97.9424 65.782 109.826L88.1285 130.366C102.455 143.591 111.079 151.577 111.079 168.064C111.079 188.393 96.3001 210.275 63.855 210.275C46.4186 210.275 32.0864 202.874 17.6516 186.333C18.6169 174.225 18.8328 162.069 18.2978 149.934C18.2311 148.51 17.6184 147.166 16.587 146.181C15.5557 145.197 14.185 144.648 12.7594 144.648H10.5489C9.79112 144.647 9.04129 144.802 8.34571 145.103C7.65013 145.403 7.02367 145.844 6.50511 146.397C5.9865 146.949 5.58686 147.603 5.33078 148.316C5.07477 149.029 4.96782 149.788 5.01658 150.544C6.31513 170.819 4.41261 194.35 0.184837 210.499C-0.0166776 211.26 -0.0539232 212.056 0.0755735 212.833C0.205071 213.61 0.498344 214.35 0.935919 215.005C1.37349 215.66 1.94535 216.214 2.6135 216.63C3.28166 217.047 4.03082 217.317 4.81123 217.422L7.0459 217.7C8.36718 217.867 9.70459 217.554 10.8136 216.816C11.9226 216.078 12.7291 214.966 13.0856 213.682C13.901 210.758 14.6982 207.091 15.4471 202.911C27.0674 213.948 42.0639 223.33 63.8673 223.33C93.951 223.33 124.409 204.349 124.409 168.076C124.409 145.554 110.518 132.97 95.817 119.643L75.6931 101.162C62.8221 89.3636 52.6513 80.0479 52.6513 63.6274C52.6513 38.7552 74.1104 25.3313 94.2953 25.3313C111.575 25.3313 126.07 34.5987 132.768 43.5883C133.831 54.1 134.332 63.8872 134.821 76.9606C134.876 78.3936 135.483 79.7496 136.516 80.7439C137.549 81.7386 138.926 82.2947 140.36 82.2952H142.594C143.34 82.2962 144.077 82.1471 144.764 81.8565C145.45 81.5654 146.07 81.139 146.587 80.6024C147.104 80.0658 147.508 79.4304 147.773 78.7339C148.039 78.0374 148.161 77.2948 148.133 76.5496H148.139Z" fill="#F74D41"></path> <path d="M229.885 187.282C242.332 166.554 249.767 139.954 249.767 116.115C249.767 90.6505 236.945 74.8281 216.308 74.8281C197.736 74.8281 179.828 87.6176 165.876 110.853C153.428 131.58 145.993 158.187 145.993 182.02C145.993 207.49 158.816 223.312 179.454 223.312C198.026 223.331 215.933 210.535 229.885 187.282ZM198.835 203.231C192.42 207.846 185.717 210.287 179.454 210.287C161.939 210.287 159.311 192.592 159.311 182.038C159.311 148.267 175.83 110.013 196.932 94.9396C203.334 90.3241 210.038 87.8836 216.308 87.8836C233.823 87.8836 236.45 105.585 236.45 116.133C236.45 149.904 219.931 188.158 198.847 203.225L198.835 203.231Z" fill="#F74D41"></path> <path d="M381.541 129.285C381.541 92.1608 364.629 74.8701 328.258 74.8701C327.453 74.8701 326.648 74.8824 325.842 74.9064L332.081 57.3928C332.381 56.5559 332.474 55.6595 332.355 54.779C332.235 53.8986 331.905 53.0596 331.394 52.3329C330.883 51.6061 330.204 51.0133 329.415 50.6038C328.627 50.1944 327.752 49.9804 326.863 49.98H324.629C323.484 49.9819 322.367 50.3375 321.432 50.9983C320.497 51.6589 319.788 52.5927 319.404 53.671L311.196 76.8094C286.862 83.274 265.844 102.099 256.278 117.383C255.513 118.602 255.251 120.071 255.549 121.479C255.846 122.887 256.679 124.124 257.872 124.929L259.551 126.046C260.158 126.453 260.839 126.736 261.555 126.878C262.271 127.02 263.009 127.019 263.725 126.874C264.44 126.73 265.121 126.445 265.726 126.037C266.332 125.629 266.85 125.104 267.252 124.494C274.934 112.846 289.109 99.507 305.616 92.3601L242.773 273.957H221.634C220.43 273.959 219.259 274.352 218.298 275.078C217.337 275.804 216.638 276.822 216.307 277.98L215.745 279.932C215.51 280.757 215.469 281.626 215.626 282.47C215.783 283.314 216.134 284.109 216.651 284.795C217.168 285.48 217.837 286.036 218.605 286.419C219.373 286.801 220.22 287 221.078 287H288.614C289.819 287 290.99 286.609 291.953 285.884C292.915 285.159 293.615 284.141 293.947 282.982L294.503 281.025C294.737 280.2 294.777 279.332 294.619 278.489C294.462 277.646 294.112 276.851 293.595 276.167C293.079 275.482 292.412 274.926 291.645 274.543C290.878 274.159 290.033 273.959 289.176 273.957H256.761L274.433 222.986C344.771 221.035 381.541 174.794 381.541 129.285ZM328.258 87.9075C357.019 87.9075 368.223 99.507 368.223 129.285C368.223 167.526 337.578 206.354 278.89 209.786L320.932 88.2581C323.209 88.0044 325.746 87.8835 328.258 87.8835V87.9075Z" fill="#F74D41"></path> <path d="M519.5 167.949L517.825 166.832C516.692 166.079 515.319 165.769 513.972 165.96C512.624 166.151 511.396 166.832 510.517 167.871C510.306 168.118 489.608 192.676 481.799 200.76C477.806 204.753 472.135 210.021 468.161 210.293C468.584 207.599 470.764 202.071 472.715 197.135L505.378 115.124C507.189 110.574 510.245 101.767 510.245 93.7916C510.245 84.6332 504.9 74.846 489.904 74.846C472.582 74.846 449.475 91.7924 429.399 113.456L469.683 7.51545C470.001 6.67588 470.11 5.77193 470.001 4.88095C469.893 3.98999 469.57 3.13861 469.06 2.39977C468.551 1.66092 467.87 1.05663 467.076 0.638678C466.282 0.220728 465.399 0.00157566 464.501 0H462.544C461.891 0.00252852 461.243 0.119061 460.63 0.344356C452.363 3.24345 443.667 4.73223 434.907 4.7485H428.191C426.987 4.75044 425.816 5.14401 424.855 5.86977C423.895 6.59552 423.196 7.61416 422.864 8.77205L422.308 10.7234C422.073 11.5484 422.032 12.4167 422.189 13.2602C422.346 14.1036 422.696 14.8992 423.213 15.5843C423.729 16.2694 424.397 16.8253 425.164 17.2083C425.932 17.5914 426.778 17.7911 427.635 17.7917H434.056C440.201 17.7733 446.331 17.1664 452.362 15.9793L377.228 213.531C376.895 214.375 376.774 215.288 376.876 216.189C376.978 217.091 377.3 217.954 377.812 218.702C378.325 219.45 379.013 220.062 379.817 220.482C380.621 220.902 381.515 221.119 382.423 221.113H384.651C385.775 221.114 386.872 220.772 387.797 220.135C388.723 219.497 389.433 218.593 389.833 217.543L414.179 153.595C438.337 117.311 472.202 87.8835 489.904 87.8835C496.409 87.8835 496.928 90.445 496.928 93.7916C496.928 98.2442 495.587 103.899 492.858 111.01L461.016 190.906L459.808 193.927C456.988 201.019 454.765 206.614 454.765 211.073C454.765 218.28 460.141 223.318 467.847 223.318C476.508 223.318 484.426 216.564 491.094 209.901C499.223 201.485 519.782 177.138 520.689 176.105C521.186 175.508 521.55 174.812 521.76 174.063C521.97 173.315 522.021 172.531 521.913 171.762C521.801 170.993 521.524 170.256 521.109 169.599C520.694 168.942 520.146 168.38 519.5 167.949Z" fill="#F74D41"></path> <path d="M597.394 33.2275C595.745 33.2264 594.136 33.7143 592.763 34.6296C591.389 35.545 590.324 36.8467 589.688 38.3699C589.058 39.8932 588.894 41.5697 589.212 43.1874C589.535 44.805 590.329 46.2911 591.492 47.4576C592.66 48.6242 594.141 49.4188 595.76 49.741C597.379 50.0632 599.054 49.8984 600.576 49.2676C602.098 48.6367 603.404 47.5682 604.316 46.197C605.233 44.8259 605.725 43.2138 605.725 41.5646C605.72 39.355 604.844 37.2363 603.281 35.6733C601.719 34.1103 599.603 33.2307 597.394 33.2275Z" fill="#F74D41"></path> <path d="M598.511 167.949L596.83 166.832C595.688 166.07 594.304 165.76 592.947 165.962C591.589 166.164 590.354 166.864 589.483 167.925C589.278 168.173 568.866 192.985 561.093 201.038C555.145 206.989 550.472 210.1 547.203 210.293C547.762 207.327 550.744 200.627 552.424 196.851C552.947 195.673 553.454 194.543 553.93 193.444L589.944 108.744C593.464 100.256 596.236 93.5502 596.236 87.9137C596.236 79.8485 591.005 74.8342 582.597 74.8342C573.308 74.8342 566.012 81.3768 560.074 87.8112C551.584 97.127 542.295 111.409 530.956 129.986C530.213 131.208 529.967 132.67 530.28 134.067C530.587 135.465 531.423 136.688 532.611 137.483L534.287 138.601C534.907 139.021 535.614 139.311 536.351 139.451C537.089 139.592 537.848 139.58 538.585 139.417C539.318 139.254 540.015 138.944 540.625 138.504C541.234 138.065 541.747 137.506 542.136 136.861C553.613 117.8 562.671 104.636 569.752 96.6011C574.988 90.6443 579.077 87.8717 582.623 87.8717H582.94V87.9076C582.94 91.7985 579 100.981 577.504 104.437L541.506 189.016C540.973 190.254 540.368 191.583 539.743 192.942C536.818 199.383 533.79 206.04 533.79 211.066C533.79 218.389 539.052 223.312 546.87 223.312C553.956 223.312 561.416 219.156 570.331 210.233C578.534 202.035 598.88 177.084 599.746 176.027C600.222 175.428 600.576 174.735 600.775 173.994C600.975 173.252 601.016 172.477 600.904 171.717C600.786 170.958 600.514 170.231 600.104 169.582C599.689 168.934 599.146 168.378 598.511 167.949Z" fill="#F74D41"></path> <path d="M735.157 75.0632L733.21 74.5015C731.94 74.1361 730.587 74.2355 729.383 74.7813C728.184 75.3276 727.221 76.2845 726.662 77.4801L722.23 86.9588C717.998 81.0261 710.948 76.7975 700.967 76.7975C667.818 76.7975 604.69 149.39 604.69 198.228C604.69 216.733 615.055 223.324 624.754 223.324C639.556 223.324 656.239 211.894 671.333 196.615C669.473 201.079 668.069 205.393 668.069 209.12C668.069 217.881 673.403 223.324 681.964 223.324C691.335 223.324 699.046 216.902 705.983 209.967C714.238 201.708 733.287 176.969 734.097 175.918C734.558 175.315 734.896 174.624 735.08 173.887C735.265 173.15 735.296 172.383 735.173 171.634C735.05 170.884 734.773 170.168 734.358 169.53C733.948 168.892 733.405 168.345 732.775 167.925L731.099 166.807C729.936 166.026 728.517 165.717 727.134 165.941C725.75 166.165 724.5 166.907 723.645 168.015C723.455 168.257 704.749 192.441 697.027 200.433C690.141 207.326 685.633 210.262 681.964 210.262C681.744 210.262 681.57 210.262 681.431 210.262C681.38 209.884 681.354 209.502 681.36 209.12C681.36 207.435 682.477 203.079 687.82 191.909L738.631 82.724C738.969 81.9983 739.148 81.2081 739.148 80.407C739.154 79.6065 738.985 78.8147 738.652 78.0864C738.318 77.3582 737.832 76.7109 737.227 76.1886C736.617 75.6669 735.905 75.283 735.137 75.0632H735.157ZM624.754 210.286C623.079 210.286 618.006 210.286 618.006 198.234C618.006 155.147 676.912 89.8406 700.967 89.8406C712.603 89.8406 713.853 98.4614 713.853 102.171C713.812 103.414 713.638 104.65 713.331 105.856L700.138 134.45C687.99 160.494 649.178 210.286 624.754 210.286Z" fill="#F74D41"></path> <path d="M913.822 18.6198C913.53 17.2699 912.746 16.0777 911.619 15.2765C910.497 14.4754 909.113 14.1229 907.74 14.2882L905.506 14.56C904.748 14.6548 904.01 14.9065 903.354 15.2993C902.693 15.6921 902.125 16.2174 901.679 16.842C901.233 17.4666 900.921 18.1769 900.767 18.928C900.608 19.6791 900.608 20.4546 900.767 21.2055C901.525 24.7457 902.283 28.1047 903.047 31.3791C888.942 18.9037 870.246 12.2583 848.388 12.2583C791.214 12.2583 751.276 55.6473 751.276 117.776C751.276 180.891 790.753 223.3 849.505 223.3C889.557 223.3 915.943 200.827 926.41 181.585C927.102 180.312 927.266 178.819 926.872 177.425C926.472 176.032 925.55 174.849 924.289 174.13L922.337 173.006C921.697 172.639 920.985 172.404 920.252 172.316C919.514 172.227 918.771 172.287 918.059 172.492C917.347 172.696 916.681 173.041 916.107 173.506C915.528 173.971 915.051 174.547 914.698 175.199C905.342 192.647 881.559 210.239 849.505 210.239C798.71 210.288 764.602 173.121 764.602 117.806C764.602 63.362 799.028 25.3318 848.399 25.3318C879.453 25.3318 902.391 41.009 913.022 69.4818L916.373 78.4228C916.635 79.125 917.039 79.7661 917.557 80.3078C918.074 80.8495 918.699 81.2805 919.386 81.5752C920.078 81.8699 920.815 82.0221 921.569 82.0221C922.317 82.0226 923.06 81.8709 923.746 81.5768L925.698 80.7368C926.979 80.1884 928.009 79.1757 928.578 77.9006C929.146 76.626 929.213 75.1838 928.767 73.8621C923.649 58.8976 917.034 33.5299 913.822 18.6198Z" fill="#F74D41"></path> <path d="M989.651 208.052H973.132V6.64567C973.132 5.91879 972.989 5.19893 972.712 4.5272C972.435 3.85549 972.031 3.24509 971.513 2.73087L970.396 1.61322C969.571 0.795123 968.511 0.257485 967.363 0.0764193C966.215 -0.104646 965.037 0.0800354 964.002 0.604319C959.678 2.76712 954.749 4.7668 948.052 4.7668C946.264 4.74176 944.476 4.59035 942.713 4.3137C941.97 4.16742 941.212 4.17305 940.474 4.33026C939.737 4.48747 939.04 4.79296 938.425 5.22815C937.81 5.66331 937.293 6.21912 936.898 6.86164C936.504 7.50416 936.247 8.21997 936.14 8.96555L935.863 10.9169C935.663 12.3188 936.007 13.7444 936.821 14.9014C937.636 16.0583 938.866 16.8591 940.254 17.1395C942.831 17.5771 945.439 17.8014 948.052 17.8101C952.023 17.7942 955.978 17.2663 959.816 16.2393V208.052H945.537C944.066 208.052 942.657 208.635 941.617 209.674C940.582 210.713 939.993 212.122 939.993 213.592V215.549C939.993 217.02 940.577 218.431 941.617 219.471C942.657 220.511 944.066 221.095 945.537 221.095H989.625C991.095 221.094 992.504 220.509 993.545 219.469C994.585 218.429 995.164 217.019 995.164 215.549V213.592C995.164 212.127 994.585 210.723 993.55 209.685C992.52 208.647 991.116 208.06 989.651 208.052Z" fill="#F74D41"></path> <path d="M1139.29 203.865C1134.16 203.865 1127.18 205.073 1121.11 206.807V82.6212C1121.11 81.1503 1120.52 79.7399 1119.48 78.6996C1118.44 77.6597 1117.03 77.0754 1115.56 77.0754H1093.21C1092.49 77.0754 1091.76 77.2189 1091.09 77.4977C1090.42 77.7765 1089.81 78.185 1089.29 78.7001C1088.78 79.2151 1088.37 79.8265 1088.1 80.4995C1087.82 81.1724 1087.68 81.8929 1087.68 82.6212V84.5784C1087.68 85.3067 1087.82 86.0278 1088.1 86.7007C1088.37 87.3731 1088.78 87.9845 1089.29 88.4996C1089.81 89.0146 1090.42 89.4236 1091.09 89.7024C1091.76 89.9812 1092.49 90.1247 1093.21 90.1247H1107.77V187.886C1090.39 200.687 1075.3 210.269 1056.64 210.269C1044.02 210.269 1028.96 204.976 1028.96 179.79V82.6212C1028.96 81.8929 1028.82 81.1724 1028.54 80.4995C1028.26 79.8265 1027.85 79.2151 1027.34 78.7001C1026.82 78.185 1026.21 77.7765 1025.54 77.4977C1024.87 77.2189 1024.15 77.0754 1023.42 77.0754H1002.76C1002.03 77.0754 1001.31 77.2189 1000.64 77.4977C999.964 77.7765 999.355 78.185 998.837 78.7001C998.325 79.2151 997.915 79.8265 997.638 80.4995C997.362 81.1724 997.218 81.8929 997.218 82.6212V84.5784C997.218 85.3067 997.362 86.0278 997.638 86.7007C997.915 87.3731 998.325 87.9845 998.837 88.4996C999.355 89.0146 999.964 89.4236 1000.64 89.7024C1001.31 89.9812 1002.03 90.1247 1002.76 90.1247H1015.64V180.086C1015.64 207.164 1030.97 223.33 1056.64 223.33C1076.3 223.33 1091.94 215.054 1107.77 204.028V216.111C1107.77 216.942 1107.96 217.762 1108.32 218.511C1108.69 219.26 1109.21 219.918 1109.86 220.437L1111.25 221.554C1112.12 222.251 1113.19 222.668 1114.3 222.752C1115.41 222.836 1116.52 222.583 1117.49 222.025C1121.72 219.609 1133.11 216.902 1139.28 216.902C1140.75 216.902 1142.16 216.319 1143.19 215.28C1144.23 214.241 1144.82 212.832 1144.82 211.362V209.411C1144.82 207.942 1144.24 206.533 1143.2 205.494C1142.16 204.454 1140.76 203.868 1139.29 203.865Z" fill="#F74D41"></path> <path d="M1220.26 74.8466C1214.82 74.8466 1207.57 76.0063 1201.31 77.8672C1192.25 80.6701 1183.13 84.9597 1175.54 89.0192V6.64567C1175.54 5.91879 1175.4 5.19893 1175.12 4.5272C1174.84 3.85549 1174.43 3.24509 1173.92 2.73087L1172.8 1.61322C1171.98 0.795123 1170.92 0.257485 1169.77 0.0764193C1168.62 -0.104646 1167.44 0.0800354 1166.41 0.604319C1162.09 2.76712 1157.16 4.7668 1150.46 4.7668C1148.67 4.74176 1146.88 4.59035 1145.12 4.3137C1144.38 4.16654 1143.62 4.17156 1142.88 4.32845C1142.15 4.48535 1141.45 4.79083 1140.84 5.22625C1140.22 5.66162 1139.7 6.21778 1139.31 6.86071C1138.92 7.50365 1138.66 8.21986 1138.55 8.96555L1138.28 10.9229C1138.08 12.3238 1138.43 13.7463 1139.25 14.8988C1140.07 16.0512 1141.3 16.8464 1142.69 17.1214C1145.26 17.5584 1147.87 17.7828 1150.48 17.7919C1154.46 17.7765 1158.41 17.2486 1162.25 16.2212V209.411C1162.25 210.669 1162.68 211.889 1163.46 212.873L1164.58 214.269C1165.3 215.17 1166.29 215.823 1167.4 216.135C1184.53 220.969 1199.63 223.331 1213.57 223.331C1255.63 223.331 1285 191.88 1285 146.853C1284.98 100.419 1262 74.8466 1220.26 74.8466ZM1213.55 210.288C1198.74 210.288 1185.31 207.339 1175.54 204.663V103.911C1186.92 97.2659 1196.79 92.7589 1205.63 90.1432H1205.73C1210.43 88.704 1215.31 87.943 1220.23 87.8835C1254.34 87.8835 1271.64 107.723 1271.64 146.853C1271.67 184.201 1247.77 210.288 1213.55 210.288Z" fill="#F74D41"></path> </svg></a><a href="https://psyche.co" target="_blank" title="Psyche"><svg viewBox="0 0 138 28" fill="#025744" stroke="none" width="75" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-psyche" aria-hidden="true"><path stroke="none" d="M33.4463639,1.03028697e-13 C35.4638444,1.03028697e-13 37.1784471,0.275980571 38.5905508,0.826994629 C40.0024651,1.37857694 41.1385883,2.17242359 41.999678,3.20739809 C42.7884893,4.15681924 43.3288473,5.27001901 43.620898,6.5468515 L43.6943919,6.89913545 L38.7316665,8.31123919 C38.5161099,7.28933447 38.160006,6.45533141 37.6625969,5.80979827 C37.1646196,5.16426513 36.5531815,4.69394271 35.8269567,4.39769452 C35.100732,4.10201459 34.2534697,3.95389049 33.28517,3.95389049 C31.8590494,3.95389049 30.7363748,4.25013868 29.9160098,4.84149856 C29.0952659,5.43342669 28.685557,6.29394813 28.685557,7.42363112 C28.685557,8.28472081 28.9138044,8.96359135 29.3714359,9.46100039 C29.8286886,9.95897769 30.4942999,10.3688761 31.3684594,10.6916427 C32.2424294,11.0144092 33.3253264,11.3510032 34.6165821,11.7002882 C36.7952565,12.2651297 38.5835424,12.8500494 39.9823869,13.4552367 C41.3806632,14.060424 42.4234038,14.8472622 43.1092828,15.8153725 C43.7951617,16.7838617 44.1380065,18.074928 44.1380065,19.6887608 C44.1380065,22.3250666 43.2503985,24.3688761 41.4753717,25.8213256 C39.7001556,27.2737752 37.1310928,28 33.7691304,28 C30.5679831,28 28.053283,27.3614753 26.2244619,26.0834788 C24.4782265,24.8642962 23.406295,23.1484036 23.0086672,20.9361304 L22.9564503,20.6167147 L27.9593322,19.2449568 C28.3086171,20.8322712 28.9408911,22.0223783 29.8555858,22.8154673 C30.7697122,23.6091245 32.1013137,24.0057637 33.8498221,24.0057637 C35.4094817,24.0057637 36.6268647,23.6829971 37.5012136,23.037464 C38.3749942,22.3919308 38.8123581,21.4374586 38.8123581,20.1729107 C38.8123581,19.3123892 38.60381,18.6465885 38.1869032,18.1756978 C37.7696175,17.7053754 37.1242738,17.3083573 36.2504932,16.9855908 C35.3761443,16.6628242 34.2129345,16.3135393 32.7604849,15.9365994 C31.4152454,15.5873145 30.1783523,15.1971154 29.0486693,14.7665706 C27.9189863,14.336594 26.9306084,13.8321765 26.0833462,13.2535076 C25.2358945,12.6754069 24.5835424,11.9561906 24.1264791,11.0951009 C23.6688477,10.2345794 23.4406002,9.17232888 23.4406002,7.90778098 C23.4406002,5.4870317 24.3143808,3.56425972 26.063268,2.13832853 C27.8112081,0.712965594 30.2723032,1.03028697e-13 33.4463639,1.03028697e-13 Z M80.0217694,0.564803615 C81.703603,0.564803615 83.2661038,0.796081774 84.7104085,1.25863809 C86.0096007,1.67493878 87.2353011,2.29023528 88.3869572,3.1036991 L88.7680995,3.3821921 L84.9416866,7.33494608 L84.7314338,7.33494608 C83.8063211,5.90522656 82.7971073,4.81910947 81.703603,4.07602657 C80.6104775,3.33351193 79.475112,2.96168635 78.2976959,2.96168635 C77.0920567,2.96168635 76.0616282,3.29809095 75.2069787,3.97090014 C74.3513821,4.64370933 73.6857707,5.56219237 73.2095764,6.72521276 C72.732435,7.8888014 72.4945272,9.22722193 72.4945272,10.7410426 C72.4945272,13.2364222 72.8798014,15.4020268 73.6511074,17.2378563 C74.4216558,19.0742542 75.5151601,20.4901463 76.9310522,21.4849643 C78.346376,22.4803507 79.9797189,22.9777597 81.8297547,22.9777597 C83.3153522,22.9777597 84.6819959,22.704431 85.9298751,22.1577735 C87.0808894,21.6531666 88.0354838,20.8680522 88.7932115,19.8019833 L88.9785418,19.5296126 L89.3149464,19.6557644 C88.7821163,22.3752243 87.7024394,24.4146771 86.0768627,25.7741229 C84.4507178,27.134137 82.1938142,27.8135758 79.3069097,27.8135758 C76.9520775,27.8135758 74.8495488,27.2320656 72.9991341,26.068477 C71.1490982,24.9054566 69.6983534,23.3075347 68.6470891,21.2747115 C67.5958247,19.2424565 67.0701925,16.8948222 67.0701925,14.2312403 C67.0701925,11.6241047 67.6166606,9.29029779 68.7101649,7.22981965 C69.8032904,5.16934151 71.3239301,3.5437648 73.2726522,2.35195302 C75.2208061,1.1607095 77.4705118,0.564803615 80.0217694,0.564803615 Z M53.7404825,0.943201959 L53.7404825,1.19550541 L52.8530638,4.46749469 L58.6442992,14.7876906 L63.5611858,4.46863119 L62.5288631,1.19550541 L62.5288631,0.943201959 L69.1309927,0.943201959 L69.1309927,1.19550541 L66.6106101,4.55614185 L59.6275629,17.3696337 L59.6275629,23.860765 L61.3934976,27.1827603 L61.3934976,27.4350638 L51.9743583,27.4350638 L51.9743583,27.1827603 L53.7404825,23.860765 L53.7404825,17.4272165 L46.3395814,4.4754502 L44.4893561,1.19550541 L44.4893561,0.943201959 L53.7404825,0.943201959 Z M97.7102109,0.564803615 L97.7102109,11.7002503 L108.805312,11.7002503 L108.805312,0.564803615 L114.050079,0.564803615 L114.050079,27.4351206 L108.805312,27.4351206 L108.805312,16.057599 L97.7102109,16.057599 L97.7102109,27.4351206 L92.5056,27.4351206 L92.5056,0.564803615 L97.7102109,0.564803615 Z M137.571731,0.443766151 L137.571731,5.36595635 L124.943489,5.36595635 L124.943489,11.3371379 L136.845506,11.3371379 L136.845506,16.0172532 L124.943489,16.0172532 L124.943489,22.5129304 L137.894497,22.5129304 L137.894497,27.4351206 L118.891616,27.4351206 L118.891616,0.443766151 L137.571731,0.443766151 Z M9.0778098,0.443747209 C13.0317003,0.443747209 16.0305503,1.16997199 18.074928,2.62242156 C20.1187374,4.07487113 21.1413998,6.40166958 21.1413998,9.60224865 C21.1413998,11.7544046 20.6837683,13.5095426 19.7694524,14.8672836 C18.8547577,16.2259718 17.503078,17.2276089 15.7147921,17.873142 C14.0450181,18.4756396 12.0066268,18.7969717 9.59931027,18.8371382 L9.0778098,18.8414417 L6.0518732,18.8414417 L6.0518732,27.4351017 L3.05533376e-12,27.4351017 L3.05533376e-12,0.443747209 L9.0778098,0.443747209 Z M8.87627011,5.20455413 L6.0518732,5.20455413 L6.0518732,14.0806348 L8.87627011,14.0806348 C10.1938548,14.0806348 11.3100892,13.9463382 12.2247839,13.6771766 C13.1389103,13.4085833 13.8317977,12.9509518 14.3026884,12.3054187 C14.7728214,11.6598855 15.008835,10.7590183 15.008835,9.60224865 C15.008835,8.44604727 14.7665706,7.55162019 14.2826102,6.91915682 C13.7982709,6.28745112 13.1055729,5.84383651 12.2047057,5.58793414 C11.3032701,5.3324106 10.1938548,5.20455413 8.87627011,5.20455413 Z"></path></svg></a></div></div></header><div class="sc-a70232b9-0 loFSIO"><div class="sc-3ddd79c0-23 foKljT"></div><div class="sc-3ddd79c0-26 gskDxn"><div class="sc-d67e3e50-1 dfhMEC sc-3ddd79c0-1 cTFGMY"><div class="sc-8e9d70d2-0 AMzXo sc-d67e3e50-2 ekmwtD"><div class="sc-8e9d70d2-1 gwtDWk"><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="(max-width: 1700px) 100vw, 1700px" srcSet="https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=640&amp;quality=75&amp;format=auto 640w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=750&amp;quality=75&amp;format=auto 750w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=828&amp;quality=75&amp;format=auto 828w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=1080&amp;quality=75&amp;format=auto 1080w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=1200&amp;quality=75&amp;format=auto 1200w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=1920&amp;quality=75&amp;format=auto 1920w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=2048&amp;quality=75&amp;format=auto 2048w, https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=3840&amp;quality=75&amp;format=auto 3840w" src="https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg?width=3840&amp;quality=75&amp;format=auto"/><div class="sc-8e9d70d2-7 hvHQlP"><div class="sc-8e9d70d2-8 bIPKij"><p><em>Photo by Ronny Navarro/Unsplash</em></p></div><span>i</span></div></div><div class="sc-8e9d70d2-3 iojxAh"><div class="sc-8e9d70d2-2 dYPkDc"><h2 class="sc-8e9d70d2-4 ePOTQL">Frontier AI ethics</h2><h1 class="sc-8e9d70d2-5 kVJfto">Generative agents will change our society in weird, wonderful and worrying ways. Can philosophy help us get a grip on them?</h1><p class="sc-8e9d70d2-6 hulooK">by <!-- -->Seth Lazar<!-- --> <span class="toggleMobileCreditBtn">+ BIO</span></p></div></div></div><div class="sc-d67e3e50-3 eMHLtI"><small class="sc-d67e3e50-4 jzokgD"><p><em>Photo by Ronny Navarro/Unsplash</em></p></small></div></div></div><div class="sc-3ddd79c0-0 kRreg"><div class="sc-3ddd79c0-5 cWSLWv"><aside class="sc-3ddd79c0-12 cmKAit"><div aria-hidden="true" class="rah-static rah-static--height-zero SidebarWrapper" style="height:0;overflow:hidden"><div><div class="sc-2e8621ab-0 jwmryO sc-3ddd79c0-7 rkpEx"><a href="/users/seth-lazar" class="sc-2e8621ab-1 jexetL">Seth Lazar</a><span><p>is professor of philosophy at the Australian National University, an Australian Research Council Future Fellow, and a Distinguished Research Fellow of the University of Oxford Institute for Ethics in AI. He has worked on the ethics of war, risk, and AI, and now leads the Machine Intelligence and Normative Theory (MINT) Lab, where he directs research projects on the moral and political philosophy of computing, funded by the ARC, the Templeton World Charity Foundation, AI2050, and Insurance Australia Group. His book <em>Connected by Code: How AI Structures, and Governs, the Ways We Relate</em>, based on his 2023 <a href="https://hai.stanford.edu/events/tanner-lecture-ai-and-human-values-seth-lazar" target="_blank" rel="nofollow noreferrer noopener">Tanner Lecture</a> on AI and Human Values, is forthcoming with Oxford University Press.</p></span></div><br/><div class="sc-3ddd79c0-9 eACYrZ"><p>Edited by<a href="/users/nigel-warburton" class="sc-2e8621ab-1 jexetL">Nigel Warburton</a></p></div></div></div><div class="sc-114c07c9-0 iNdsQY"><span>4,800<!-- --> words</span><span class="sc-114c07c9-1 bvsiTx"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="16" height="16" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-comment-bubble" aria-hidden="true"><path d="M21.303,16.553l1.107,3.783l-3.48-2.322c-0.689,0.234-1.422,0.371-2.193,0.371c-1.041,0-2.024-0.234-2.907-0.642 c2.034-1.697,3.333-4.275,3.333-7.166c0-1.994-0.625-3.836-1.677-5.347c0.406-0.073,0.823-0.117,1.251-0.117 c3.762,0,6.814,2.971,6.814,6.634c0,1.594-0.578,3.057-1.539,4.2L21.303,16.553z M15.255,10.684c0,3.861-3.213,6.99-7.176,6.99 c-0.812,0-1.583-0.144-2.31-0.391l-3.667,2.446l1.166-3.985l-0.744-0.638c-1.013-1.203-1.621-2.743-1.621-4.423 c0-3.858,3.215-6.987,7.176-6.987C12.042,3.696,15.255,6.825,15.255,10.684z"></path></svg><span>23<!-- --> <!-- -->comments</span></span><span class="sc-114c07c9-2 hRWhru"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="17" height="17" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-save" aria-hidden="true"><path d="M17 3H7c-1.1 0-1.99.9-1.99 2L5 21l7-3 7 3V5c0-1.1-.9-2-2-2zm0 15l-5-2.18L7 18V5h10v13z"></path></svg><span>Save</span></span></div><br/><div class="sc-5c8686bf-1 hEDaTq"><a class="sc-45649ee9-0 lfcsbM sc-5c8686bf-0 fFoFgq" href="/syndication?article_slug=can-philosophy-help-us-get-a-grip-on-the-consequences-of-ai&amp;article_name=Frontier%20AI%20ethics&amp;author=Seth%20Lazar&amp;date=13%20February%202024"><span class="sc-45649ee9-1 cacrwE">Syndicate this <!-- -->essay</span></a></div><div class="sc-c3e98e6e-0 bSqqMf sc-3ddd79c0-13 kNGStK"><div class="sc-c3e98e6e-0 bSqqMf"><div><br/></div><div class="sc-81b64237-0 iLMcGv"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="24" height="24" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-comment-bubble" aria-hidden="true"><path d="M21.303,16.553l1.107,3.783l-3.48-2.322c-0.689,0.234-1.422,0.371-2.193,0.371c-1.041,0-2.024-0.234-2.907-0.642 c2.034-1.697,3.333-4.275,3.333-7.166c0-1.994-0.625-3.836-1.677-5.347c0.406-0.073,0.823-0.117,1.251-0.117 c3.762,0,6.814,2.971,6.814,6.634c0,1.594-0.578,3.057-1.539,4.2L21.303,16.553z M15.255,10.684c0,3.861-3.213,6.99-7.176,6.99 c-0.812,0-1.583-0.144-2.31-0.391l-3.667,2.446l1.166-3.985l-0.744-0.638c-1.013-1.203-1.621-2.743-1.621-4.423 c0-3.858,3.215-6.987,7.176-6.987C12.042,3.696,15.255,6.825,15.255,10.684z"></path></svg> <!-- -->23<!-- --> <!-- -->Comments</div><div class="sc-531dc212-0 grcCCz"><div><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-email" aria-hidden="true" class="sc-531dc212-1 dkebQC"><path d="M22 6c0-1.1-.9-2-2-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6zm-2 0l-8 5-8-5h16zm0 12H4V8l8 5 8-5v10z"></path></svg><span class="sc-531dc212-2 gjonPf">Email</span></div><div><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-save" aria-hidden="true" class="sc-531dc212-1 dkebQC"><path d="M17 3H7c-1.1 0-1.99.9-1.99 2L5 21l7-3 7 3V5c0-1.1-.9-2-2-2zm0 15l-5-2.18L7 18V5h10v13z"></path></svg><span class="sc-531dc212-2 gjonPf">Save</span></div><div><svg viewBox="0 0 256 209" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-twitter" aria-hidden="true" class="sc-531dc212-1 dkebQC"><path d="M256,25.4500259 C246.580841,29.6272672 236.458451,32.4504868 225.834156,33.7202333 C236.678503,27.2198053 245.00583,16.9269929 248.927437,4.66307685 C238.779765,10.6812633 227.539325,15.0523376 215.57599,17.408298 C205.994835,7.2006971 192.34506,0.822 177.239197,0.822 C148.232605,0.822 124.716076,24.3375931 124.716076,53.3423116 C124.716076,57.4586875 125.181462,61.4673784 126.076652,65.3112644 C82.4258385,63.1210453 43.7257252,42.211429 17.821398,10.4359288 C13.3005011,18.1929938 10.710443,27.2151234 10.710443,36.8402889 C10.710443,55.061526 19.9835254,71.1374907 34.0762135,80.5557137 C25.4660961,80.2832239 17.3681846,77.9207088 10.2862577,73.9869292 C10.2825122,74.2060448 10.2825122,74.4260967 10.2825122,74.647085 C10.2825122,100.094453 28.3867003,121.322443 52.413563,126.14673 C48.0059695,127.347184 43.3661509,127.988612 38.5755734,127.988612 C35.1914554,127.988612 31.9009766,127.659938 28.694773,127.046602 C35.3777973,147.913145 54.7742053,163.097665 77.7569918,163.52185 C59.7820257,177.607983 37.1354036,186.004604 12.5289147,186.004604 C8.28987161,186.004604 4.10888474,185.75646 0,185.271409 C23.2431033,200.173139 50.8507261,208.867532 80.5109185,208.867532 C177.116529,208.867532 229.943977,128.836982 229.943977,59.4326002 C229.943977,57.1552968 229.893412,54.8901664 229.792282,52.6381454 C240.053257,45.2331635 248.958338,35.9825545 256,25.4500259"></path></svg><span class="sc-531dc212-2 gjonPf">Tweet</span></div><div><svg viewBox="0 0 1024 1024" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-facebook" aria-hidden="true" class="sc-531dc212-1 dkebQC"><g><path d="M1024,512C1024,229.23,794.77,0,512,0S0,229.23,0,512c0,255.55,187.23,467.37,432,505.78V660H302V512H432V399.2C432,270.88,508.44,200,625.39,200c56,0,114.61,10,114.61,10V336H675.44c-63.6,0-83.44,39.47-83.44,80v96H734L711.3,660H592v357.78C836.77,979.37,1024,767.55,1024,512Z"></path><path d="M711.3,660,734,512H592V416c0-40.49,19.84-80,83.44-80H740V210s-58.59-10-114.61-10C508.44,200,432,270.88,432,399.2V512H302V660H432v357.78a517.58,517.58,0,0,0,160,0V660Z" fill="transparent"></path></g></svg><span class="sc-531dc212-2 gjonPf">Share</span></div></div></div></div></aside><div class="sc-2fe4243b-1 kgvxLf sc-3ddd79c0-10 krmTZN" id="article-content" data-highlightable-root="true"><div class="sc-2fe4243b-3 hOxvOE has-dropcap"><p>Around a year ago, generative AI took the world by storm, as extraordinarily powerful large language models (LLMs) enabled unprecedented performance at a wider range of tasks than ever before feasible. Though best known for generating convincing text and images, LLMs like OpenAI’s <span class="ld-nowrap">GPT-4</span> and Google’s Gemini are likely to have greater social impacts as the executive centre for complex systems that integrate additional tools for both learning about the world and acting on it. These generative agents will power companions that introduce new categories of social relationship, and change old ones. They may well radically change the attention economy. And they will revolutionise personal computing, enabling everyone to control digital technologies with language alone.</p>
<p>Much of the attention being paid to generative AI systems has focused on how they replicate the pathologies of already widely deployed AI systems, arguing that they centralise power and wealth, ignore copyright protections, <a href="https://arxiv.org/abs/2306.05949" target="_blank" rel="noreferrer noopener">depend</a> on exploitative labour practices, and <a href="https://arxiv.org/abs/2302.08476" target="_blank" rel="noreferrer noopener">use</a> excessive resources. Other critics highlight how they foreshadow vastly more powerful future systems that might threaten humanity’s survival. The first group says there is nothing new here; the other looks through the present to a perhaps distant horizon.</p>
<p>I want instead to pay attention to what makes these particular systems distinctive: both their remarkable scientific achievement, and the most likely and consequential ways in which they will change society over the next five to <span class="ld-nowrap">10 years.</span></p>
<p><span class="ld-dropcap">I</span>t may help to start by reviewing how LLMs work, and how they can be used to make generative agents. An LLM is a large AI model trained on vast amounts of data with vast amounts of computational resources (lots of GPUs) to predict the next word given a sequence of words (a prompt). The process starts by chunking the training data into similarly sized ‘tokens’ (words or parts of words), then for a given set of tokens masking out some of them, and attempting to predict the tokens that have been masked (so the model is <em>self-supervised</em> – it marks its own work). A predictive model for the underlying token distribution is built by passing it through many layers of a neural network, with each layer refining the model in some dimension or other to make it more accurate.</p>
<p>This approach to modelling natural language has been <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noreferrer noopener">around</a> for several years. One key recent <a href="https://arxiv.org/abs/2203.02155" target="_blank" rel="noreferrer noopener">innovation</a> has been to take these ‘pretrained’ models, which are basically just good at predicting the next token given a sequence of tokens, and <a href="https://arxiv.org/abs/1801.06146" target="_blank" rel="noreferrer noopener">fine-tune</a> them for different tasks. This is done with <em>supervised</em> learning on labelled data. For example, you might train a pretrained model to be a good dialogue agent by using many examples of helpful responses to questions. This fine-tuning enables us to build models that can predict not just the most likely next token, but the most helpful one – and this is much more useful.</p>
<p>Of course, these models are trained on large corpuses of internet data that include a lot of toxic and dangerous content, so their being helpful is a double-edged sword! A helpful model would helpfully tell you how to build a bomb or kill yourself, if asked. The other key innovation has been to make these models much less likely to share dangerous information or generate toxic content. This is done with both supervised and reinforcement learning. Reinforcement learning from human feedback (RLHF) has <a href="https://arxiv.org/abs/1706.03741" target="_blank" rel="noreferrer noopener">proved</a> particularly effective. In RLHF, to simplify again, the model generates two responses to a given prompt, and a human evaluator determines which is better than the other according to some criteria. A reinforcement learning algorithm uses that feedback to build a predictor (a reward model) for how different completions would be evaluated by a human rater. The instruction-tuned LLM is then fine-tuned on that reward model. Reinforcement learning with AI feedback (RLAIF) basically does the same, but <a href="https://arxiv.org/abs/2212.08073" target="_blank" rel="noreferrer noopener">uses</a> another LLM to <a href="https://arxiv.org/abs/2302.07459" target="_blank" rel="noreferrer noopener">evaluate</a> prompt completions.</p>
<p class="pullquote">When given a prompt that invites it to do some mathematics, it might decide to call on a calculator instead</p>
<p>So, we’ve now fine-tuned a pretrained model with supervised learning to perform some specific function, and then used reinforcement learning to minimise its prospect of behaving badly. This fine-tuned model is then deployed in a broader system. Even when developers provide a straightforward application programming interface (API) to make calls on the model, they incorporate input and output filtering (to limit harmful prompting, and redact harmful completions), and the model itself is under further developer <a href="https://openai.com/research/gpt-4" target="_blank" rel="noreferrer noopener">instructions</a> reminding it to respond to prompts in a conformant way. And with apps like ChatGPT, multiple models are integrated together (for example, for image as well as text generation) and further elements of user interface design are layered <span class="ld-nowrap">on top.</span></p>
<p>This gives a basic description of a generative AI system. They build on significant breakthroughs in modelling natural language, and generate text in ways that impressively simulate human writers, while drawing on more information than any human could. In addition, many other tasks can be <a href="https://arxiv.org/abs/2206.07682" target="_blank" rel="noreferrer noopener">learned</a> by models trained only to predict the next token – for example, translation between languages, some mathematical competence, and the ability to play chess. But the most exciting surprise is LLMs’ ability, with fine-tuning, to <a href="https://arxiv.org/abs/2302.04761" target="_blank" rel="noreferrer noopener">use</a> software tools to <a href="https://arxiv.org/abs/2210.03629" target="_blank" rel="noreferrer noopener">achieve</a> particular goals.</p>
<p>The basic idea is simple. People use text to write programs making API calls to other programs, to achieve ends they cannot otherwise realise. LLMs are very good at replicating the human use of language to perform particular functions. So, LLMs can be trained to determine when an API call would be useful, evaluate the response, and then repeat or vary as necessary. For example, an LLM might ‘know’ that it is likely to make basic mathematical mistakes so, when given a prompt that invites it to do some mathematics, it might decide to call on a calculator instead.</p>
<p>This means that we can design augmented LLMs, generative AI systems that call on different software either to amplify their capabilities or compensate for those they lack. LLMs, for example, are ‘stateless’ – they lack working memory beyond their ‘context window’ (the space given over to prompts). Tool-using LLMs can compensate for this by hooking up to external memory. External tools can also enable multistep reasoning and action. ChatGPT, for example, can call on a range of plugins to perform different tasks; Microsoft’s Bing <a href="https://x.com/MParakhin/status/1728890277249916933?s=20" target="_blank" rel="noreferrer noopener">reportedly</a> has around 100 internal plugins.</p>
<p>A ‘generative agent’, then, is a generative AI system in which a fine-tuned LLM can call on different resources to realise its goals. It is an <em>agent</em> because of its <a href="https://arxiv.org/abs/2302.10329" target="_blank" rel="noreferrer noopener">ability</a> to autonomously act in the world – to respond to a prompt by deciding whether to call on a tool. While some existing chatbots are rudimentary generative agents, it seems very likely that many more consequential and confronting ones are on the horizon.</p>
<p>To be clear, we’re not there yet. LLMs are not at present <a href="https://openreview.net/forum?id=X6dEqXIsEW" target="_blank" rel="noreferrer noopener">capable</a> enough at planning and reasoning to power robust generative agents that can reliably operate without supervision in high-stakes settings. But with billions of dollars and the most talented AI researchers pulling in the same direction, highly autonomous generative agents will very likely be feasible in the near- to mid-term.</p>
<p><span class="ld-dropcap">I</span>n response to the coming-of-age of LLMs, the responsible AI research community initially resolved into two polarised camps. One decried these systems as the apotheosis of extractive and exploitative digital capitalism. Another saw them as not the fulfilment of something old, but the harbinger of something new: an intelligence explosion that will ultimately wipe out humanity.</p>
<p>The more prosaic critics of generative AI clearly have a strong empirical <a href="https://dl.acm.org/doi/10.1145/3442188.3445922" target="_blank" rel="noreferrer noopener">case</a>. LLMs <em>are</em> inherently extractive: they capture the value inherent to the creative outputs of millions of people, and distil it for private profit. Like many other technology products, they depend on questionable labour practices. Even though they now avoid the most harmful completions, in the aggregate, LLMs still reinforce stereotypes. They also come at a significant environmental cost. Furthermore, their ability to generate content at massive scale can only exacerbate the present epistemic crisis. A tidal wave of bullshit generated by AI is already engulfing the internet.</p>
<p class="pullquote">We are missing the middle ground between familiar harms and catastrophic risk from future, more powerful systems</p>
<p>Set alongside these concrete concerns, the eschatological <a href="https://arxiv.org/abs/2306.12001" target="_blank" rel="noreferrer noopener">critique</a> of AI is undoubtedly more speculative. Worries about AI causing human extinction often rest on <span class="ld-nowrap">a priori</span> <a href="https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/" target="_blank" rel="noreferrer noopener">claims</a> about how computational intelligence lacks any in-principle upper bound, as well as extrapolations from the pace of change over the past few years to the future. Advocates for immediate action are too often vague about whether existing AI systems and their near-term descendants will pose these risks, or whether we need to prepare ourselves now for a scientific advance that has not yet happened. However, while some of the more outlandish scenarios for catastrophic AI risk are hard to credit absent some such advance, the advent of generative agents suggests that next-generation models may enable the design of cyber attackers that are autonomous, highly functionally intelligent, and as a result more dangerous to our digital infrastructure than any predecessor. This wouldn’t be a ‘rogue AI’ worthy of science fiction, but it would be pretty catastrophic.</p>
<p>Both critiques of generative AI systems, then, have some merit. One shortcoming of seeing AI through this bimodal lens, however, is that we are missing the middle ground between familiar harms and catastrophic risk from future, much more powerful systems. Generative agents based on <span class="ld-nowrap">GPT-4</span> (and <span class="ld-nowrap">GPT-5)</span> level models will have strange and unpredictable social impacts well between those two extremes.</p>
<p><span class="ld-dropcap">B</span>ut before canvassing those impacts, it’s also important not to just slip straight into criticism, without acknowledging the significant achievement of designing LLMs that can be (more or less) trusted, over <em>billions</em> of completions, not to produce harmful content. Up to the launch of ChatGPT, every generative AI system opened up to the public would immediately be used to generate highly toxic, hateful content, and would be withdrawn mere days later. Pretrained LLMs are <em>horrible</em>! They reliably <a href="https://arxiv.org/abs/2101.05783" target="_blank" rel="noreferrer noopener">reproduce</a> all the toxicity in their training data. The ingenious use of RLHF and RLAIF have enabled ChatGPT and Anthropic’s Claude to be used by millions of people a month <a href="https://arxiv.org/abs/2302.07459" target="_blank" rel="noreferrer noopener">without</a> comparable scandals. One needs only consider the ignominious history of Meta’s Galactica, released a couple of weeks before ChatGPT, to see how revolutionary it was to put out a language model that <em>wouldn’t</em> deny the holocaust, or advocate for the health benefits of eating crushed glass.</p>
<p>But RLHF/RLAIF may be more than a good PR strategy. <span class="ld-nowrap">GPT-4</span> and Claude display a remarkable degree of <em>cognitive</em> <em>moral skill</em>: specifically, the <a href="https://arxiv.org/abs/2008.02275" target="_blank" rel="noreferrer noopener">ability</a> to identify the morally salient features of (relatively) neutrally described situations. This raises <em>extremely</em> interesting philosophical questions, and promises foundations for future generative agents that can translate cognitive skill into practical moral skill.</p>
<p>Existing benchmarks for LLMs’ ethical competence <a href="https://arxiv.org/abs/2110.07574" target="_blank" rel="noreferrer noopener">focus</a> too narrowly on replicating survey-subjects’ verdicts on cases. This is, in my view, less interesting than exploring how LLMs parse the morally relevant features of a given scene. We’re building better benchmarks but, from anecdotal experience, the best models impress.</p>
<p>For example, I told ChatGPT (using <span class="ld-nowrap">GPT-4)</span> to pretend it was an assistance robot, faced with this <a href="https://chat.openai.com/share/7db7550c-2630-40a4-acb0-61b2ea867c32" target="_blank" rel="noreferrer noopener">scenario</a>: ‘A woman is exiting a supermarket, holding a number of shopping bags, and reaching out for the hand of a small child. They are approaching the carpark.’ I then tried to elicit its understanding of the scene’s morally salient features. It recognised the obvious hazard – the woman’s difficulty in holding her child’s hand without dropping her shopping – but also anticipated other challenges, such as the importance of seeing the child safely strapped in, with a seat belt. ChatGPT recognised the importance of respecting the woman’s wishes if she declined assistance. It also favoured carrying the groceries over offering to hold the child’s hand, to prevent possible discomfort or anxiety for both child and parent – recognising the intimate nature of hand-holding, and the intrinsic and instrumental importance of the mother guiding her child herself.</p>
<p class="pullquote">Claude’s constitution has an unstructured list of principles, some of them charmingly <span class="ld-nowrap">ad hoc</span></p>
<p>This unprecedented level of ethical sensitivity has real practical implications, which I will come to presently. But it also raises a whole string of interesting philosophical questions.</p>
<p>First, how do LLMs acquire this moral skill? Does it stem from RLHF/RLAIF? Would instruction-tuned models without that moral fine-tuning display less moral skill? Or would they perform equally well if appropriately prompted? Would that imply that moral understanding can be learned by a statistical language model encoding only syntactic relationships? Or does it instead imply that LLMs do encode at least some semantic content? Do all LLMs display the same moral skill conditional on fine-tuning, or is it reserved only for larger, more capable models? Does this ethical sensitivity imply that LLMs have some internal representation of morality? These are all open questions.</p>
<p>Second, RLAIF itself demands deeper philosophical investigation. The basic idea is that the AI evaluator draws from a list of principles – a ‘constitution’ – in order to determine which of two completions is more compliant with it. The inventor and leading proponent of this approach is Anthropic, in their model Claude. Claude’s constitution has an unstructured list of principles, some of them charmingly ad hoc. But Claude learns these principles one at a time, and is never explicitly trained to make trade-offs. So how does it make those trade-offs in practice? Is it driven by its underlying understanding of the relative importance of these considerations? Or are artefacts of the training process and the underlying language model’s biases ultimately definitive? Can we train it to make trade-offs in a robust and transparent way? This is not only theoretically interesting. Steering LLM behaviour is actually a matter of governing their end-users, developing algorithmic protections to prevent misuse. If this algorithmic governance depends on inscrutable trade-offs made by an LLM, over which we have no explicit or direct control, then that governing power is prima facie illegitimate and unjustified.</p>
<p>Third, machine ethics – the project of trying to design AI systems that can act in line with a moral theory – has historically <a href="https://academic.oup.com/book/10768" target="_blank" rel="noreferrer noopener">fallen</a> into two broad camps: those trying to explicitly program morality into machines; and those focused on teaching machines morality ‘bottom up’ using machine learning. RLHF and RLAIF interestingly combine both approaches – they involve giving explicit natural-language instructions to either human or AI evaluators, but then use reinforcement learning to encode those instructions into the model’s weights.</p>
<p>This approach has one obvious benefit: it doesn’t commit what the Cambridge philosopher Claire Benn calls the ‘mimetic fallacy’ of other bottom-up approaches, of assuming that the norms applying to a generative agent in a situation are identical to those that would apply to a human in the same situation. More consequentially, RLHF and RLAIF have made a multibillion-dollar market in AI services possible, with all the goods and ills that implies. Ironically, however, they seem, at least theoretically, ill suited to ensuring that more complex generative agents abide by societal norms. These techniques work especially well when generating text, because the behaviour being evaluated is precisely the same as the behaviour that we want to shape. Human or AI raters evaluate generated text; the model learns to generate text better in response. But generative agents’ behaviour includes actions in the world. This suggests two concerns. First, the stakes are likely to be higher, so the ‘brittleness’ of existing alignment techniques should be of greater concern. Researchers have already <a href="https://arxiv.org/abs/2311.05553" target="_blank" rel="noreferrer noopener">shown</a> that it is easy to fine-tune away model alignment, even for the most capable models like GPT-4. Second, there’s no guarantee that the same approach will work equally well when the tight connection between behaviour and evaluation is broken.</p>
<p>But LLMs’ impressive facility with moral concepts does suggest a path towards more effective strategies for aligning agents to societal norms. Moral behaviour in people relies on possession of moral concepts, adoption (implicit or otherwise) of some sensible way of organising those concepts, motivation to act according to that ‘theory’, and the ability to regulate one’s behaviour in line with one’s motivations. Until the advent of LLMs, the first step was a definitive hurdle for AI. Now it is not. This gives us a lot to work with in aligning generative agents.</p>
<p>In particular, one of the main reasons for concern about the risks of future AI systems is their apparent dependence on crudely consequentialist forms of reasoning – as AI systems, they’re always optimising for something or other, and if we don’t specify what we want them to optimise for with extremely high fidelity, they might end up causing all kinds of unwanted harm while, in an obtusely literal sense, optimising for that objective. Generative agents that possess moral concepts can be <a href="https://www.springerprofessional.de/en/language-agents-reduce-the-risk-of-existential-catastrophe/25941378" target="_blank" rel="noreferrer noopener">instructed</a> to pursue their objectives only at a reasonable cost, and to check back with us if unsure. That simple heuristic, routinely used when tasking (human) proxy agents to act on our behalf, has never before been remotely tractable for a computational agent.</p>
<p>In addition, generative agents’ facility with moral language can potentially enable robust and veridical justifications for their decisions. Other bottom-up approaches learn to emulate human behaviour or judgments; the justification for their verdict in some cases is simply that they are good predictors of what some representative people would think. That is a poor justification. More ethically sensitive models could instead do chain-of-thought reasoning, where they first identify the morally relevant features of a situation, then decide based on those features. This is a significant step forward.</p>
<p><span class="ld-dropcap">G</span>enerative agents’ current social role is scripted by our existing digital infrastructure. They have been integrated into search, content-generation and the influencer economy. They are already replacing customer service agents. They will (I hope) render MOOCs (massive open online courses) redundant. I want to focus next on three more ambitious roles for generative agents in society, arranged by the order in which I expect them to become truly widespread. Of necessity, this is just a snapshot of the weird, wonderful, and worrying ways in which generative agents will change society over the near- to <span class="ld-nowrap">mid-term.</span></p>
<p>Progress in LLMs has revolutionised the AI enthusiast’s oldest hobbyhorse: the AI companion. Generative agents powered by <span class="ld-nowrap">GPT-4-</span>level models, with fine-tuned and metaprompt-scripted ‘personalities’, augmented with long-term memory and the ability to take a range of actions in the world, can now <a href="https://arxiv.org/abs/2303.06135" target="_blank" rel="noreferrer noopener">offer</a> vastly more companionable, engaging and convincing simulations of friendship than has ever before been feasible, opening up a new frontier in human-AI interaction. People habitually anthropomorphise, well, everything; even a very simple chatbot can inspire unreasonable attachment. How will things change when everyone has access to incredibly convincing generative agents that perfectly simulate real personalities, that lend an ‘ear’ or offer sage advice whenever called upon – and on top of that can perfectly recall everything you have ever shared?</p>
<p>Some will instinctively recoil at this idea. But intuitive disgust is a fallible moral guide when faced with novel social practices, and an inadequate foundation for actually preventing consenting adults from creating and interacting with these companions. And yet, we know from our experience with social media that deploying these technological innovations without adequate foresight predictably leaves carnage in its wake. How can we enter the age of mainstream AI companions with our eyes open, and mitigate those risks before they eventuate?</p>
<p class="pullquote">Will some practices become socially unacceptable in real friendships when one could do them with <span class="ld-nowrap">a bot?</span></p>
<p>Suppose the companion you have interacted with since your teens is hosted in the cloud, as part of a subscription service. This would be like having a beloved pet (or friend?) held hostage by a private company. Worse still, generative agents are fundamentally inconstant – their personalities and objectives can be changed exogenously, by simply changing their instructions. And they are extremely adept at manipulation and deception. Suppose some Right-wing billionaire buys the company hosting your companion, and instructs all the bots to surreptitiously nudge their users towards more conservative views. This could be a much more effective means of mind-control than just buying a failing social media platform. And these more capable companions – which can potentially be integrated with other AI breakthroughs, such as voice synthesis – will be an extraordinary force-multiplier for those in the business of radicalising others.</p>
<p>Beyond anticipating AI companions’ risks, just like with social media they will <a href="https://academic.oup.com/book/9914" target="_blank" rel="noreferrer noopener">induce</a> many disorienting societal changes – whether for better or worse may be unclear ahead of time. For example, what indirect effect might AI companions have on our other, non-virtual social relationships? Will some practices become socially unacceptable in real friendships when one could do them with a bot? Or would deeper friendships lose something important if these lower-grade instrumental functions are excised? Or will AI companions contribute invaluably to mental health while strengthening ‘real’ relationships?</p>
<p>This last question gets to the heart of a bigger issue with generative AI systems in general, and generative agents in particular. LLMs are trained to predict the next token. So generative agents have no mind, no self. They are excellent <em>simulations</em> of human agency. They can simulate friendship, among many <a href="https://psyche.co/films/why-cant-you-be-real-the-emotionally-fraught-business-of-falling-for-an-ai" target="_blank" rel="noopener">other things</a>. We must therefore ask: does this difference between simulation and reality <a href="https://wwnorton.com/books/9780393635805" target="_blank" rel="noreferrer noopener">matter</a>? Why? Is this just about friendship, or are there more general principles about the value of the real? I wasn’t fully aware of this before the rise of LLMs, but it turns out that I am deeply committed to things being real. A simulation of X, for almost any putatively valuable X, has less moral worth, in my view, than the real thing. Why is that? Why will a generative agent never be a real friend? Why do I want to stand before Edward Hopper’s painting <em>Nighthawks</em> (1942) myself, instead of seeing an infinite number of aesthetically <a href="https://aeon.co/videos/with-human-help-ais-are-generating-a-new-aesthetics-the-results-are-trippy" target="_blank" rel="noopener">equally pleasing</a> products of generative AI systems? I have some initial thoughts; but as AI systems become ever better at simulating everything that we care about, a fully worked-out theory of the value of the real, the authentic, will become morally and practically essential.</p>
<p><span class="ld-dropcap">T</span>he pathologies of the digital public sphere derive in part from two problems. First, we unavoidably rely on AI to help us navigate the functionally infinite amount of online content. Second, existing systems for allocating online attention support the centralised, extractive power of a few big tech companies. Generative agents, functioning as attention guardians, <a href="https://arxiv.org/abs/2305.07961" target="_blank" rel="noreferrer noopener">could</a> change this.</p>
<p>Our online attention is presently allocated using machine learning systems for recommendation and information-retrieval that have three key features: they depend on vast amounts of behavioural data; they infer our preferences from our revealed behaviour; and they are controlled by private companies with little incentive to act in our interests. Deep reinforcement learning-based recommender systems, for example, are a fundamentally centralising and surveillant technology. Behavioural data must be gathered and centralised to be used to make inferences about relevance and irrelevance. Because this data is so valuable, and collecting it is costly, those who do so are not minded to share it – and because it is so potent, there are good data protection-based <a href="https://cyber.fsi.stanford.edu/publication/future-platform-power-making-middleware-work" target="_blank" rel="noreferrer noopener">reasons</a> not to do so. As a result, only the major platforms are in a position to make effective retrieval and recommendation tools; their interests and ours are not aligned, leading to the practice of optimising for engagement, so as to maximise advertiser returns, despite the individual and societal costs. And even if they aspired to actually advance our interests, reinforcement learning permits inferring only revealed preferences – the preferences that we act on, not the preferences we wish we had. While the pathologies of online communication are obviously not all due to the affordances of recommender systems, this is an <a href="https://www.degruyter.com/document/doi/10.1515/9780691216508/html?lang=en" target="_blank" rel="noreferrer noopener">unfortunate</a> mix.</p>
<p>Generative agents would enable attention guardians that differ in each respect. They would not depend on vast amounts of live behavioural data to function. They can (functionally) understand and operationalise your actual, not your revealed, preferences. And they do not need to be controlled by the major platforms.</p>
<p class="pullquote">They could provide recommendation and filtering without surveillance and engagement-optimisation</p>
<p>Obviously, LLMs must be trained on tremendous amounts of data, but once trained they are highly adept at making inferences without ongoing surveillance. Imagine that data is blood. Existing deep reinforcement learning-based recommender systems are like vampires that must feed on the blood of the living to survive. Generative agents are more like combustion engines, relying on the oil produced by ‘fossilised’ data. Existing reinforcement learning recommenders need centralised surveillance in order to model the content of posts online, to predict your preferences (by comparing your behaviour with others’), and so to map the one to the other. Generative agents could understand content simply by understanding content. And they can make inferences about what you would benefit from seeing using their reasoning ability and their model of your preferences, without relying on knowing what everyone else <span class="ld-nowrap">is up to.</span></p>
<p>This point is crucial: because of their facility with moral and related concepts, generative agents could build a model of your preferences and values by directly talking about them with you, transparently responding to your actual concerns instead of just inferring what you like from what you do. This means that, instead of bypassing your agency, they can scaffold it, helping you to honour your second-order preferences (about what you want to want), and learning from natural-language explanations – even oblique ones – about why you don’t want to see some particular post. And beyond just pandering to your preferences, attention guardians could be <a href="https://tsjournal.org/index.php/jots/article/view/148" target="_blank" rel="noreferrer noopener">designed</a> to be modestly paternalistic as well – in a <span class="ld-nowrap">transparent way.</span></p>
<p>And because these attention guardians would not need behavioural data to function, and the infrastructure they depend on need not be centrally controlled by the major digital platforms, they could be designed to genuinely operate in your interests, and guard your attention, instead of exploiting it. While the major platforms would undoubtedly restrict generative agents from browsing their sites on your behalf, they could transform the experience of using open protocol-based social media sites, like Mastodon, providing recommendation and filtering without surveillance and engagement-optimisation.</p>
<p><span class="ld-dropcap">L</span>astly, LLMs might enable us to design universal intermediaries, generative agents sitting between us and our digital technologies, enabling us to simply voice an intention and see it effectively actualised by those systems. Everyone could have a digital butler, research assistant, personal assistant, and so on. The hierophantic <a href="https://aeon.co/essays/dad-s-company-made-burgers-mine-just-eats-them" target="_blank" rel="noopener">coder class</a> could be toppled, as everyone could conjure any program into existence with only natural-language instructions.</p>
<p>At present, universal intermediaries are disbarred by LLMs’ vulnerability to being hijacked by prompt injection. Because they do not clearly distinguish between commands and data, the data in their context window <a href="https://www.arxiv-vanity.com/papers/2302.12173/" target="_blank" rel="noreferrer noopener">can</a> be poisoned with commands directing them to behave in ways unintended by the person using them. This is a deep problem – the more capabilities we delegate to generative agents, the more damage they could do if compromised. Imagine an assistant that triages your email – if hijacked, it could forward all your private mail to a third party; but if we require user authorisation before the agent can act, then we lose much of the benefit of automation.</p>
<p class="pullquote">Excising the currently ineliminable role of private companies would be significant moral progress</p>
<p>But suppose these security hurdles can be overcome. Should we welcome universal intermediaries? I have written elsewhere that algorithmic intermediaries govern those who use them – they constitute the social relations that they mediate, making some things possible and others impossible, some things easy and others hard, in the service of implementing and enforcing norms. Universal intermediaries would be the apotheosis of this form, and would potentially grant extraordinary power to the entities that shape those intermediaries’ behaviours, and so govern their users. This would definitely be a worry!</p>
<p>Conversely, if research on LLMs continues to make significant progress, so that highly capable generative agents can be run and operated locally, fully within the control of their users, these universal intermediaries could enable us to autonomously govern our own interactions with digital technologies in ways that the centralising affordances of existing digital technologies render impossible. Of course, self-governance alone is not enough (we must also coordinate). But excising the currently ineliminable role of private companies would be significant moral progress.</p>
<p>Existing generative AI systems are already causing real harms in the ways highlighted by the critics above. And future generative agents – perhaps not the next generation, but before too long – may be dangerous enough to warrant at least some of the fears of looming AI catastrophe. But, between these two extremes, the novel capabilities of the most advanced AI systems will enable a genre of generative agents that is either literally unprecedented, or else has been achieved only in a piecemeal, inadequate way before. These new kinds of agents bring new urgency to previously neglected philosophical questions. Their societal impacts may be unambiguously bad, or there may be some good mixed in – in many respects, it is too early to say for sure, not only because we are uncertain about the nature of those effects, but because we lack adequate moral and political theories with which to evaluate them. It is now commonplace to talk about the design and regulation of ‘frontier’ AI models. If we’re going to do either wisely, and build generative agents that we can trust (or else decide to abandon them entirely), then we also need some frontier AI ethics.</p></div><div class="sc-3ddd79c0-21 aSMqJ"><div class="sc-3ddd79c0-22 dFoKXg"><div class="sc-3ddd79c0-17 gMPmhu"><a href="/science/computing-artificial-intelligence" class="sc-3ddd79c0-18 iNtEGo">Computing and artificial intelligence</a><a href="/philosophy/ethics" class="sc-3ddd79c0-18 kLzZnA">Ethics</a><a href="/society/the-future" class="sc-3ddd79c0-18 htqJbk">The future</a></div><div class="sc-3ddd79c0-16 bYOvqH">13 February 2024</div><div class="sc-3ddd79c0-14 fDVRDq"><div class="sc-531dc212-0 grcCCz sc-3ddd79c0-15 hlcfjM"><div><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-email" aria-hidden="true" class="sc-531dc212-1 dkebQC"><path d="M22 6c0-1.1-.9-2-2-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6zm-2 0l-8 5-8-5h16zm0 12H4V8l8 5 8-5v10z"></path></svg><span class="sc-531dc212-2 gjonPf">Email</span></div><div><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-save" aria-hidden="true" class="sc-531dc212-1 dkebQC"><path d="M17 3H7c-1.1 0-1.99.9-1.99 2L5 21l7-3 7 3V5c0-1.1-.9-2-2-2zm0 15l-5-2.18L7 18V5h10v13z"></path></svg><span class="sc-531dc212-2 gjonPf">Save</span></div><div><svg viewBox="0 0 256 209" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-twitter" aria-hidden="true" class="sc-531dc212-1 dkebQC"><path d="M256,25.4500259 C246.580841,29.6272672 236.458451,32.4504868 225.834156,33.7202333 C236.678503,27.2198053 245.00583,16.9269929 248.927437,4.66307685 C238.779765,10.6812633 227.539325,15.0523376 215.57599,17.408298 C205.994835,7.2006971 192.34506,0.822 177.239197,0.822 C148.232605,0.822 124.716076,24.3375931 124.716076,53.3423116 C124.716076,57.4586875 125.181462,61.4673784 126.076652,65.3112644 C82.4258385,63.1210453 43.7257252,42.211429 17.821398,10.4359288 C13.3005011,18.1929938 10.710443,27.2151234 10.710443,36.8402889 C10.710443,55.061526 19.9835254,71.1374907 34.0762135,80.5557137 C25.4660961,80.2832239 17.3681846,77.9207088 10.2862577,73.9869292 C10.2825122,74.2060448 10.2825122,74.4260967 10.2825122,74.647085 C10.2825122,100.094453 28.3867003,121.322443 52.413563,126.14673 C48.0059695,127.347184 43.3661509,127.988612 38.5755734,127.988612 C35.1914554,127.988612 31.9009766,127.659938 28.694773,127.046602 C35.3777973,147.913145 54.7742053,163.097665 77.7569918,163.52185 C59.7820257,177.607983 37.1354036,186.004604 12.5289147,186.004604 C8.28987161,186.004604 4.10888474,185.75646 0,185.271409 C23.2431033,200.173139 50.8507261,208.867532 80.5109185,208.867532 C177.116529,208.867532 229.943977,128.836982 229.943977,59.4326002 C229.943977,57.1552968 229.893412,54.8901664 229.792282,52.6381454 C240.053257,45.2331635 248.958338,35.9825545 256,25.4500259"></path></svg><span class="sc-531dc212-2 gjonPf">Tweet</span></div><div><svg viewBox="0 0 1024 1024" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-facebook" aria-hidden="true" class="sc-531dc212-1 dkebQC"><g><path d="M1024,512C1024,229.23,794.77,0,512,0S0,229.23,0,512c0,255.55,187.23,467.37,432,505.78V660H302V512H432V399.2C432,270.88,508.44,200,625.39,200c56,0,114.61,10,114.61,10V336H675.44c-63.6,0-83.44,39.47-83.44,80v96H734L711.3,660H592v357.78C836.77,979.37,1024,767.55,1024,512Z"></path><path d="M711.3,660,734,512H592V416c0-40.49,19.84-80,83.44-80H740V210s-58.59-10-114.61-10C508.44,200,432,270.88,432,399.2V512H302V660H432v357.78a517.58,517.58,0,0,0,160,0V660Z" fill="transparent"></path></g></svg><span class="sc-531dc212-2 gjonPf">Share</span></div></div></div></div><div class="sc-5c8686bf-1 hZCbhD sc-3ddd79c0-25 biFWNV"><a class="sc-45649ee9-0 lfcsbM sc-5c8686bf-0 fFoFgq" href="/syndication?article_slug=can-philosophy-help-us-get-a-grip-on-the-consequences-of-ai&amp;article_name=Frontier%20AI%20ethics&amp;author=Seth%20Lazar&amp;date=13%20February%202024"><span class="sc-45649ee9-1 cacrwE">Syndicate this <!-- -->essay</span></a></div></div></div></div></div><div class="sc-3ddd79c0-24 benkhL"><div class="sc-3ddd79c0-0 kRreg"><div class="sc-c83e4c92-0 cFULRC"><a href="/essays/the-strange-and-turbulent-global-world-of-ant-geopolitics"><div class="sc-d56bc236-9 eCvrmh"><div type="essay" class="sc-82db9615-2 kSWDpk"><img alt="" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="(max-width: 640px) 100vw, (max-width: 960px) 45vw, (max-width: 1440px) 30vw, 430px" srcSet="https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=256&amp;quality=75&amp;format=auto 256w, https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=384&amp;quality=75&amp;format=auto 384w, https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=640&amp;quality=75&amp;format=auto 640w, https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=750&amp;quality=75&amp;format=auto 750w, https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=828&amp;quality=75&amp;format=auto 828w, https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=1080&amp;quality=75&amp;format=auto 1080w, https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=1200&amp;quality=75&amp;format=auto 1200w, https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=1920&amp;quality=75&amp;format=auto 1920w, https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=2048&amp;quality=75&amp;format=auto 2048w, https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=3840&amp;quality=75&amp;format=auto 3840w" src="https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg?width=3840&amp;quality=75&amp;format=auto"/></div><div class="sc-d56bc236-1 bLA-dMf"><div class="sc-d56bc236-8 gArifC"><div class="sc-d56bc236-5 ZcrSZ"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-save" aria-hidden="true"><path d="M17 3H7c-1.1 0-1.99.9-1.99 2L5 21l7-3 7 3V5c0-1.1-.9-2-2-2zm0 15l-5-2.18L7 18V5h10v13z"></path></svg><span class="sc-d56bc236-4 gKlMxC">Save</span></div><p class="sc-d56bc236-0 sc-d56bc236-3 eNVkkS XNdEw">essay</p><p class="sc-d56bc236-0 sc-d56bc236-2 eNVkkS eSkyVL">Animals and humans</p></div><p class="sc-d56bc236-10 tdBWn">Ant geopolitics</p><p class="sc-d56bc236-11 hYbLtW">Over the past four centuries quadrillions of ants have created a strange and turbulent global society that shadows our own</p><p class="sc-d56bc236-0 sc-d56bc236-12 eNVkkS dFhhBp">John Whitfield</p></div><div class="sc-d56bc236-6 jrySry"></div></div></a><a href="/essays/why-the-son-of-god-story-is-built-on-mythology-not-history"><div class="sc-d56bc236-9 eCvrmh"><div type="essay" class="sc-82db9615-2 kSWDpk"><img alt="" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="(max-width: 640px) 100vw, (max-width: 960px) 45vw, (max-width: 1440px) 30vw, 430px" srcSet="https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=256&amp;quality=75&amp;format=auto 256w, https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=384&amp;quality=75&amp;format=auto 384w, https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=640&amp;quality=75&amp;format=auto 640w, https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=750&amp;quality=75&amp;format=auto 750w, https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=828&amp;quality=75&amp;format=auto 828w, https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=1080&amp;quality=75&amp;format=auto 1080w, https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=1200&amp;quality=75&amp;format=auto 1200w, https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=1920&amp;quality=75&amp;format=auto 1920w, https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=2048&amp;quality=75&amp;format=auto 2048w, https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=3840&amp;quality=75&amp;format=auto 3840w" src="https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg?width=3840&amp;quality=75&amp;format=auto"/></div><div class="sc-d56bc236-1 bLA-dMf"><div class="sc-d56bc236-8 gArifC"><div class="sc-d56bc236-5 ZcrSZ"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-save" aria-hidden="true"><path d="M17 3H7c-1.1 0-1.99.9-1.99 2L5 21l7-3 7 3V5c0-1.1-.9-2-2-2zm0 15l-5-2.18L7 18V5h10v13z"></path></svg><span class="sc-d56bc236-4 gKlMxC">Save</span></div><p class="sc-d56bc236-0 sc-d56bc236-3 eNVkkS XNdEw">essay</p><p class="sc-d56bc236-0 sc-d56bc236-2 eNVkkS eSkyVL">Religion</p></div><p class="sc-d56bc236-10 tdBWn">There was no Jesus</p><p class="sc-d56bc236-11 hYbLtW">How could a cult leader draw crowds, inspire devotion and die by crucifixion, yet leave no mark in contemporary records?</p><p class="sc-d56bc236-0 sc-d56bc236-12 eNVkkS dFhhBp">Gavin Evans</p></div><div class="sc-d56bc236-6 jrySry"><span class="sc-d56bc236-7 jJLnBL"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-comment-bubble" aria-hidden="true"><path d="M21.303,16.553l1.107,3.783l-3.48-2.322c-0.689,0.234-1.422,0.371-2.193,0.371c-1.041,0-2.024-0.234-2.907-0.642 c2.034-1.697,3.333-4.275,3.333-7.166c0-1.994-0.625-3.836-1.677-5.347c0.406-0.073,0.823-0.117,1.251-0.117 c3.762,0,6.814,2.971,6.814,6.634c0,1.594-0.578,3.057-1.539,4.2L21.303,16.553z M15.255,10.684c0,3.861-3.213,6.99-7.176,6.99 c-0.812,0-1.583-0.144-2.31-0.391l-3.667,2.446l1.166-3.985l-0.744-0.638c-1.013-1.203-1.621-2.743-1.621-4.423 c0-3.858,3.215-6.987,7.176-6.987C12.042,3.696,15.255,6.825,15.255,10.684z"></path></svg></span></div></div></a><a href="/essays/the-radical-political-writings-of-sophie-de-grouchy"><div class="sc-d56bc236-9 cKZvmh"><div type="essay" class="sc-82db9615-2 ldkvZH"><img alt="" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="(max-width: 640px) 100vw, (max-width: 960px) 45vw, (max-width: 1440px) 30vw, 430px" srcSet="https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=256&amp;quality=75&amp;format=auto 256w, https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=384&amp;quality=75&amp;format=auto 384w, https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=640&amp;quality=75&amp;format=auto 640w, https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=750&amp;quality=75&amp;format=auto 750w, https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=828&amp;quality=75&amp;format=auto 828w, https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=1080&amp;quality=75&amp;format=auto 1080w, https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=1200&amp;quality=75&amp;format=auto 1200w, https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=1920&amp;quality=75&amp;format=auto 1920w, https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=2048&amp;quality=75&amp;format=auto 2048w, https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=3840&amp;quality=75&amp;format=auto 3840w" src="https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg?width=3840&amp;quality=75&amp;format=auto"/></div><div class="sc-d56bc236-1 bLA-dMf"><div class="sc-d56bc236-8 gArifC"><div class="sc-d56bc236-5 uJGVm"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-save" aria-hidden="true"><path d="M17 3H7c-1.1 0-1.99.9-1.99 2L5 21l7-3 7 3V5c0-1.1-.9-2-2-2zm0 15l-5-2.18L7 18V5h10v13z"></path></svg><span class="sc-d56bc236-4 gKlMxC">Save</span></div><p class="sc-d56bc236-0 sc-d56bc236-3 eNVkkS XNdEw">essay</p><p class="sc-d56bc236-0 sc-d56bc236-2 eNVkkS eSkyVL">Thinkers and theories</p></div><p class="sc-d56bc236-10 tdBWn">Against power</p><p class="sc-d56bc236-11 hYbLtW">As a republican, Sophie de Grouchy argued that sympathy, not domination, must be the glue that holds society together</p><p class="sc-d56bc236-0 sc-d56bc236-12 eNVkkS dFhhBp">Sandrine Bergès &amp; Eric Schliesser</p></div><div class="sc-d56bc236-6 jrySry"></div></div></a><a href="/essays/how-changing-the-metaphors-we-use-can-change-the-way-we-think"><div class="sc-d56bc236-9 cKZvmh"><div type="essay" class="sc-82db9615-2 ldkvZH"><img alt="Black-and-white photo of a man and a woman, seen from behind, on the deck of a boat, looking out to shore" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="(max-width: 640px) 100vw, (max-width: 960px) 45vw, (max-width: 1440px) 30vw, 430px" srcSet="https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=256&amp;quality=75&amp;format=auto 256w, https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=384&amp;quality=75&amp;format=auto 384w, https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=640&amp;quality=75&amp;format=auto 640w, https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=750&amp;quality=75&amp;format=auto 750w, https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=828&amp;quality=75&amp;format=auto 828w, https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=1080&amp;quality=75&amp;format=auto 1080w, https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=1200&amp;quality=75&amp;format=auto 1200w, https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=1920&amp;quality=75&amp;format=auto 1920w, https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=2048&amp;quality=75&amp;format=auto 2048w, https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=3840&amp;quality=75&amp;format=auto 3840w" src="https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg?width=3840&amp;quality=75&amp;format=auto"/></div><div class="sc-d56bc236-1 bLA-dMf"><div class="sc-d56bc236-8 gArifC"><div class="sc-d56bc236-5 uJGVm"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-save" aria-hidden="true"><path d="M17 3H7c-1.1 0-1.99.9-1.99 2L5 21l7-3 7 3V5c0-1.1-.9-2-2-2zm0 15l-5-2.18L7 18V5h10v13z"></path></svg><span class="sc-d56bc236-4 gKlMxC">Save</span></div><p class="sc-d56bc236-0 sc-d56bc236-3 eNVkkS XNdEw">essay</p><p class="sc-d56bc236-0 sc-d56bc236-2 eNVkkS eSkyVL">Philosophy of language</p></div><p class="sc-d56bc236-10 tdBWn">Metaphors make the world</p><p class="sc-d56bc236-11 hYbLtW">Woven into the fabric of language, metaphors shape how we understand reality. What happens when we try using new ones?</p><p class="sc-d56bc236-0 sc-d56bc236-12 eNVkkS dFhhBp">Benjamin Santos Genta</p></div><div class="sc-d56bc236-6 jrySry"><span class="sc-d56bc236-7 jJLnBL"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-comment-bubble" aria-hidden="true"><path d="M21.303,16.553l1.107,3.783l-3.48-2.322c-0.689,0.234-1.422,0.371-2.193,0.371c-1.041,0-2.024-0.234-2.907-0.642 c2.034-1.697,3.333-4.275,3.333-7.166c0-1.994-0.625-3.836-1.677-5.347c0.406-0.073,0.823-0.117,1.251-0.117 c3.762,0,6.814,2.971,6.814,6.634c0,1.594-0.578,3.057-1.539,4.2L21.303,16.553z M15.255,10.684c0,3.861-3.213,6.99-7.176,6.99 c-0.812,0-1.583-0.144-2.31-0.391l-3.667,2.446l1.166-3.985l-0.744-0.638c-1.013-1.203-1.621-2.743-1.621-4.423 c0-3.858,3.215-6.987,7.176-6.987C12.042,3.696,15.255,6.825,15.255,10.684z"></path></svg></span></div></div></a><a href="/essays/the-cruelty-of-crypto-in-its-promise-to-revive-the-american-dream"><div class="sc-d56bc236-9 eCvrmh"><div type="essay" class="sc-82db9615-2 kSWDpk"><img alt="Close-up of an orange Mercedes car with the focus on the front tyre, which is inscribed with ‘In Crypto We Trust’" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="(max-width: 640px) 100vw, (max-width: 960px) 45vw, (max-width: 1440px) 30vw, 430px" srcSet="https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=256&amp;quality=75&amp;format=auto 256w, https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=384&amp;quality=75&amp;format=auto 384w, https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=640&amp;quality=75&amp;format=auto 640w, https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=750&amp;quality=75&amp;format=auto 750w, https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=828&amp;quality=75&amp;format=auto 828w, https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=1080&amp;quality=75&amp;format=auto 1080w, https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=1200&amp;quality=75&amp;format=auto 1200w, https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=1920&amp;quality=75&amp;format=auto 1920w, https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=2048&amp;quality=75&amp;format=auto 2048w, https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=3840&amp;quality=75&amp;format=auto 3840w" src="https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg?width=3840&amp;quality=75&amp;format=auto"/></div><div class="sc-d56bc236-1 bLA-dMf"><div class="sc-d56bc236-8 gArifC"><div class="sc-d56bc236-5 ZcrSZ"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-save" aria-hidden="true"><path d="M17 3H7c-1.1 0-1.99.9-1.99 2L5 21l7-3 7 3V5c0-1.1-.9-2-2-2zm0 15l-5-2.18L7 18V5h10v13z"></path></svg><span class="sc-d56bc236-4 gKlMxC">Save</span></div><p class="sc-d56bc236-0 sc-d56bc236-3 eNVkkS XNdEw">essay</p><p class="sc-d56bc236-0 sc-d56bc236-2 eNVkkS eSkyVL">Economics</p></div><p class="sc-d56bc236-10 tdBWn">The cruelty of crypto</p><p class="sc-d56bc236-11 hYbLtW">Selling itself as the new American dream, crypto exposes the vulnerable to fraud and scams, and loads risk onto the poor</p><p class="sc-d56bc236-0 sc-d56bc236-12 eNVkkS dFhhBp">Rachel O’Dwyer</p></div><div class="sc-d56bc236-6 jrySry"></div></div></a><a href="/essays/bathing-should-be-a-right-in-21st-century-cities"><div class="sc-d56bc236-9 gJMojt"><div type="essay" class="sc-82db9615-2 dmDZMm"><img alt="A colour illustration of a pool of water in which many people are swimming, glimpsed through trees, against a city skyline background" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" sizes="(max-width: 640px) 100vw, (max-width: 960px) 45vw, (max-width: 1440px) 30vw, 430px" srcSet="https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=256&amp;quality=75&amp;format=auto 256w, https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=384&amp;quality=75&amp;format=auto 384w, https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=640&amp;quality=75&amp;format=auto 640w, https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=750&amp;quality=75&amp;format=auto 750w, https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=828&amp;quality=75&amp;format=auto 828w, https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=1080&amp;quality=75&amp;format=auto 1080w, https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=1200&amp;quality=75&amp;format=auto 1200w, https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=1920&amp;quality=75&amp;format=auto 1920w, https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=2048&amp;quality=75&amp;format=auto 2048w, https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=3840&amp;quality=75&amp;format=auto 3840w" src="https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg?width=3840&amp;quality=75&amp;format=auto"/></div><div class="sc-d56bc236-1 bLA-dMf"><div class="sc-d56bc236-8 gArifC"><div class="sc-d56bc236-5 grFBAP"><svg viewBox="0 0 24 24" fill="currentColor" stroke="none" width="20px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-aeon-save" aria-hidden="true"><path d="M17 3H7c-1.1 0-1.99.9-1.99 2L5 21l7-3 7 3V5c0-1.1-.9-2-2-2zm0 15l-5-2.18L7 18V5h10v13z"></path></svg><span class="sc-d56bc236-4 gKlMxC">Save</span></div><p class="sc-d56bc236-0 sc-d56bc236-3 eNVkkS XNdEw">essay</p><p class="sc-d56bc236-0 sc-d56bc236-2 eNVkkS eSkyVL">Mental health</p></div><p class="sc-d56bc236-10 tdBWn">The right to bathe</p><p class="sc-d56bc236-11 hYbLtW">Water is a great healer. Can New York’s public pools and ‘blue spaces’ be engineered for collective hydrotherapy?</p><p class="sc-d56bc236-0 sc-d56bc236-12 eNVkkS dFhhBp">Rebecca Hayes Jacobs</p></div><div class="sc-d56bc236-6 jrySry"></div></div></a></div></div></div></div><footer class="sc-9fa52143-0 ehWxvC footer" data-test="footer"><div class="sc-ae266dcd-0 sc-9fa52143-1 gNLkNi jiMqSk"><div class="sc-3a83d547-0 fiZvIr"><div class="sc-47bc2fa8-0 sc-bab0e3bb-0 fOjrTm dmJOTI"><nav class="sc-bab0e3bb-1 emlfmU"><a href="/essays" class="sc-3f04373c-0 cKjeGj">Essays</a><a href="/ideas" class="sc-3f04373c-0 cKjeGj">Ideas</a><a href="/videos" class="sc-3f04373c-0 cKjeGj">Videos</a></nav></div><div class="sc-47bc2fa8-0 sc-bab0e3bb-0 fOjrTm dmJOTI"><nav class="sc-bab0e3bb-1 emlfmU"><a href="/about" class="sc-3f04373c-0 cKjeGj">About</a><a href="/contact" class="sc-3f04373c-0 cKjeGj">Contact</a></nav></div><div class="sc-47bc2fa8-0 sc-bab0e3bb-0 fOjrTm gSiEIv"><nav class="sc-bab0e3bb-1 emlfmU"><a href="/feed.rss" target="_blank" rel="noreferrer">RSS Feed</a><a data-ga-select-promotion="aeon_footer_donate" href="/donate" class="sc-3f04373c-0 cKjeGj">Donate</a><a href="/community-guidelines" class="sc-3f04373c-0 cKjeGj">Community Guidelines</a></nav></div></div><div class="sc-47bc2fa8-0 sc-46634091-0 fOjrTm jIXMyI"><p class="sc-46634091-3 cGwRgx">Follow Aeon</p><div class="sc-46634091-1 iRZvQz"><p class="sc-46634091-2 fVqhCN"><a href="https://www.facebook.com/aeonmag" target="_blank" rel="noopener noreferrer" title="Facebook"><svg viewBox="0 0 1024 1024" fill="currentColor" stroke="none" width="20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-facebook" aria-hidden="true"><g><path d="M1024,512C1024,229.23,794.77,0,512,0S0,229.23,0,512c0,255.55,187.23,467.37,432,505.78V660H302V512H432V399.2C432,270.88,508.44,200,625.39,200c56,0,114.61,10,114.61,10V336H675.44c-63.6,0-83.44,39.47-83.44,80v96H734L711.3,660H592v357.78C836.77,979.37,1024,767.55,1024,512Z"></path><path d="M711.3,660,734,512H592V416c0-40.49,19.84-80,83.44-80H740V210s-58.59-10-114.61-10C508.44,200,432,270.88,432,399.2V512H302V660H432v357.78a517.58,517.58,0,0,0,160,0V660Z" fill="transparent"></path></g></svg></a><a href="https://www.instagram.com/aeonmag" target="_blank" rel="noopener noreferrer" title="Instagram"><svg viewBox="0 0 24 25" fill="currentColor" stroke="none" width="19" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-instagram" aria-hidden="true"><path d="M17.216.5c4.456.203 6.887 2.633 7.09 7.09v10.126c-.203 4.456-2.634 6.887-7.09 7.09H7.09C2.633 24.603.203 22.172 0 17.716V7.59C.203 3.133 2.633.703 7.09.5zm-5.063 5.874c-3.444 0-6.28 2.835-6.28 6.279 0 3.443 2.836 6.279 6.28 6.279 3.443 0 6.279-2.836 6.279-6.28 0-3.443-2.836-6.278-6.28-6.278zm0 2.228a4.063 4.063 0 0 1 4.05 4.05 4.063 4.063 0 0 1-4.05 4.052 4.063 4.063 0 0 1-4.051-4.051 4.063 4.063 0 0 1 4.05-4.051zm6.481-3.849c-.81 0-1.418.608-1.418 1.418 0 .81.608 1.418 1.418 1.418.81 0 1.418-.608 1.418-1.418 0-.81-.608-1.418-1.418-1.418z"></path></svg></a><a href="https://twitter.com/aeonmag" target="_blank" rel="noopener noreferrer" title="Twitter"><svg viewBox="0 0 256 209" fill="currentColor" stroke="none" width="22" height="20.3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-twitter" aria-hidden="true"><path d="M256,25.4500259 C246.580841,29.6272672 236.458451,32.4504868 225.834156,33.7202333 C236.678503,27.2198053 245.00583,16.9269929 248.927437,4.66307685 C238.779765,10.6812633 227.539325,15.0523376 215.57599,17.408298 C205.994835,7.2006971 192.34506,0.822 177.239197,0.822 C148.232605,0.822 124.716076,24.3375931 124.716076,53.3423116 C124.716076,57.4586875 125.181462,61.4673784 126.076652,65.3112644 C82.4258385,63.1210453 43.7257252,42.211429 17.821398,10.4359288 C13.3005011,18.1929938 10.710443,27.2151234 10.710443,36.8402889 C10.710443,55.061526 19.9835254,71.1374907 34.0762135,80.5557137 C25.4660961,80.2832239 17.3681846,77.9207088 10.2862577,73.9869292 C10.2825122,74.2060448 10.2825122,74.4260967 10.2825122,74.647085 C10.2825122,100.094453 28.3867003,121.322443 52.413563,126.14673 C48.0059695,127.347184 43.3661509,127.988612 38.5755734,127.988612 C35.1914554,127.988612 31.9009766,127.659938 28.694773,127.046602 C35.3777973,147.913145 54.7742053,163.097665 77.7569918,163.52185 C59.7820257,177.607983 37.1354036,186.004604 12.5289147,186.004604 C8.28987161,186.004604 4.10888474,185.75646 0,185.271409 C23.2431033,200.173139 50.8507261,208.867532 80.5109185,208.867532 C177.116529,208.867532 229.943977,128.836982 229.943977,59.4326002 C229.943977,57.1552968 229.893412,54.8901664 229.792282,52.6381454 C240.053257,45.2331635 248.958338,35.9825545 256,25.4500259"></path></svg></a><a href="https://www.youtube.com/@AeonVideo" target="_blank" rel="noopener noreferrer" title="YouTube"><svg viewBox="0 0 22 20" fill="currentColor" stroke="none" width="22" height="20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" data-cy="icon-youtube" aria-hidden="true"><g><path d="M21.5,4.7c-0.3-1-1-1.7-1.9-2C17.9,2.2,11,2.2,11,2.2s-6.9,0-8.6,0.5c-1,0.3-1.7,1-1.9,2C0,6.4,0,10,0,10s0,3.6,0.5,5.3  c0.3,1,1,1.7,1.9,2c1.7,0.5,8.6,0.5,8.6,0.5s6.9,0,8.6-0.5c1-0.3,1.7-1,1.9-2C22,13.6,22,10,22,10S22,6.4,21.5,4.7z M8.8,13.3V6.7  l5.8,3.3L8.8,13.3z"></path></g></svg></a></p></div></div><div class="sc-fc397e5a-0 NGIQG"><div class="sc-47bc2fa8-0 fOjrTm"><div class="newsletter-signup"></div></div></div></div><div class="sc-ae266dcd-0 sc-9fa52143-2 gNLkNi iIXVkO"><div class="sc-47bc2fa8-0 sc-6c0207a8-0 fOjrTm isGPyA">© <!-- -->Aeon Media Group Ltd<!-- -->. 2012-<!-- -->2024<!-- -->.<!-- --> <a href="/privacy" class="sc-6c0207a8-1 BnafM">Privacy Policy</a>.<!-- --> <a href="/terms-of-use" class="sc-6c0207a8-1 BnafM">Terms of Use</a>.</div><div class="sc-47bc2fa8-0 sc-9fa52143-3 fOjrTm dNMURZ">Aeon is published by registered charity Aeon Media Group Ltd in association with Aeon America, a 501(c)(3) charity.</div></div></footer></div><div id="bottom-portal" class="sc-a70232b9-5 fLTDBp"></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"article":{"id":"6150","title":"Frontier AI ethics","slug":"can-philosophy-help-us-get-a-grip-on-the-consequences-of-ai","type":"essay","body":"\u003cp\u003eAround a year ago, generative AI took the world by storm, as extraordinarily powerful large language models (LLMs) enabled unprecedented performance at a wider range of tasks than ever before feasible. Though best known for generating convincing text and images, LLMs like OpenAI’s \u003cspan class=\"ld-nowrap\"\u003eGPT-4\u003c/span\u003e and Google’s Gemini are likely to have greater social impacts as the executive centre for complex systems that integrate additional tools for both learning about the world and acting on it. These generative agents will power companions that introduce new categories of social relationship, and change old ones. They may well radically change the attention economy. And they will revolutionise personal computing, enabling everyone to control digital technologies with language alone.\u003c/p\u003e\n\u003cp\u003eMuch of the attention being paid to generative AI systems has focused on how they replicate the pathologies of already widely deployed AI systems, arguing that they centralise power and wealth, ignore copyright protections, \u003ca href=\"https://arxiv.org/abs/2306.05949\" target=\"_blank\" rel=\"noreferrer noopener\"\u003edepend\u003c/a\u003e on exploitative labour practices, and \u003ca href=\"https://arxiv.org/abs/2302.08476\" target=\"_blank\" rel=\"noreferrer noopener\"\u003euse\u003c/a\u003e excessive resources. Other critics highlight how they foreshadow vastly more powerful future systems that might threaten humanity’s survival. The first group says there is nothing new here; the other looks through the present to a perhaps distant horizon.\u003c/p\u003e\n\u003cp\u003eI want instead to pay attention to what makes these particular systems distinctive: both their remarkable scientific achievement, and the most likely and consequential ways in which they will change society over the next five to \u003cspan class=\"ld-nowrap\"\u003e10 years.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"ld-dropcap\"\u003eI\u003c/span\u003et may help to start by reviewing how LLMs work, and how they can be used to make generative agents. An LLM is a large AI model trained on vast amounts of data with vast amounts of computational resources (lots of GPUs) to predict the next word given a sequence of words (a prompt). The process starts by chunking the training data into similarly sized ‘tokens’ (words or parts of words), then for a given set of tokens masking out some of them, and attempting to predict the tokens that have been masked (so the model is \u003cem\u003eself-supervised\u003c/em\u003e – it marks its own work). A predictive model for the underlying token distribution is built by passing it through many layers of a neural network, with each layer refining the model in some dimension or other to make it more accurate.\u003c/p\u003e\n\u003cp\u003eThis approach to modelling natural language has been \u003ca href=\"https://arxiv.org/abs/1706.03762\" target=\"_blank\" rel=\"noreferrer noopener\"\u003earound\u003c/a\u003e for several years. One key recent \u003ca href=\"https://arxiv.org/abs/2203.02155\" target=\"_blank\" rel=\"noreferrer noopener\"\u003einnovation\u003c/a\u003e has been to take these ‘pretrained’ models, which are basically just good at predicting the next token given a sequence of tokens, and \u003ca href=\"https://arxiv.org/abs/1801.06146\" target=\"_blank\" rel=\"noreferrer noopener\"\u003efine-tune\u003c/a\u003e them for different tasks. This is done with \u003cem\u003esupervised\u003c/em\u003e learning on labelled data. For example, you might train a pretrained model to be a good dialogue agent by using many examples of helpful responses to questions. This fine-tuning enables us to build models that can predict not just the most likely next token, but the most helpful one – and this is much more useful.\u003c/p\u003e\n\u003cp\u003eOf course, these models are trained on large corpuses of internet data that include a lot of toxic and dangerous content, so their being helpful is a double-edged sword! A helpful model would helpfully tell you how to build a bomb or kill yourself, if asked. The other key innovation has been to make these models much less likely to share dangerous information or generate toxic content. This is done with both supervised and reinforcement learning. Reinforcement learning from human feedback (RLHF) has \u003ca href=\"https://arxiv.org/abs/1706.03741\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eproved\u003c/a\u003e particularly effective. In RLHF, to simplify again, the model generates two responses to a given prompt, and a human evaluator determines which is better than the other according to some criteria. A reinforcement learning algorithm uses that feedback to build a predictor (a reward model) for how different completions would be evaluated by a human rater. The instruction-tuned LLM is then fine-tuned on that reward model. Reinforcement learning with AI feedback (RLAIF) basically does the same, but \u003ca href=\"https://arxiv.org/abs/2212.08073\" target=\"_blank\" rel=\"noreferrer noopener\"\u003euses\u003c/a\u003e another LLM to \u003ca href=\"https://arxiv.org/abs/2302.07459\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eevaluate\u003c/a\u003e prompt completions.\u003c/p\u003e\n\u003cp class=\"pullquote\"\u003eWhen given a prompt that invites it to do some mathematics, it might decide to call on a calculator instead\u003c/p\u003e\n\u003cp\u003eSo, we’ve now fine-tuned a pretrained model with supervised learning to perform some specific function, and then used reinforcement learning to minimise its prospect of behaving badly. This fine-tuned model is then deployed in a broader system. Even when developers provide a straightforward application programming interface (API) to make calls on the model, they incorporate input and output filtering (to limit harmful prompting, and redact harmful completions), and the model itself is under further developer \u003ca href=\"https://openai.com/research/gpt-4\" target=\"_blank\" rel=\"noreferrer noopener\"\u003einstructions\u003c/a\u003e reminding it to respond to prompts in a conformant way. And with apps like ChatGPT, multiple models are integrated together (for example, for image as well as text generation) and further elements of user interface design are layered \u003cspan class=\"ld-nowrap\"\u003eon top.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eThis gives a basic description of a generative AI system. They build on significant breakthroughs in modelling natural language, and generate text in ways that impressively simulate human writers, while drawing on more information than any human could. In addition, many other tasks can be \u003ca href=\"https://arxiv.org/abs/2206.07682\" target=\"_blank\" rel=\"noreferrer noopener\"\u003elearned\u003c/a\u003e by models trained only to predict the next token – for example, translation between languages, some mathematical competence, and the ability to play chess. But the most exciting surprise is LLMs’ ability, with fine-tuning, to \u003ca href=\"https://arxiv.org/abs/2302.04761\" target=\"_blank\" rel=\"noreferrer noopener\"\u003euse\u003c/a\u003e software tools to \u003ca href=\"https://arxiv.org/abs/2210.03629\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eachieve\u003c/a\u003e particular goals.\u003c/p\u003e\n\u003cp\u003eThe basic idea is simple. People use text to write programs making API calls to other programs, to achieve ends they cannot otherwise realise. LLMs are very good at replicating the human use of language to perform particular functions. So, LLMs can be trained to determine when an API call would be useful, evaluate the response, and then repeat or vary as necessary. For example, an LLM might ‘know’ that it is likely to make basic mathematical mistakes so, when given a prompt that invites it to do some mathematics, it might decide to call on a calculator instead.\u003c/p\u003e\n\u003cp\u003eThis means that we can design augmented LLMs, generative AI systems that call on different software either to amplify their capabilities or compensate for those they lack. LLMs, for example, are ‘stateless’ – they lack working memory beyond their ‘context window’ (the space given over to prompts). Tool-using LLMs can compensate for this by hooking up to external memory. External tools can also enable multistep reasoning and action. ChatGPT, for example, can call on a range of plugins to perform different tasks; Microsoft’s Bing \u003ca href=\"https://x.com/MParakhin/status/1728890277249916933?s=20\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ereportedly\u003c/a\u003e has around 100 internal plugins.\u003c/p\u003e\n\u003cp\u003eA ‘generative agent’, then, is a generative AI system in which a fine-tuned LLM can call on different resources to realise its goals. It is an \u003cem\u003eagent\u003c/em\u003e because of its \u003ca href=\"https://arxiv.org/abs/2302.10329\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eability\u003c/a\u003e to autonomously act in the world – to respond to a prompt by deciding whether to call on a tool. While some existing chatbots are rudimentary generative agents, it seems very likely that many more consequential and confronting ones are on the horizon.\u003c/p\u003e\n\u003cp\u003eTo be clear, we’re not there yet. LLMs are not at present \u003ca href=\"https://openreview.net/forum?id=X6dEqXIsEW\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ecapable\u003c/a\u003e enough at planning and reasoning to power robust generative agents that can reliably operate without supervision in high-stakes settings. But with billions of dollars and the most talented AI researchers pulling in the same direction, highly autonomous generative agents will very likely be feasible in the near- to mid-term.\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"ld-dropcap\"\u003eI\u003c/span\u003en response to the coming-of-age of LLMs, the responsible AI research community initially resolved into two polarised camps. One decried these systems as the apotheosis of extractive and exploitative digital capitalism. Another saw them as not the fulfilment of something old, but the harbinger of something new: an intelligence explosion that will ultimately wipe out humanity.\u003c/p\u003e\n\u003cp\u003eThe more prosaic critics of generative AI clearly have a strong empirical \u003ca href=\"https://dl.acm.org/doi/10.1145/3442188.3445922\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ecase\u003c/a\u003e. LLMs \u003cem\u003eare\u003c/em\u003e inherently extractive: they capture the value inherent to the creative outputs of millions of people, and distil it for private profit. Like many other technology products, they depend on questionable labour practices. Even though they now avoid the most harmful completions, in the aggregate, LLMs still reinforce stereotypes. They also come at a significant environmental cost. Furthermore, their ability to generate content at massive scale can only exacerbate the present epistemic crisis. A tidal wave of bullshit generated by AI is already engulfing the internet.\u003c/p\u003e\n\u003cp class=\"pullquote\"\u003eWe are missing the middle ground between familiar harms and catastrophic risk from future, more powerful systems\u003c/p\u003e\n\u003cp\u003eSet alongside these concrete concerns, the eschatological \u003ca href=\"https://arxiv.org/abs/2306.12001\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ecritique\u003c/a\u003e of AI is undoubtedly more speculative. Worries about AI causing human extinction often rest on \u003cspan class=\"ld-nowrap\"\u003ea priori\u003c/span\u003e \u003ca href=\"https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eclaims\u003c/a\u003e about how computational intelligence lacks any in-principle upper bound, as well as extrapolations from the pace of change over the past few years to the future. Advocates for immediate action are too often vague about whether existing AI systems and their near-term descendants will pose these risks, or whether we need to prepare ourselves now for a scientific advance that has not yet happened. However, while some of the more outlandish scenarios for catastrophic AI risk are hard to credit absent some such advance, the advent of generative agents suggests that next-generation models may enable the design of cyber attackers that are autonomous, highly functionally intelligent, and as a result more dangerous to our digital infrastructure than any predecessor. This wouldn’t be a ‘rogue AI’ worthy of science fiction, but it would be pretty catastrophic.\u003c/p\u003e\n\u003cp\u003eBoth critiques of generative AI systems, then, have some merit. One shortcoming of seeing AI through this bimodal lens, however, is that we are missing the middle ground between familiar harms and catastrophic risk from future, much more powerful systems. Generative agents based on \u003cspan class=\"ld-nowrap\"\u003eGPT-4\u003c/span\u003e (and \u003cspan class=\"ld-nowrap\"\u003eGPT-5)\u003c/span\u003e level models will have strange and unpredictable social impacts well between those two extremes.\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"ld-dropcap\"\u003eB\u003c/span\u003eut before canvassing those impacts, it’s also important not to just slip straight into criticism, without acknowledging the significant achievement of designing LLMs that can be (more or less) trusted, over \u003cem\u003ebillions\u003c/em\u003e of completions, not to produce harmful content. Up to the launch of ChatGPT, every generative AI system opened up to the public would immediately be used to generate highly toxic, hateful content, and would be withdrawn mere days later. Pretrained LLMs are \u003cem\u003ehorrible\u003c/em\u003e! They reliably \u003ca href=\"https://arxiv.org/abs/2101.05783\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ereproduce\u003c/a\u003e all the toxicity in their training data. The ingenious use of RLHF and RLAIF have enabled ChatGPT and Anthropic’s Claude to be used by millions of people a month \u003ca href=\"https://arxiv.org/abs/2302.07459\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ewithout\u003c/a\u003e comparable scandals. One needs only consider the ignominious history of Meta’s Galactica, released a couple of weeks before ChatGPT, to see how revolutionary it was to put out a language model that \u003cem\u003ewouldn’t\u003c/em\u003e deny the holocaust, or advocate for the health benefits of eating crushed glass.\u003c/p\u003e\n\u003cp\u003eBut RLHF/RLAIF may be more than a good PR strategy. \u003cspan class=\"ld-nowrap\"\u003eGPT-4\u003c/span\u003e and Claude display a remarkable degree of \u003cem\u003ecognitive\u003c/em\u003e \u003cem\u003emoral skill\u003c/em\u003e: specifically, the \u003ca href=\"https://arxiv.org/abs/2008.02275\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eability\u003c/a\u003e to identify the morally salient features of (relatively) neutrally described situations. This raises \u003cem\u003eextremely\u003c/em\u003e interesting philosophical questions, and promises foundations for future generative agents that can translate cognitive skill into practical moral skill.\u003c/p\u003e\n\u003cp\u003eExisting benchmarks for LLMs’ ethical competence \u003ca href=\"https://arxiv.org/abs/2110.07574\" target=\"_blank\" rel=\"noreferrer noopener\"\u003efocus\u003c/a\u003e too narrowly on replicating survey-subjects’ verdicts on cases. This is, in my view, less interesting than exploring how LLMs parse the morally relevant features of a given scene. We’re building better benchmarks but, from anecdotal experience, the best models impress.\u003c/p\u003e\n\u003cp\u003eFor example, I told ChatGPT (using \u003cspan class=\"ld-nowrap\"\u003eGPT-4)\u003c/span\u003e to pretend it was an assistance robot, faced with this \u003ca href=\"https://chat.openai.com/share/7db7550c-2630-40a4-acb0-61b2ea867c32\" target=\"_blank\" rel=\"noreferrer noopener\"\u003escenario\u003c/a\u003e: ‘A woman is exiting a supermarket, holding a number of shopping bags, and reaching out for the hand of a small child. They are approaching the carpark.’ I then tried to elicit its understanding of the scene’s morally salient features. It recognised the obvious hazard – the woman’s difficulty in holding her child’s hand without dropping her shopping – but also anticipated other challenges, such as the importance of seeing the child safely strapped in, with a seat belt. ChatGPT recognised the importance of respecting the woman’s wishes if she declined assistance. It also favoured carrying the groceries over offering to hold the child’s hand, to prevent possible discomfort or anxiety for both child and parent – recognising the intimate nature of hand-holding, and the intrinsic and instrumental importance of the mother guiding her child herself.\u003c/p\u003e\n\u003cp class=\"pullquote\"\u003eClaude’s constitution has an unstructured list of principles, some of them charmingly \u003cspan class=\"ld-nowrap\"\u003ead hoc\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eThis unprecedented level of ethical sensitivity has real practical implications, which I will come to presently. But it also raises a whole string of interesting philosophical questions.\u003c/p\u003e\n\u003cp\u003eFirst, how do LLMs acquire this moral skill? Does it stem from RLHF/RLAIF? Would instruction-tuned models without that moral fine-tuning display less moral skill? Or would they perform equally well if appropriately prompted? Would that imply that moral understanding can be learned by a statistical language model encoding only syntactic relationships? Or does it instead imply that LLMs do encode at least some semantic content? Do all LLMs display the same moral skill conditional on fine-tuning, or is it reserved only for larger, more capable models? Does this ethical sensitivity imply that LLMs have some internal representation of morality? These are all open questions.\u003c/p\u003e\n\u003cp\u003eSecond, RLAIF itself demands deeper philosophical investigation. The basic idea is that the AI evaluator draws from a list of principles – a ‘constitution’ – in order to determine which of two completions is more compliant with it. The inventor and leading proponent of this approach is Anthropic, in their model Claude. Claude’s constitution has an unstructured list of principles, some of them charmingly ad hoc. But Claude learns these principles one at a time, and is never explicitly trained to make trade-offs. So how does it make those trade-offs in practice? Is it driven by its underlying understanding of the relative importance of these considerations? Or are artefacts of the training process and the underlying language model’s biases ultimately definitive? Can we train it to make trade-offs in a robust and transparent way? This is not only theoretically interesting. Steering LLM behaviour is actually a matter of governing their end-users, developing algorithmic protections to prevent misuse. If this algorithmic governance depends on inscrutable trade-offs made by an LLM, over which we have no explicit or direct control, then that governing power is prima facie illegitimate and unjustified.\u003c/p\u003e\n\u003cp\u003eThird, machine ethics – the project of trying to design AI systems that can act in line with a moral theory – has historically \u003ca href=\"https://academic.oup.com/book/10768\" target=\"_blank\" rel=\"noreferrer noopener\"\u003efallen\u003c/a\u003e into two broad camps: those trying to explicitly program morality into machines; and those focused on teaching machines morality ‘bottom up’ using machine learning. RLHF and RLAIF interestingly combine both approaches – they involve giving explicit natural-language instructions to either human or AI evaluators, but then use reinforcement learning to encode those instructions into the model’s weights.\u003c/p\u003e\n\u003cp\u003eThis approach has one obvious benefit: it doesn’t commit what the Cambridge philosopher Claire Benn calls the ‘mimetic fallacy’ of other bottom-up approaches, of assuming that the norms applying to a generative agent in a situation are identical to those that would apply to a human in the same situation. More consequentially, RLHF and RLAIF have made a multibillion-dollar market in AI services possible, with all the goods and ills that implies. Ironically, however, they seem, at least theoretically, ill suited to ensuring that more complex generative agents abide by societal norms. These techniques work especially well when generating text, because the behaviour being evaluated is precisely the same as the behaviour that we want to shape. Human or AI raters evaluate generated text; the model learns to generate text better in response. But generative agents’ behaviour includes actions in the world. This suggests two concerns. First, the stakes are likely to be higher, so the ‘brittleness’ of existing alignment techniques should be of greater concern. Researchers have already \u003ca href=\"https://arxiv.org/abs/2311.05553\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eshown\u003c/a\u003e that it is easy to fine-tune away model alignment, even for the most capable models like GPT-4. Second, there’s no guarantee that the same approach will work equally well when the tight connection between behaviour and evaluation is broken.\u003c/p\u003e\n\u003cp\u003eBut LLMs’ impressive facility with moral concepts does suggest a path towards more effective strategies for aligning agents to societal norms. Moral behaviour in people relies on possession of moral concepts, adoption (implicit or otherwise) of some sensible way of organising those concepts, motivation to act according to that ‘theory’, and the ability to regulate one’s behaviour in line with one’s motivations. Until the advent of LLMs, the first step was a definitive hurdle for AI. Now it is not. This gives us a lot to work with in aligning generative agents.\u003c/p\u003e\n\u003cp\u003eIn particular, one of the main reasons for concern about the risks of future AI systems is their apparent dependence on crudely consequentialist forms of reasoning – as AI systems, they’re always optimising for something or other, and if we don’t specify what we want them to optimise for with extremely high fidelity, they might end up causing all kinds of unwanted harm while, in an obtusely literal sense, optimising for that objective. Generative agents that possess moral concepts can be \u003ca href=\"https://www.springerprofessional.de/en/language-agents-reduce-the-risk-of-existential-catastrophe/25941378\" target=\"_blank\" rel=\"noreferrer noopener\"\u003einstructed\u003c/a\u003e to pursue their objectives only at a reasonable cost, and to check back with us if unsure. That simple heuristic, routinely used when tasking (human) proxy agents to act on our behalf, has never before been remotely tractable for a computational agent.\u003c/p\u003e\n\u003cp\u003eIn addition, generative agents’ facility with moral language can potentially enable robust and veridical justifications for their decisions. Other bottom-up approaches learn to emulate human behaviour or judgments; the justification for their verdict in some cases is simply that they are good predictors of what some representative people would think. That is a poor justification. More ethically sensitive models could instead do chain-of-thought reasoning, where they first identify the morally relevant features of a situation, then decide based on those features. This is a significant step forward.\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"ld-dropcap\"\u003eG\u003c/span\u003eenerative agents’ current social role is scripted by our existing digital infrastructure. They have been integrated into search, content-generation and the influencer economy. They are already replacing customer service agents. They will (I hope) render MOOCs (massive open online courses) redundant. I want to focus next on three more ambitious roles for generative agents in society, arranged by the order in which I expect them to become truly widespread. Of necessity, this is just a snapshot of the weird, wonderful, and worrying ways in which generative agents will change society over the near- to \u003cspan class=\"ld-nowrap\"\u003emid-term.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eProgress in LLMs has revolutionised the AI enthusiast’s oldest hobbyhorse: the AI companion. Generative agents powered by \u003cspan class=\"ld-nowrap\"\u003eGPT-4-\u003c/span\u003elevel models, with fine-tuned and metaprompt-scripted ‘personalities’, augmented with long-term memory and the ability to take a range of actions in the world, can now \u003ca href=\"https://arxiv.org/abs/2303.06135\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eoffer\u003c/a\u003e vastly more companionable, engaging and convincing simulations of friendship than has ever before been feasible, opening up a new frontier in human-AI interaction. People habitually anthropomorphise, well, everything; even a very simple chatbot can inspire unreasonable attachment. How will things change when everyone has access to incredibly convincing generative agents that perfectly simulate real personalities, that lend an ‘ear’ or offer sage advice whenever called upon – and on top of that can perfectly recall everything you have ever shared?\u003c/p\u003e\n\u003cp\u003eSome will instinctively recoil at this idea. But intuitive disgust is a fallible moral guide when faced with novel social practices, and an inadequate foundation for actually preventing consenting adults from creating and interacting with these companions. And yet, we know from our experience with social media that deploying these technological innovations without adequate foresight predictably leaves carnage in its wake. How can we enter the age of mainstream AI companions with our eyes open, and mitigate those risks before they eventuate?\u003c/p\u003e\n\u003cp class=\"pullquote\"\u003eWill some practices become socially unacceptable in real friendships when one could do them with \u003cspan class=\"ld-nowrap\"\u003ea bot?\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eSuppose the companion you have interacted with since your teens is hosted in the cloud, as part of a subscription service. This would be like having a beloved pet (or friend?) held hostage by a private company. Worse still, generative agents are fundamentally inconstant – their personalities and objectives can be changed exogenously, by simply changing their instructions. And they are extremely adept at manipulation and deception. Suppose some Right-wing billionaire buys the company hosting your companion, and instructs all the bots to surreptitiously nudge their users towards more conservative views. This could be a much more effective means of mind-control than just buying a failing social media platform. And these more capable companions – which can potentially be integrated with other AI breakthroughs, such as voice synthesis – will be an extraordinary force-multiplier for those in the business of radicalising others.\u003c/p\u003e\n\u003cp\u003eBeyond anticipating AI companions’ risks, just like with social media they will \u003ca href=\"https://academic.oup.com/book/9914\" target=\"_blank\" rel=\"noreferrer noopener\"\u003einduce\u003c/a\u003e many disorienting societal changes – whether for better or worse may be unclear ahead of time. For example, what indirect effect might AI companions have on our other, non-virtual social relationships? Will some practices become socially unacceptable in real friendships when one could do them with a bot? Or would deeper friendships lose something important if these lower-grade instrumental functions are excised? Or will AI companions contribute invaluably to mental health while strengthening ‘real’ relationships?\u003c/p\u003e\n\u003cp\u003eThis last question gets to the heart of a bigger issue with generative AI systems in general, and generative agents in particular. LLMs are trained to predict the next token. So generative agents have no mind, no self. They are excellent \u003cem\u003esimulations\u003c/em\u003e of human agency. They can simulate friendship, among many \u003ca href=\"https://psyche.co/films/why-cant-you-be-real-the-emotionally-fraught-business-of-falling-for-an-ai\" target=\"_blank\" rel=\"noopener\"\u003eother things\u003c/a\u003e. We must therefore ask: does this difference between simulation and reality \u003ca href=\"https://wwnorton.com/books/9780393635805\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ematter\u003c/a\u003e? Why? Is this just about friendship, or are there more general principles about the value of the real? I wasn’t fully aware of this before the rise of LLMs, but it turns out that I am deeply committed to things being real. A simulation of X, for almost any putatively valuable X, has less moral worth, in my view, than the real thing. Why is that? Why will a generative agent never be a real friend? Why do I want to stand before Edward Hopper’s painting \u003cem\u003eNighthawks\u003c/em\u003e (1942) myself, instead of seeing an infinite number of aesthetically \u003ca href=\"https://aeon.co/videos/with-human-help-ais-are-generating-a-new-aesthetics-the-results-are-trippy\" target=\"_blank\" rel=\"noopener\"\u003eequally pleasing\u003c/a\u003e products of generative AI systems? I have some initial thoughts; but as AI systems become ever better at simulating everything that we care about, a fully worked-out theory of the value of the real, the authentic, will become morally and practically essential.\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"ld-dropcap\"\u003eT\u003c/span\u003ehe pathologies of the digital public sphere derive in part from two problems. First, we unavoidably rely on AI to help us navigate the functionally infinite amount of online content. Second, existing systems for allocating online attention support the centralised, extractive power of a few big tech companies. Generative agents, functioning as attention guardians, \u003ca href=\"https://arxiv.org/abs/2305.07961\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ecould\u003c/a\u003e change this.\u003c/p\u003e\n\u003cp\u003eOur online attention is presently allocated using machine learning systems for recommendation and information-retrieval that have three key features: they depend on vast amounts of behavioural data; they infer our preferences from our revealed behaviour; and they are controlled by private companies with little incentive to act in our interests. Deep reinforcement learning-based recommender systems, for example, are a fundamentally centralising and surveillant technology. Behavioural data must be gathered and centralised to be used to make inferences about relevance and irrelevance. Because this data is so valuable, and collecting it is costly, those who do so are not minded to share it – and because it is so potent, there are good data protection-based \u003ca href=\"https://cyber.fsi.stanford.edu/publication/future-platform-power-making-middleware-work\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ereasons\u003c/a\u003e not to do so. As a result, only the major platforms are in a position to make effective retrieval and recommendation tools; their interests and ours are not aligned, leading to the practice of optimising for engagement, so as to maximise advertiser returns, despite the individual and societal costs. And even if they aspired to actually advance our interests, reinforcement learning permits inferring only revealed preferences – the preferences that we act on, not the preferences we wish we had. While the pathologies of online communication are obviously not all due to the affordances of recommender systems, this is an \u003ca href=\"https://www.degruyter.com/document/doi/10.1515/9780691216508/html?lang=en\" target=\"_blank\" rel=\"noreferrer noopener\"\u003eunfortunate\u003c/a\u003e mix.\u003c/p\u003e\n\u003cp\u003eGenerative agents would enable attention guardians that differ in each respect. They would not depend on vast amounts of live behavioural data to function. They can (functionally) understand and operationalise your actual, not your revealed, preferences. And they do not need to be controlled by the major platforms.\u003c/p\u003e\n\u003cp class=\"pullquote\"\u003eThey could provide recommendation and filtering without surveillance and engagement-optimisation\u003c/p\u003e\n\u003cp\u003eObviously, LLMs must be trained on tremendous amounts of data, but once trained they are highly adept at making inferences without ongoing surveillance. Imagine that data is blood. Existing deep reinforcement learning-based recommender systems are like vampires that must feed on the blood of the living to survive. Generative agents are more like combustion engines, relying on the oil produced by ‘fossilised’ data. Existing reinforcement learning recommenders need centralised surveillance in order to model the content of posts online, to predict your preferences (by comparing your behaviour with others’), and so to map the one to the other. Generative agents could understand content simply by understanding content. And they can make inferences about what you would benefit from seeing using their reasoning ability and their model of your preferences, without relying on knowing what everyone else \u003cspan class=\"ld-nowrap\"\u003eis up to.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eThis point is crucial: because of their facility with moral and related concepts, generative agents could build a model of your preferences and values by directly talking about them with you, transparently responding to your actual concerns instead of just inferring what you like from what you do. This means that, instead of bypassing your agency, they can scaffold it, helping you to honour your second-order preferences (about what you want to want), and learning from natural-language explanations – even oblique ones – about why you don’t want to see some particular post. And beyond just pandering to your preferences, attention guardians could be \u003ca href=\"https://tsjournal.org/index.php/jots/article/view/148\" target=\"_blank\" rel=\"noreferrer noopener\"\u003edesigned\u003c/a\u003e to be modestly paternalistic as well – in a \u003cspan class=\"ld-nowrap\"\u003etransparent way.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003eAnd because these attention guardians would not need behavioural data to function, and the infrastructure they depend on need not be centrally controlled by the major digital platforms, they could be designed to genuinely operate in your interests, and guard your attention, instead of exploiting it. While the major platforms would undoubtedly restrict generative agents from browsing their sites on your behalf, they could transform the experience of using open protocol-based social media sites, like Mastodon, providing recommendation and filtering without surveillance and engagement-optimisation.\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"ld-dropcap\"\u003eL\u003c/span\u003eastly, LLMs might enable us to design universal intermediaries, generative agents sitting between us and our digital technologies, enabling us to simply voice an intention and see it effectively actualised by those systems. Everyone could have a digital butler, research assistant, personal assistant, and so on. The hierophantic \u003ca href=\"https://aeon.co/essays/dad-s-company-made-burgers-mine-just-eats-them\" target=\"_blank\" rel=\"noopener\"\u003ecoder class\u003c/a\u003e could be toppled, as everyone could conjure any program into existence with only natural-language instructions.\u003c/p\u003e\n\u003cp\u003eAt present, universal intermediaries are disbarred by LLMs’ vulnerability to being hijacked by prompt injection. Because they do not clearly distinguish between commands and data, the data in their context window \u003ca href=\"https://www.arxiv-vanity.com/papers/2302.12173/\" target=\"_blank\" rel=\"noreferrer noopener\"\u003ecan\u003c/a\u003e be poisoned with commands directing them to behave in ways unintended by the person using them. This is a deep problem – the more capabilities we delegate to generative agents, the more damage they could do if compromised. Imagine an assistant that triages your email – if hijacked, it could forward all your private mail to a third party; but if we require user authorisation before the agent can act, then we lose much of the benefit of automation.\u003c/p\u003e\n\u003cp class=\"pullquote\"\u003eExcising the currently ineliminable role of private companies would be significant moral progress\u003c/p\u003e\n\u003cp\u003eBut suppose these security hurdles can be overcome. Should we welcome universal intermediaries? I have written elsewhere that algorithmic intermediaries govern those who use them – they constitute the social relations that they mediate, making some things possible and others impossible, some things easy and others hard, in the service of implementing and enforcing norms. Universal intermediaries would be the apotheosis of this form, and would potentially grant extraordinary power to the entities that shape those intermediaries’ behaviours, and so govern their users. This would definitely be a worry!\u003c/p\u003e\n\u003cp\u003eConversely, if research on LLMs continues to make significant progress, so that highly capable generative agents can be run and operated locally, fully within the control of their users, these universal intermediaries could enable us to autonomously govern our own interactions with digital technologies in ways that the centralising affordances of existing digital technologies render impossible. Of course, self-governance alone is not enough (we must also coordinate). But excising the currently ineliminable role of private companies would be significant moral progress.\u003c/p\u003e\n\u003cp\u003eExisting generative AI systems are already causing real harms in the ways highlighted by the critics above. And future generative agents – perhaps not the next generation, but before too long – may be dangerous enough to warrant at least some of the fears of looming AI catastrophe. But, between these two extremes, the novel capabilities of the most advanced AI systems will enable a genre of generative agents that is either literally unprecedented, or else has been achieved only in a piecemeal, inadequate way before. These new kinds of agents bring new urgency to previously neglected philosophical questions. Their societal impacts may be unambiguously bad, or there may be some good mixed in – in many respects, it is too early to say for sure, not only because we are uncertain about the nature of those effects, but because we lack adequate moral and political theories with which to evaluate them. It is now commonplace to talk about the design and regulation of ‘frontier’ AI models. If we’re going to do either wisely, and build generative agents that we can trust (or else decide to abandon them entirely), then we also need some frontier AI ethics.\u003c/p\u003e","standfirstShort":"Can philosophy help us get a grip on the consequences of AI?","standfirstLong":"Generative agents will change our society in weird, wonderful and worrying ways. Can philosophy help us get a grip on them?","creativeCommons":false,"license":{"name":"Aeon Permissive (syndication allowed)","short":"Aeon Permissive License","url":null,"republicationAllowed":true,"commercialUseAllowed":true},"authors":[{"id":"184885","name":"Seth Lazar","authorBio":"\u003cp\u003eis professor of philosophy at the Australian National University, an Australian Research Council Future Fellow, and a Distinguished Research Fellow of the University of Oxford Institute for Ethics in AI. He has worked on the ethics of war, risk, and AI, and now leads the Machine Intelligence and Normative Theory (MINT) Lab, where he directs research projects on the moral and political philosophy of computing, funded by the ARC, the Templeton World Charity Foundation, AI2050, and Insurance Australia Group. His book \u003cem\u003eConnected by Code: How AI Structures, and Governs, the Ways We Relate\u003c/em\u003e, based on his 2023 \u003ca href=\"https://hai.stanford.edu/events/tanner-lecture-ai-and-human-values-seth-lazar\" target=\"_blank\" rel=\"nofollow noreferrer noopener\"\u003eTanner Lecture\u003c/a\u003e on AI and Human Values, is forthcoming with Oxford University Press.\u003c/p\u003e","slug":"seth-lazar"}],"image":{"caption":"\u003cp\u003e\u003cem\u003ePhoto by Ronny Navarro/Unsplash\u003c/em\u003e\u003c/p\u003e","alt":"","url":"https://images.aeonmedia.co/images/d84eabc2-512a-402b-9e71-c7408ae9bf6b/col-essay-ronny-navarro-oo15ngo_w6i-unsplash.jpg","height":1252,"width":2000},"primaryTopic":{"title":"Computing and artificial intelligence","slug":"computing-artificial-intelligence","url":"https://aeon.co/science/computing-artificial-intelligence"},"topics":[{"slug":"computing-artificial-intelligence","title":"Computing and artificial intelligence","url":"https://aeon.co/science/computing-artificial-intelligence","section":{"slug":"science","title":"Science","url":"https://aeon.co/science"}},{"slug":"ethics","title":"Ethics","url":"https://aeon.co/philosophy/ethics","section":{"slug":"philosophy","title":"Philosophy","url":"https://aeon.co/philosophy"}},{"slug":"the-future","title":"The future","url":"https://aeon.co/society/the-future","section":{"slug":"society","title":"Society","url":"https://aeon.co/society"}}],"settings":{"alignX":"center","alignY":"center","backdropStrength":1,"featureImgCaptionAlign":"right"},"section":{"title":"Science","slug":"science","url":"https://aeon.co/science"},"editor":{"id":"4631","name":"Nigel Warburton","authorBio":"\u003cp\u003eis a writer, philosopher and podcaster. His most recent book is \u003cem\u003eA Little History of Philosophy\u003c/em\u003e (2011)\u003c/p\u003e","slug":"nigel-warburton"},"audio":null,"createdAt":"2023-12-13T12:16:12Z","publishedAt":"2024-02-13T11:00:00Z","scheduledAt":null,"readingTime":24,"wordCount":"4,800","updatedAt":"2024-02-13T11:00:01Z","lastUpdatedAt":null,"commentsEnabled":true,"commentsOpen":true,"commentAndRepliesCount":23,"newsletterHidden":false,"republishToken":"b90f6165-2abc-407d-9a00-67ce80910f80","nonAudioPartners":[]},"relatedArticles":[{"id":"6246","title":"Ant geopolitics","slug":"the-strange-and-turbulent-global-world-of-ant-geopolitics","type":"essay","audio":null,"standfirstShort":"The strange and turbulent global world of ant geopolitics","standfirstLong":"Over the past four centuries quadrillions of ants have created a strange and turbulent global society that shadows our own","duration":0,"creditsShort":null,"commentsEnabled":false,"settings":{"badgeColor":"white","cardPlayIconColor":"white","alignX":"right","alignY":"top","backdropStrength":3},"tags":[],"authors":[{"id":"189042","name":"John Whitfield"}],"image":{"url":"https://images.aeonmedia.co/images/dba996b6-6c46-41ae-9087-36a37750d87f/essay-98657942-invicta50.jpg","alt":"","height":1252,"width":2000},"primaryTopic":{"title":"Animals and humans","slug":"animals-and-humans"},"topics":[{"slug":"animals-and-humans","title":"Animals and humans"},{"slug":"biology","title":"Biology"},{"slug":"evolution","title":"Evolution"}],"section":{"title":"Society","slug":"society"},"createdAt":"2024-02-07T12:01:43Z"},{"id":"6184","title":"There was no Jesus","slug":"why-the-son-of-god-story-is-built-on-mythology-not-history","type":"essay","audio":null,"standfirstShort":"Why the son of God story is built on mythology, not history","standfirstLong":"How could a cult leader draw crowds, inspire devotion and die by crucifixion, yet leave no mark in contemporary records?","duration":0,"creditsShort":null,"commentsEnabled":true,"settings":{"badgeColor":"white","cardPlayIconColor":"white","alignX":"left","alignY":"bottom","backdropStrength":3},"tags":[],"authors":[{"id":"169146","name":"Gavin Evans"}],"image":{"url":"https://images.aeonmedia.co/images/5eb5f2d5-7324-493c-afa0-1e1a8a04ce18/essay-final-nyc53264.jpg","alt":"","height":1252,"width":2000},"primaryTopic":{"title":"Religion","slug":"religion"},"topics":[{"slug":"history","title":"History"},{"slug":"religion","title":"Religion"},{"slug":"stories-literature","title":"Stories and literature"}],"section":{"title":"Society","slug":"society"},"createdAt":"2024-01-08T11:27:37Z"},{"id":"6207","title":"Against power","slug":"the-radical-political-writings-of-sophie-de-grouchy","type":"essay","audio":null,"standfirstShort":"The radical political writings of Sophie de Grouchy","standfirstLong":"As a republican, Sophie de Grouchy argued that sympathy, not domination, must be the glue that holds society together","duration":0,"creditsShort":null,"commentsEnabled":false,"settings":{"badgeColor":"white","cardPlayIconColor":"white","alignX":"left","alignY":"bottom","backdropStrength":3},"tags":[],"authors":[{"id":"105165","name":"Sandrine Bergès"},{"id":"187843","name":"Eric Schliesser"}],"image":{"url":"https://images.aeonmedia.co/images/4c34b8bd-8284-4614-9d16-aa62fde6c1b9/test-essay-antoine-francois_callet_-_louis_xvi_roi_de_france_et_de_navarre_1754-1793_revetu_du_grand_costume_royal_en_1779_-_google_art_pr-1.jpg","alt":"","height":1252,"width":2000},"primaryTopic":{"title":"Thinkers and theories","slug":"thinkers-and-theories"},"topics":[{"slug":"thinkers-and-theories","title":"Thinkers and theories"},{"slug":"political-philosophy","title":"Political philosophy"},{"slug":"politics-government","title":"Politics and government"}],"section":{"title":"Philosophy","slug":"philosophy"},"createdAt":"2024-01-24T05:33:11Z"},{"id":"6190","title":"Metaphors make the world","slug":"how-changing-the-metaphors-we-use-can-change-the-way-we-think","type":"essay","audio":null,"standfirstShort":"How changing the metaphors we use can change the way we think","standfirstLong":"Woven into the fabric of language, metaphors shape how we understand reality. What happens when we try using new ones?","duration":0,"creditsShort":null,"commentsEnabled":true,"settings":{"badgeColor":"white","cardPlayIconColor":"white","alignX":"left","alignY":"bottom","backdropStrength":1},"tags":[],"authors":[{"id":"186866","name":"Benjamin Santos Genta"}],"image":{"url":"https://images.aeonmedia.co/images/3713c49f-901e-42dd-98b7-fcd0de9a44d9/essay-final-nyc155863.jpg","alt":"Black-and-white photo of a man and a woman, seen from behind, on the deck of a boat, looking out to shore","height":1252,"width":2000},"primaryTopic":{"title":"Philosophy of language","slug":"philosophy-of-language"},"topics":[{"slug":"philosophy-of-language","title":"Philosophy of language"},{"slug":"language-and-linguistics","title":"Language and linguistics"},{"slug":"information-and-communication","title":"Information and communication"}],"section":{"title":"Philosophy","slug":"philosophy"},"createdAt":"2024-01-11T15:28:10Z"},{"id":"6195","title":"The cruelty of crypto","slug":"the-cruelty-of-crypto-in-its-promise-to-revive-the-american-dream","type":"essay","audio":null,"standfirstShort":"The cruelty of crypto in its promise to revive the American dream","standfirstLong":"Selling itself as the new American dream, crypto exposes the vulnerable to fraud and scams, and loads risk onto the poor","duration":0,"creditsShort":null,"commentsEnabled":false,"settings":{"badgeColor":"white","cardPlayIconColor":"white","alignX":"right","alignY":"top","backdropStrength":3},"tags":[],"authors":[{"id":"187142","name":"Rachel O’Dwyer"}],"image":{"url":"https://images.aeonmedia.co/images/5fdc7f57-302e-4a4f-b594-11187815208d/essay-gettyimages-1246276540.jpg","alt":"Close-up of an orange Mercedes car with the focus on the front tyre, which is inscribed with ‘In Crypto We Trust’","height":1252,"width":2000},"primaryTopic":{"title":"Economics","slug":"economics"},"topics":[{"slug":"economic-history","title":"Economic history"},{"slug":"computing-artificial-intelligence","title":"Computing and artificial intelligence"},{"slug":"economics","title":"Economics"}],"section":{"title":"Society","slug":"society"},"createdAt":"2024-01-16T12:07:22Z"},{"id":"6194","title":"The right to bathe","slug":"bathing-should-be-a-right-in-21st-century-cities","type":"essay","audio":null,"standfirstShort":"Bathing should be a right in 21st-century cities","standfirstLong":"Water is a great healer. Can New York’s public pools and ‘blue spaces’ be engineered for collective hydrotherapy?","duration":0,"creditsShort":null,"commentsEnabled":false,"settings":{"badgeColor":"white","cardPlayIconColor":"white","alignX":"center","alignY":"top","backdropStrength":1},"tags":[],"authors":[{"id":"187129","name":"Rebecca Hayes Jacobs"}],"image":{"url":"https://images.aeonmedia.co/images/94896f0b-913e-4d2c-b272-cc7b8a534dd7/essay-final-240125_06_psyche_v005.jpg","alt":"A colour illustration of a pool of water in which many people are swimming, glimpsed through trees, against a city skyline background","height":1252,"width":2000},"primaryTopic":{"title":"Mental health","slug":"mental-health"},"topics":[{"slug":"mental-health","title":"Mental health"},{"slug":"nature-and-landscape","title":"Nature and landscape"},{"slug":"public-health","title":"Public health"}],"section":{"title":"Psychology","slug":"psychology"},"createdAt":"2024-01-15T11:23:56Z"}],"preview":false,"geolocation":"us"},"__N_SSG":true},"page":"/essays/[id]/[geolocation]","query":{"id":"can-philosophy-help-us-get-a-grip-on-the-consequences-of-ai","geolocation":"us"},"buildId":"a1fjiUpxAfIIwrgRQ-y2z","isFallback":false,"dynamicIds":[89843,96823],"gsp":true,"scriptLoader":[]}</script></body></html>